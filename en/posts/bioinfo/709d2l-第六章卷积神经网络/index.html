<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">

<link rel="icon" href="/favicon.ico" type="image/x-icon"> 
<title>D2L--第六章卷积神经网络 | Li&#39;s Bioinfo-Blog</title>
<meta name="keywords" content="深度学习, D2L">
<meta name="description" content="1. 从全连接层到卷积
1.1 不变性
假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：

平移不变性：无论该物品在图片的哪个位置，都可以检测到；
局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。

1.2 多层感知机的限制

对于图片（例如12M）像素的一维展开，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。
卷积(convolution)计算：输入X为二维矩阵，输出的隐藏表示H仍为矩阵。参数包括权重矩阵V与偏置U。H中的每一个元素都由权重矩阵V与输入X中相应区域元素的&rsquo;点积&rsquo;，再加上偏置所得到。（下图演示忽略了偏置计算）

平移不变性：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。
局部性：卷积核(kernel)的形状通常较小(|a|&gt;△;|b|&gt;△)，即针对输入的局部区域进行特征提取。




">
<meta name="author" content="Lishensuo">
<link rel="canonical" href="https://lishensuo.github.io/en/posts/bioinfo/709d2l-%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.9e4de5e3ba61ea358168341aa7cdf70abfaafb7c697dfe8624af3ddff9a35c2f.css" integrity="sha256-nk3l47ph6jWBaDQap833Cr&#43;q&#43;3xpff6GJK893/mjXC8=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.555af97124d54bb1457985dd081b8f5616a48103aafeb30ac89fde835d65aa6c.js" integrity="sha256-VVr5cSTVS7FFeYXdCBuPVhakgQOq/rMKyJ/eg11lqmw="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://lishensuo.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://lishensuo.github.io/Q.gif">
<link rel="mask-icon" href="https://lishensuo.github.io/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lishensuo.github.io/en/posts/bioinfo/709d2l-%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="D2L--第六章卷积神经网络" />
<meta property="og:description" content="1. 从全连接层到卷积
1.1 不变性
假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：

平移不变性：无论该物品在图片的哪个位置，都可以检测到；
局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。

1.2 多层感知机的限制

对于图片（例如12M）像素的一维展开，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。
卷积(convolution)计算：输入X为二维矩阵，输出的隐藏表示H仍为矩阵。参数包括权重矩阵V与偏置U。H中的每一个元素都由权重矩阵V与输入X中相应区域元素的&rsquo;点积&rsquo;，再加上偏置所得到。（下图演示忽略了偏置计算）

平移不变性：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。
局部性：卷积核(kernel)的形状通常较小(|a|&gt;△;|b|&gt;△)，即针对输入的局部区域进行特征提取。




" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lishensuo.github.io/en/posts/bioinfo/709d2l-%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-04T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-08-04T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="D2L--第六章卷积神经网络"/>
<meta name="twitter:description" content="1. 从全连接层到卷积
1.1 不变性
假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：

平移不变性：无论该物品在图片的哪个位置，都可以检测到；
局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。

1.2 多层感知机的限制

对于图片（例如12M）像素的一维展开，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。
卷积(convolution)计算：输入X为二维矩阵，输出的隐藏表示H仍为矩阵。参数包括权重矩阵V与偏置U。H中的每一个元素都由权重矩阵V与输入X中相应区域元素的&rsquo;点积&rsquo;，再加上偏置所得到。（下图演示忽略了偏置计算）

平移不变性：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。
局部性：卷积核(kernel)的形状通常较小(|a|&gt;△;|b|&gt;△)，即针对输入的局部区域进行特征提取。




"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "分类",
      "item": "https://lishensuo.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📖 生信数据分析--分析流程，工具包等",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "D2L--第六章卷积神经网络",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/709d2l-%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "D2L--第六章卷积神经网络",
  "name": "D2L--第六章卷积神经网络",
  "description": "1. 从全连接层到卷积 1.1 不变性 假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：\n平移不变性：无论该物品在图片的哪个位置，都可以检测到； 局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。 1.2 多层感知机的限制 对于图片（例如12M）像素的一维展开，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。 卷积(convolution)计算：输入X为二维矩阵，输出的隐藏表示H仍为矩阵。参数包括权重矩阵V与偏置U。H中的每一个元素都由权重矩阵V与输入X中相应区域元素的\u0026rsquo;点积\u0026rsquo;，再加上偏置所得到。（下图演示忽略了偏置计算） 平移不变性：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。 局部性：卷积核(kernel)的形状通常较小(|a|\u0026gt;△;|b|\u0026gt;△)，即针对输入的局部区域进行特征提取。 ",
  "keywords": [
    "深度学习", "D2L"
  ],
  "articleBody": "1. 从全连接层到卷积 1.1 不变性 假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：\n平移不变性：无论该物品在图片的哪个位置，都可以检测到； 局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。 1.2 多层感知机的限制 对于图片（例如12M）像素的一维展开，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。 卷积(convolution)计算：输入X为二维矩阵，输出的隐藏表示H仍为矩阵。参数包括权重矩阵V与偏置U。H中的每一个元素都由权重矩阵V与输入X中相应区域元素的’点积’，再加上偏置所得到。（下图演示忽略了偏置计算） 平移不变性：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。 局部性：卷积核(kernel)的形状通常较小(|a|\u003e△;|b|\u003e△)，即针对输入的局部区域进行特征提取。 如上计算中，模型参数的数量比全连接层参数少很多，降低了训练难度。 2. 图像卷积 2.1 互相关运算 CNN中的卷积与数学中的卷积概念不完全相同，本质上为互相关运算(cross-correlation) 如下图，输入是3×3的二维张量；卷积核的高和宽都是2： 卷积窗口从输入的左上角开始，从左到右，从上到下滑动； 每次按对应位置的元素相乘，再求和得到单个标量结果； 按上述规则滑动的计算结果，输出形状将小于输入形状。 输出结果有时被称为特征映射。对于输出结果中的任一元素，其感受野指上一层中所有参与计算的输入元素。\n手动代码实现互相关运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import torch from torch import nn from d2l import torch as d2l def corr2d(X, K): #@save \"\"\"计算二维互相关运算\"\"\" h, w = K.shape #定义输出的形状 Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) #遍历每次滑动 for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] = (X[i:i + h, j:j + w] * K).sum() return Y # 输入 X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) # 卷积核 K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) corr2d(X, K) 2.2 卷积层 如前所述，卷积层中的两个被训练的参数是卷积核权重和标量偏置，在训练时，会被随机初始化； 基于上述互相关运算函数，手动定义一个二维卷积层 1 2 3 4 5 6 7 8 class Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight = nn.Parameter(torch.rand(kernel_size)) self.bias = nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias 2.3 图像中目标的边缘检测 卷积层的简单应用：根据像素变化的位置，检测图像中不同颜色的边缘。 1 2 3 4 5 6 7 8 9 # 输入数据：下图左 X = torch.ones((6, 8)) X[:, 2:6] = 0 # 卷积核 K = torch.tensor([[1.0, -1.0]]) # 卷积计算：下图右 Y = corr2d(X, K) 2.4 学习卷积核 可通过torch的nn.Conv2d类快速定义一个卷积层 该类的前两个参数分别用于设置输入与输出通道数； kernel_size参数用于指定卷积核的高和宽。 如下代码，将根据上述的输入X与输出Y，学习卷积核 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核 conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False) # 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度）， # 其中批量大小和通道数都为1 X = X.reshape((1, 1, 6, 8)) #示例输入 Y = Y.reshape((1, 1, 6, 7)) #示例输出 lr = 3e-2 # 学习率 for i in range(10): Y_hat = conv2d(X) l = (Y_hat - Y) ** 2 #预测的平方损失 conv2d.zero_grad() l.sum().backward() # 迭代卷积核 conv2d.weight.data[:] -= lr * conv2d.weight.grad if (i + 1) % 2 == 0: print(f'epoch {i+1}, loss {l.sum():.3f}') conv2d.weight.data.reshape((1, 2)) # tensor([[ 0.9938, -0.9841]]) 3. 填充和步幅 3.1 填充 可在输入图像的边界填充元素（通常为0），使得经卷积计算后的输出形状变大； 当卷积核的高宽为奇数（推荐）时，若填充的行数（一半在顶，一半在底）与列数（一半在左，一半在右）与卷积核的高宽少1，则输入与输出的形状相同。 可通过nn.Conv2d类的padding参数设置填充。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import torch from torch import nn # 为了方便起见，我们定义了一个计算卷积层的函数。 # 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数 def comp_conv2d(conv2d, X): # 这里的（1，1）表示批量大小和通道数都是1 X = X.reshape((1, 1) + X.shape) #(1, 1) + X.shape 长度为4的tuple Y = conv2d(X) # 省略前两个维度：批量大小和通道 return Y.reshape(Y.shape[2:]) # 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列 conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) X = torch.rand(size=(8, 8)) comp_conv2d(conv2d, X).shape # torch.Size([8, 8]) 3.2 步幅 在上述示例中，卷积窗口滑动的长度（步幅）为1； 为了高效计算或是缩减采样次数，可增大滑动的幅度； 当卷积核高宽为奇数，且填充比卷积核形状少1时，则输出的形状大小为输入形状除以步幅； 可通过nn.Conv2d类的stride参数设置 1 2 3 conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2) comp_conv2d(conv2d, X).shape # torch.Size([4, 4]) 4. 多输入多输出通道 4.1 多输入通道 图片通常包含三个通道（红绿蓝三原色），即输入数据有三个维度。其中，前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示。 此时，每个通道都有一个卷积核，最后的输出是所有通道卷积结果的和。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import torch from d2l import torch as d2l # X表示多通道输入 # K表示多通道卷积核 def corr2d_multi_in(X, K): # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起 return sum(d2l.corr2d(x, k) for x, k in zip(X, K)) X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]) K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]]) corr2d_multi_in(X, K) 4.2 多输出通道 在上述的多通道输入中，每个通道只有一个卷积核，最后得到一个通道的输出； 可以在每个通道中建立多个(o)卷积核。此时，对于i个输入通道，就共有o × i个卷积核； 然后按照4.1计算方法，可以得到o个输出通道的结果； 如下，i=1，o=4 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # X表示多通道输入 # K表示多通道卷积核【4个维度】 def corr2d_multi_in_out(X, K): # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。 # 最后将所有结果都叠加在一起(沿新的第一维度（dim=0）堆叠起来) return torch.stack([corr2d_multi_in(X, k) for k in K], 0) #k三个维度，参考4.1 # 之前的K是三维的多个(等于对应通道数)卷积核 K = torch.stack((K, K + 1, K + 2), 0) K.shape # torch.Size([3, 2, 2, 2]) # i=2; o=3 corr2d_multi_in_out(X, K).shape # torch.Size([3, 2, 2]) 可以将每个输出通道认为是提取的一种特征模式，供下一神经网络层组合学习。(https://poloclub.github.io/cnn-explainer/)\n4.3 1×1卷积层 卷积的本质是有效提取相邻像素间的相关特征，而1×1卷积显然没有此作用； 1×1卷积受欢迎的原因是作为融合通道使用，直观上是改变了输入通道的数量。 代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #从全连接层的角度，实现1×1卷积 def corr2d_multi_in_out_1x1(X, K): c_i, h, w = X.shape c_o = K.shape[0] X = X.reshape((c_i, h * w)) #每个通道拉平为一个向量，此时X为一个矩阵 K = K.reshape((c_o, c_i)) # 全连接层中的矩阵乘法 Y = torch.matmul(K, X) #(c_o, h * w) return Y.reshape((c_o, h, w)) X = torch.normal(0, 1, (3, 3, 3)) #3个输入通道 K = torch.normal(0, 1, (2, 3, 1, 1)) #2×3个卷积核 Y1 = corr2d_multi_in_out_1x1(X, K) #按常规卷积层角度的实现 Y2 = corr2d_multi_in_out(X, K) assert float(torch.abs(Y1 - Y2).sum()) \u003c 1e-6 5. 汇聚层 5.1 最大汇聚层和平均汇聚层 汇聚层(pooling)又称池化层，降低卷积层对位置的敏感性。 它与卷积操作类似，由一个固定窗口组成，在输入数据中滑动，并计算得到输出。 不同之处在于，汇聚层没有学习参数，为确定性计算；主要分为如下两种 最大汇聚层：汇聚窗口覆盖区域内的最大值； 平均汇聚层：汇聚窗口覆盖区域内的平均值； 手动代码实现（类似上述的2.1处） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import torch from torch import nn from d2l import torch as d2l def pool2d(X, pool_size, mode='max'): p_h, p_w = pool_size Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)) for i in range(Y.shape[0]): for j in range(Y.shape[1]): if mode == 'max': Y[i, j] = X[i: i + p_h, j: j + p_w].max() elif mode == 'avg': Y[i, j] = X[i: i + p_h, j: j + p_w].mean() return Y X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) pool2d(X, (2, 2)) pool2d(X, (2, 2), 'avg') 5.2 填充和步幅 默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同（即每次滑动区域没有重叠）； 可设置nn.MaxPool2d/nn.AvgPool2d类的参数： 第一个参数为窗口的大小 padding与stride参数分别制定填充与步幅 默认stride与窗口的大小相同 1 2 3 4 5 6 7 8 9 10 11 12 X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4)) #转换为4维的输入 X pool2d = nn.MaxPool2d(3) pool2d(X) #只返回一个值 # 其它灵活设置 pool2d = nn.MaxPool2d(3, padding=1, stride=2) pool2d(X) pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1)) pool2d(X) 5.3 多个通道 对于多个通道，汇聚层将在每个通道单独运算，分别作为输出；即输出通道与输入通道数相同。 1 2 3 4 5 6 # 将原有X的第二个维度上，增加一组数据；即两个输入通道 X = torch.cat((X, X + 1), 1) X pool2d = nn.MaxPool2d(3, padding=1, stride=2) pool2d(X) #汇聚后输出通道的数量仍然是2。 6 卷积神经网络(LeNet) 6.1 LeNet LeNet是最早发布的卷积神经网络之一，用于是被图像的手写数字，由AT\u0026T贝尔实验室的研究员Yann LeCun在1989年提出； 主要分为卷积编码器（两个卷积层）与全连接层密集块（三个全连接层）两部分； 1 2 3 4 5 6 7 8 9 10 11 12 13 import torch from torch import nn from d2l import torch as d2l net = nn.Sequential( nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10)) 模型组成特点： 每个卷积层与全连接层（输出层除外）后均连接一个激活函数； 第一个卷积层有6个输出通道，第二个卷积层有16个输出通道； 第一个卷积层通过填充使得输出形状不变，第二个卷积层未使用； 汇聚层的步幅设置使得输出的高宽形状减半； 在接入全连接层之前需要将图像输出展开为一维的形式。 为了构造高性能的卷积神经网络，通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n1 2 3 4 X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32) for layer in net: X = layer(X) print(layer.__class__.__name__,'output shape: \\t',X.shape) 6.2 模型训练 数据迭代器 1 2 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size) 定义GPU版本的准确率评价指标 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def evaluate_accuracy_gpu(net, data_iter, device=None): #@save \"\"\"使用GPU计算模型在数据集上的精度\"\"\" if isinstance(net, nn.Module): net.eval() # 设置为评估模式 if not device: device = next(iter(net.parameters())).device #与模型的device保持一致 # 正确预测的数量，总预测的数量 metric = d2l.Accumulator(2) with torch.no_grad(): for X, y in data_iter: if isinstance(X, list): #判断是否为list # BERT微调所需的（之后将介绍） X = [x.to(device) for x in X] else: X = X.to(device) y = y.to(device) metric.add(d2l.accuracy(net(X), y), y.numel()) return metric[0] / metric[1] 定义GPU版本的训练函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #@save def train_ch6(net, train_iter, test_iter, num_epochs, lr, device): \"\"\"用GPU训练模型(在第六章定义)\"\"\" def init_weights(m): #模型参数初始化 if type(m) == nn.Linear or type(m) == nn.Conv2d: nn.init.xavier_uniform_(m.weight) net.apply(init_weights) print('training on', device) net.to(device) optimizer = torch.optim.SGD(net.parameters(), lr=lr) loss = nn.CrossEntropyLoss() animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['train loss', 'train acc', 'test acc']) timer, num_batches = d2l.Timer(), len(train_iter) for epoch in range(num_epochs): # 训练损失之和，训练准确率之和，样本数 metric = d2l.Accumulator(3) # 训练模型 net.train() for i, (X, y) in enumerate(train_iter): timer.start() optimizer.zero_grad() X, y = X.to(device), y.to(device) y_hat = net(X) l = loss(y_hat, y) l.backward() optimizer.step() with torch.no_grad(): metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) # 下述代码用于可视化 timer.stop() train_l = metric[0] / metric[2] train_acc = metric[1] / metric[2] if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1: animator.add(epoch + (i + 1) / num_batches, (train_l, train_acc, None)) #每次epoch后的测试集评价 test_acc = evaluate_accuracy_gpu(net, test_iter) animator.add(epoch + 1, (None, None, test_acc)) print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, ' f'test acc {test_acc:.3f}') print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec ' f'on {str(device)}') 开始训练 1 2 lr, num_epochs = 0.9, 10 train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ",
  "wordCount" : "4106",
  "inLanguage": "en",
  "datePublished": "2024-08-04T00:00:00Z",
  "dateModified": "2024-08-04T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lishensuo"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lishensuo.github.io/en/posts/bioinfo/709d2l-%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Li's Bioinfo-Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lishensuo.github.io/img/Q.gif"
    }
  }
}
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lishensuo.github.io/en/" accesskey="h" title="Li&#39;s Bioinfo-Blog (Alt + H)">Li&#39;s Bioinfo-Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lishensuo.github.io/en/" title="主页">
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/posts" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/about" title="关于">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/search" title="搜索 (Alt &#43; /)" accesskey=/>
                    <span>搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lishensuo.github.io/en/">Home</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/">分类</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/bioinfo/">📖 生信数据分析--分析流程，工具包等</a></div>
    <h1 class="post-title">
      D2L--第六章卷积神经网络
    </h1>
    <div class="post-meta">













Create:&amp;nbsp;&lt;span title=&#39;2024-08-04 00:00:00 &#43;0000 UTC&#39;&gt;2024-08-04&lt;/span&gt;&amp;nbsp;|&amp;nbsp;Update:&amp;nbsp;2024-08-04&amp;nbsp;|&amp;nbsp;Words:&amp;nbsp;4106&amp;nbsp;|&amp;nbsp;9 min&amp;nbsp;|&amp;nbsp;Lishensuo

|  Viewers: <span id="busuanzi_value_page_pv"></span> 
	  
    </div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#1-%e4%bb%8e%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%b1%82%e5%88%b0%e5%8d%b7%e7%a7%af" aria-label="1. 从全连接层到卷积">1. 从全连接层到卷积</a><ul>
                            
                    <li>
                        <a href="#11-%e4%b8%8d%e5%8f%98%e6%80%a7" aria-label="1.1 不变性">1.1 不变性</a></li>
                    <li>
                        <a href="#12-%e5%a4%9a%e5%b1%82%e6%84%9f%e7%9f%a5%e6%9c%ba%e7%9a%84%e9%99%90%e5%88%b6" aria-label="1.2 多层感知机的限制">1.2 多层感知机的限制</a></li></ul>
                    </li>
                    <li>
                        <a href="#2-%e5%9b%be%e5%83%8f%e5%8d%b7%e7%a7%af" aria-label="2. 图像卷积">2. 图像卷积</a><ul>
                            
                    <li>
                        <a href="#21-%e4%ba%92%e7%9b%b8%e5%85%b3%e8%bf%90%e7%ae%97" aria-label="2.1 互相关运算">2.1 互相关运算</a></li>
                    <li>
                        <a href="#22-%e5%8d%b7%e7%a7%af%e5%b1%82" aria-label="2.2 卷积层">2.2 卷积层</a></li>
                    <li>
                        <a href="#23-%e5%9b%be%e5%83%8f%e4%b8%ad%e7%9b%ae%e6%a0%87%e7%9a%84%e8%be%b9%e7%bc%98%e6%a3%80%e6%b5%8b" aria-label="2.3 图像中目标的边缘检测">2.3 图像中目标的边缘检测</a></li>
                    <li>
                        <a href="#24-%e5%ad%a6%e4%b9%a0%e5%8d%b7%e7%a7%af%e6%a0%b8" aria-label="2.4 学习卷积核">2.4 学习卷积核</a></li></ul>
                    </li>
                    <li>
                        <a href="#3-%e5%a1%ab%e5%85%85%e5%92%8c%e6%ad%a5%e5%b9%85" aria-label="3. 填充和步幅">3. 填充和步幅</a><ul>
                            
                    <li>
                        <a href="#31-%e5%a1%ab%e5%85%85" aria-label="3.1 填充">3.1 填充</a></li>
                    <li>
                        <a href="#32-%e6%ad%a5%e5%b9%85" aria-label="3.2 步幅">3.2 步幅</a></li></ul>
                    </li>
                    <li>
                        <a href="#4-%e5%a4%9a%e8%be%93%e5%85%a5%e5%a4%9a%e8%be%93%e5%87%ba%e9%80%9a%e9%81%93" aria-label="4. 多输入多输出通道">4. 多输入多输出通道</a><ul>
                            
                    <li>
                        <a href="#41-%e5%a4%9a%e8%be%93%e5%85%a5%e9%80%9a%e9%81%93" aria-label="4.1 多输入通道">4.1 多输入通道</a></li>
                    <li>
                        <a href="#42-%e5%a4%9a%e8%be%93%e5%87%ba%e9%80%9a%e9%81%93" aria-label="4.2 多输出通道">4.2 多输出通道</a></li>
                    <li>
                        <a href="#43-11%e5%8d%b7%e7%a7%af%e5%b1%82" aria-label="4.3 1×1卷积层">4.3 1×1卷积层</a></li></ul>
                    </li>
                    <li>
                        <a href="#5-%e6%b1%87%e8%81%9a%e5%b1%82" aria-label="5. 汇聚层">5. 汇聚层</a><ul>
                            
                    <li>
                        <a href="#51-%e6%9c%80%e5%a4%a7%e6%b1%87%e8%81%9a%e5%b1%82%e5%92%8c%e5%b9%b3%e5%9d%87%e6%b1%87%e8%81%9a%e5%b1%82" aria-label="5.1 最大汇聚层和平均汇聚层">5.1 最大汇聚层和平均汇聚层</a></li>
                    <li>
                        <a href="#52-%e5%a1%ab%e5%85%85%e5%92%8c%e6%ad%a5%e5%b9%85" aria-label="5.2 填充和步幅">5.2 填充和步幅</a></li>
                    <li>
                        <a href="#53-%e5%a4%9a%e4%b8%aa%e9%80%9a%e9%81%93" aria-label="5.3 多个通道">5.3 多个通道</a></li></ul>
                    </li>
                    <li>
                        <a href="#6-%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9clenet" aria-label="6 卷积神经网络(LeNet)">6 卷积神经网络(LeNet)</a><ul>
                            
                    <li>
                        <a href="#61-lenet" aria-label="6.1 LeNet">6.1 LeNet</a></li>
                    <li>
                        <a href="#62-%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83" aria-label="6.2 模型训练">6.2 模型训练</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>


  <div class="post-content"><h1 id="1-从全连接层到卷积">1. 从全连接层到卷积<a hidden class="anchor" aria-hidden="true" href="#1-从全连接层到卷积">#</a></h1>
<h2 id="11-不变性">1.1 不变性<a hidden class="anchor" aria-hidden="true" href="#11-不变性">#</a></h2>
<p>假设一个场景：需要制作一个检测器，在一张图片中检测一种特定物体。需要满足两个性质：</p>
<ol>
<li>平移不变性：无论该物品在图片的哪个位置，都可以检测到；</li>
<li>局部性：检测器只需要关注图像中的局部区域，不过度关注其它无关区域。</li>
</ol>
<h2 id="12-多层感知机的限制">1.2 多层感知机的限制<a hidden class="anchor" aria-hidden="true" href="#12-多层感知机的限制">#</a></h2>
<ul>
<li>对于图片（例如12M）像素的<strong>一维展开</strong>，包含36M的元素。若使用包含100个神经元的单隐藏层，模型就要3.6B元素，训练难度过大。</li>
<li><strong>卷积</strong>(convolution)计算：输入<strong>X</strong>为二维矩阵，输出的隐藏表示<strong>H</strong>仍为矩阵。参数包括权重矩阵<strong>V</strong>与偏置<strong>U</strong>。<strong>H</strong>中的每一个元素都由权重矩阵<strong>V</strong>与输入<strong>X</strong>中相应区域元素的&rsquo;点积&rsquo;，再加上偏置所得到。（下图演示忽略了偏置计算）
<ul>
<li><strong>平移不变性</strong>：权重矩阵（又称为卷积核/滤波器）在每次计算中保持不变，以提取相同的模式。</li>
<li><strong>局部性</strong>：卷积核(kernel)的形状通常较小(|a|&gt;△;|b|&gt;△)，即针对输入的局部区域进行特征提取。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="C:%5cUsers%5cxiaoxin%5cAppData%5cRoaming%5cTypora%5ctypora-user-images%5cimage-20240731113235058.png" alt="image-20240731113235058"  />
</p>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:1400/1*n76q1X-S-hF6zbNQOtPRug.gif" alt="卷積神經網絡Convolutional Neural Network (CNN) | by 李謦伊| 謦伊的閱讀筆記| Medium"  />
</p>
<ul>
<li>如上计算中，模型参数的数量比全连接层参数少很多，降低了训练难度。</li>
</ul>
<h1 id="2-图像卷积">2. 图像卷积<a hidden class="anchor" aria-hidden="true" href="#2-图像卷积">#</a></h1>
<h2 id="21-互相关运算">2.1 互相关运算<a hidden class="anchor" aria-hidden="true" href="#21-互相关运算">#</a></h2>
<ul>
<li>CNN中的卷积与数学中的卷积概念不完全相同，本质上为互相关运算(cross-correlation)</li>
<li>如下图，输入是3×3的二维张量；卷积核的高和宽都是2：
<ul>
<li>卷积窗口从输入的左上角开始，从左到右，从上到下滑动；</li>
<li>每次按对应位置的元素相乘，再求和得到单个标量结果；</li>
<li>按上述规则滑动的计算结果，输出形状将小于输入形状。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731123437491.png" alt="image-20240731123437491"  />
</p>
<blockquote>
<p>输出结果有时被称为特征映射。对于输出结果中的任一元素，其感受野指上一层中所有参与计算的输入元素。</p></blockquote>
<ul>
<li>手动代码实现互相关运算</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> corr2d(X, K):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;计算二维互相关运算&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    h, w = K.shape
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#定义输出的形状</span>
</span></span><span style="display:flex;"><span>    Y = torch.zeros((X.shape[<span style="color:#ff0;font-weight:bold">0</span>] - h + <span style="color:#ff0;font-weight:bold">1</span>, X.shape[<span style="color:#ff0;font-weight:bold">1</span>] - w + <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#遍历每次滑动</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(Y.shape[<span style="color:#ff0;font-weight:bold">0</span>]):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> j in <span style="color:#fff;font-weight:bold">range</span>(Y.shape[<span style="color:#ff0;font-weight:bold">1</span>]):
</span></span><span style="display:flex;"><span>            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> Y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 输入</span>
</span></span><span style="display:flex;"><span>X = torch.tensor([[<span style="color:#ff0;font-weight:bold">0.0</span>, <span style="color:#ff0;font-weight:bold">1.0</span>, <span style="color:#ff0;font-weight:bold">2.0</span>], [<span style="color:#ff0;font-weight:bold">3.0</span>, <span style="color:#ff0;font-weight:bold">4.0</span>, <span style="color:#ff0;font-weight:bold">5.0</span>], [<span style="color:#ff0;font-weight:bold">6.0</span>, <span style="color:#ff0;font-weight:bold">7.0</span>, <span style="color:#ff0;font-weight:bold">8.0</span>]])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 卷积核</span>
</span></span><span style="display:flex;"><span>K = torch.tensor([[<span style="color:#ff0;font-weight:bold">0.0</span>, <span style="color:#ff0;font-weight:bold">1.0</span>], [<span style="color:#ff0;font-weight:bold">2.0</span>, <span style="color:#ff0;font-weight:bold">3.0</span>]])
</span></span><span style="display:flex;"><span>corr2d(X, K)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="22-卷积层">2.2 卷积层<a hidden class="anchor" aria-hidden="true" href="#22-卷积层">#</a></h2>
<ul>
<li>如前所述，卷积层中的两个被训练的参数是卷积核权重和标量偏置，在训练时，会被随机初始化；</li>
<li>基于上述互相关运算函数，手动定义一个二维卷积层</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Conv2D(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, kernel_size):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>().__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.weight = nn.Parameter(torch.rand(kernel_size))
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.bias = nn.Parameter(torch.zeros(<span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, x):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> corr2d(x, <span style="color:#fff;font-weight:bold">self</span>.weight) + <span style="color:#fff;font-weight:bold">self</span>.bias
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="23-图像中目标的边缘检测">2.3 图像中目标的边缘检测<a hidden class="anchor" aria-hidden="true" href="#23-图像中目标的边缘检测">#</a></h2>
<ul>
<li>卷积层的简单应用：根据像素变化的位置，检测图像中不同颜色的边缘。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#007f7f"># 输入数据：下图左</span>
</span></span><span style="display:flex;"><span>X = torch.ones((<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">8</span>))
</span></span><span style="display:flex;"><span>X[:, <span style="color:#ff0;font-weight:bold">2</span>:<span style="color:#ff0;font-weight:bold">6</span>] = <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 卷积核</span>
</span></span><span style="display:flex;"><span>K = torch.tensor([[<span style="color:#ff0;font-weight:bold">1.0</span>, -<span style="color:#ff0;font-weight:bold">1.0</span>]])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 卷积计算：下图右</span>
</span></span><span style="display:flex;"><span>Y = corr2d(X, K)
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731130517874.png" alt="image-20240731130517874"  />
</p>
<h2 id="24-学习卷积核">2.4 学习卷积核<a hidden class="anchor" aria-hidden="true" href="#24-学习卷积核">#</a></h2>
<ul>
<li>可通过torch的<code>nn.Conv2d</code>类快速定义一个卷积层
<ul>
<li>该类的前两个参数分别用于设置输入与输出通道数；</li>
<li>kernel_size参数用于指定卷积核的高和宽。</li>
</ul>
</li>
<li>如下代码，将根据上述的输入X与输出Y，学习卷积核</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核</span>
</span></span><span style="display:flex;"><span>conv2d = nn.Conv2d(<span style="color:#ff0;font-weight:bold">1</span>,<span style="color:#ff0;font-weight:bold">1</span>, kernel_size=(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">2</span>), bias=<span style="color:#fff;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 其中批量大小和通道数都为1</span>
</span></span><span style="display:flex;"><span>X = X.reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">8</span>)) <span style="color:#007f7f">#示例输入</span>
</span></span><span style="display:flex;"><span>Y = Y.reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">7</span>)) <span style="color:#007f7f">#示例输出</span>
</span></span><span style="display:flex;"><span>lr = <span style="color:#ff0;font-weight:bold">3e-2</span>  <span style="color:#007f7f"># 学习率</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">10</span>):
</span></span><span style="display:flex;"><span>    Y_hat = conv2d(X)
</span></span><span style="display:flex;"><span>    l = (Y_hat - Y) ** <span style="color:#ff0;font-weight:bold">2</span> <span style="color:#007f7f">#预测的平方损失</span>
</span></span><span style="display:flex;"><span>    conv2d.zero_grad()
</span></span><span style="display:flex;"><span>    l.sum().backward()
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 迭代卷积核</span>
</span></span><span style="display:flex;"><span>    conv2d.weight.data[:] -= lr * conv2d.weight.grad
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> (i + <span style="color:#ff0;font-weight:bold">1</span>) % <span style="color:#ff0;font-weight:bold">2</span> == <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;epoch </span><span style="color:#0ff;font-weight:bold">{</span>i+<span style="color:#ff0;font-weight:bold">1</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, loss </span><span style="color:#0ff;font-weight:bold">{</span>l.sum()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>conv2d.weight.data.reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># tensor([[ 0.9938, -0.9841]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="3-填充和步幅">3. 填充和步幅<a hidden class="anchor" aria-hidden="true" href="#3-填充和步幅">#</a></h1>
<h2 id="31-填充">3.1 填充<a hidden class="anchor" aria-hidden="true" href="#31-填充">#</a></h2>
<ul>
<li>可在输入图像的边界填充元素（通常为0），使得经卷积计算后的输出形状变大；</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731132928512.png" alt="image-20240731132928512"  />
</p>
<ul>
<li>当卷积核的高宽为<strong>奇数</strong>（推荐）时，若填充的行数（一半在顶，一半在底）与列数（一半在左，一半在右）与卷积核的<strong>高宽少1</strong>，则输入与输出的形状相同。</li>
<li>可通过nn.Conv2d类的padding参数设置填充。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 为了方便起见，我们定义了一个计算卷积层的函数。</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> comp_conv2d(conv2d, X):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 这里的（1，1）表示批量大小和通道数都是1</span>
</span></span><span style="display:flex;"><span>    X = X.reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>) + X.shape)  <span style="color:#007f7f">#(1, 1) + X.shape 长度为4的tuple</span>
</span></span><span style="display:flex;"><span>    Y = conv2d(X)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 省略前两个维度：批量大小和通道</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> Y.reshape(Y.shape[<span style="color:#ff0;font-weight:bold">2</span>:])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列</span>
</span></span><span style="display:flex;"><span>conv2d = nn.Conv2d(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, kernel_size=<span style="color:#ff0;font-weight:bold">3</span>, padding=<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X = torch.rand(size=(<span style="color:#ff0;font-weight:bold">8</span>, <span style="color:#ff0;font-weight:bold">8</span>))
</span></span><span style="display:flex;"><span>comp_conv2d(conv2d, X).shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([8, 8])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="32-步幅">3.2 步幅<a hidden class="anchor" aria-hidden="true" href="#32-步幅">#</a></h2>
<ul>
<li>在上述示例中，卷积窗口滑动的长度（步幅）为1；</li>
<li>为了高效计算或是缩减采样次数，可增大滑动的幅度；</li>
<li>当卷积核高宽为奇数，且填充比卷积核形状少1时，则输出的形状大小为<strong>输入形状除以步幅</strong>；</li>
<li>可通过nn.Conv2d类的stride参数设置</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>conv2d = nn.Conv2d(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, kernel_size=<span style="color:#ff0;font-weight:bold">3</span>, padding=<span style="color:#ff0;font-weight:bold">1</span>, stride=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>comp_conv2d(conv2d, X).shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([4, 4])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="4-多输入多输出通道">4. 多输入多输出通道<a hidden class="anchor" aria-hidden="true" href="#4-多输入多输出通道">#</a></h1>
<h2 id="41-多输入通道">4.1 多输入通道<a hidden class="anchor" aria-hidden="true" href="#41-多输入通道">#</a></h2>
<ul>
<li>图片通常包含三个通道（红绿蓝三原色），即输入数据有三个维度。其中，前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示。</li>
<li>此时，每个通道都有一个卷积核，最后的输出是所有通道卷积结果的和。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731142412991.png" alt="image-20240731142412991"  />
</p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># X表示多通道输入</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># K表示多通道卷积核</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> corr2d_multi_in(X, K):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">sum</span>(d2l.corr2d(x, k) <span style="color:#fff;font-weight:bold">for</span> x, k in <span style="color:#fff;font-weight:bold">zip</span>(X, K))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X = torch.tensor([[[<span style="color:#ff0;font-weight:bold">0.0</span>, <span style="color:#ff0;font-weight:bold">1.0</span>, <span style="color:#ff0;font-weight:bold">2.0</span>], [<span style="color:#ff0;font-weight:bold">3.0</span>, <span style="color:#ff0;font-weight:bold">4.0</span>, <span style="color:#ff0;font-weight:bold">5.0</span>], [<span style="color:#ff0;font-weight:bold">6.0</span>, <span style="color:#ff0;font-weight:bold">7.0</span>, <span style="color:#ff0;font-weight:bold">8.0</span>]],
</span></span><span style="display:flex;"><span>               [[<span style="color:#ff0;font-weight:bold">1.0</span>, <span style="color:#ff0;font-weight:bold">2.0</span>, <span style="color:#ff0;font-weight:bold">3.0</span>], [<span style="color:#ff0;font-weight:bold">4.0</span>, <span style="color:#ff0;font-weight:bold">5.0</span>, <span style="color:#ff0;font-weight:bold">6.0</span>], [<span style="color:#ff0;font-weight:bold">7.0</span>, <span style="color:#ff0;font-weight:bold">8.0</span>, <span style="color:#ff0;font-weight:bold">9.0</span>]]])
</span></span><span style="display:flex;"><span>K = torch.tensor([[[<span style="color:#ff0;font-weight:bold">0.0</span>, <span style="color:#ff0;font-weight:bold">1.0</span>], [<span style="color:#ff0;font-weight:bold">2.0</span>, <span style="color:#ff0;font-weight:bold">3.0</span>]], [[<span style="color:#ff0;font-weight:bold">1.0</span>, <span style="color:#ff0;font-weight:bold">2.0</span>], [<span style="color:#ff0;font-weight:bold">3.0</span>, <span style="color:#ff0;font-weight:bold">4.0</span>]]])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>corr2d_multi_in(X, K)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="42-多输出通道">4.2 多输出通道<a hidden class="anchor" aria-hidden="true" href="#42-多输出通道">#</a></h2>
<ul>
<li>在上述的多通道输入中，每个通道只有一个卷积核，最后得到一个通道的输出；</li>
<li>可以在每个通道中建立多个(o)卷积核。此时，对于i个输入通道，就共有o × i个卷积核；</li>
<li>然后按照4.1计算方法，可以得到o个输出通道的结果；</li>
<li>如下，i=1，o=4</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240804113644154.png" alt="image-20240804113644154" style="zoom: 67%;" />
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># X表示多通道输入</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># K表示多通道卷积核【4个维度】</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> corr2d_multi_in_out(X, K):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 最后将所有结果都叠加在一起(沿新的第一维度（dim=0）堆叠起来)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> torch.stack([corr2d_multi_in(X, k) <span style="color:#fff;font-weight:bold">for</span> k in K], <span style="color:#ff0;font-weight:bold">0</span>) <span style="color:#007f7f">#k三个维度，参考4.1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 之前的K是三维的多个(等于对应通道数)卷积核</span>
</span></span><span style="display:flex;"><span>K = torch.stack((K, K + <span style="color:#ff0;font-weight:bold">1</span>, K + <span style="color:#ff0;font-weight:bold">2</span>), <span style="color:#ff0;font-weight:bold">0</span>)
</span></span><span style="display:flex;"><span>K.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([3, 2, 2, 2])</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># i=2; o=3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>corr2d_multi_in_out(X, K).shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([3, 2, 2])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>可以将每个输出通道认为是提取的一种特征模式，供下一神经网络层组合学习。(<a href="https://poloclub.github.io/cnn-explainer/">https://poloclub.github.io/cnn-explainer/</a>)</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240804114145239.png" alt="image-20240804114145239"  />
</p></blockquote>
<h2 id="43-11卷积层">4.3 1×1卷积层<a hidden class="anchor" aria-hidden="true" href="#43-11卷积层">#</a></h2>
<ul>
<li>卷积的本质是有效提取相邻像素间的相关特征，而1×1卷积显然没有此作用；</li>
<li>1×1卷积受欢迎的原因是作为融合通道使用，直观上是改变了输入通道的数量。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731150756245.png" alt="image-20240731150756245"  />
</p>
<ul>
<li>代码实现</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#从全连接层的角度，实现1×1卷积</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> corr2d_multi_in_out_1x1(X, K):
</span></span><span style="display:flex;"><span>    c_i, h, w = X.shape
</span></span><span style="display:flex;"><span>    c_o = K.shape[<span style="color:#ff0;font-weight:bold">0</span>]
</span></span><span style="display:flex;"><span>    X = X.reshape((c_i, h * w)) <span style="color:#007f7f">#每个通道拉平为一个向量，此时X为一个矩阵</span>
</span></span><span style="display:flex;"><span>    K = K.reshape((c_o, c_i))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 全连接层中的矩阵乘法</span>
</span></span><span style="display:flex;"><span>    Y = torch.matmul(K, X)  <span style="color:#007f7f">#(c_o, h * w)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> Y.reshape((c_o, h, w))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X = torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">3</span>)) <span style="color:#007f7f">#3个输入通道</span>
</span></span><span style="display:flex;"><span>K = torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>)) <span style="color:#007f7f">#2×3个卷积核</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y1 = corr2d_multi_in_out_1x1(X, K)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#按常规卷积层角度的实现</span>
</span></span><span style="display:flex;"><span>Y2 = corr2d_multi_in_out(X, K)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">assert</span> <span style="color:#fff;font-weight:bold">float</span>(torch.abs(Y1 - Y2).sum()) &lt; <span style="color:#ff0;font-weight:bold">1e-6</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="5-汇聚层">5. 汇聚层<a hidden class="anchor" aria-hidden="true" href="#5-汇聚层">#</a></h1>
<h2 id="51-最大汇聚层和平均汇聚层">5.1 最大汇聚层和平均汇聚层<a hidden class="anchor" aria-hidden="true" href="#51-最大汇聚层和平均汇聚层">#</a></h2>
<ul>
<li>汇聚层(pooling)又称池化层，降低卷积层对位置的敏感性。</li>
<li>它与卷积操作类似，由一个固定窗口组成，在输入数据中滑动，并计算得到输出。</li>
<li>不同之处在于，汇聚层没有学习参数，为确定性计算；主要分为如下两种
<ul>
<li>最大汇聚层：汇聚窗口覆盖区域内的最大值；</li>
<li>平均汇聚层：汇聚窗口覆盖区域内的平均值；</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240731231553212.png" alt="image-20240731231553212"  />
</p>
<ul>
<li>手动代码实现（类似上述的2.1处）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> pool2d(X, pool_size, mode=<span style="color:#0ff;font-weight:bold">&#39;max&#39;</span>):
</span></span><span style="display:flex;"><span>    p_h, p_w = pool_size
</span></span><span style="display:flex;"><span>    Y = torch.zeros((X.shape[<span style="color:#ff0;font-weight:bold">0</span>] - p_h + <span style="color:#ff0;font-weight:bold">1</span>, X.shape[<span style="color:#ff0;font-weight:bold">1</span>] - p_w + <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(Y.shape[<span style="color:#ff0;font-weight:bold">0</span>]):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> j in <span style="color:#fff;font-weight:bold">range</span>(Y.shape[<span style="color:#ff0;font-weight:bold">1</span>]):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> mode == <span style="color:#0ff;font-weight:bold">&#39;max&#39;</span>:
</span></span><span style="display:flex;"><span>                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">elif</span> mode == <span style="color:#0ff;font-weight:bold">&#39;avg&#39;</span>:
</span></span><span style="display:flex;"><span>                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> Y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X = torch.tensor([[<span style="color:#ff0;font-weight:bold">0.0</span>, <span style="color:#ff0;font-weight:bold">1.0</span>, <span style="color:#ff0;font-weight:bold">2.0</span>], [<span style="color:#ff0;font-weight:bold">3.0</span>, <span style="color:#ff0;font-weight:bold">4.0</span>, <span style="color:#ff0;font-weight:bold">5.0</span>], [<span style="color:#ff0;font-weight:bold">6.0</span>, <span style="color:#ff0;font-weight:bold">7.0</span>, <span style="color:#ff0;font-weight:bold">8.0</span>]])
</span></span><span style="display:flex;"><span>pool2d(X, (<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>pool2d(X, (<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>), <span style="color:#0ff;font-weight:bold">&#39;avg&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="52-填充和步幅">5.2 填充和步幅<a hidden class="anchor" aria-hidden="true" href="#52-填充和步幅">#</a></h2>
<ul>
<li>默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同（即每次滑动区域没有重叠）；</li>
<li>可设置nn.MaxPool2d/nn.AvgPool2d类的参数：
<ul>
<li>第一个参数为窗口的大小</li>
<li>padding与stride参数分别制定填充与步幅</li>
<li>默认stride与窗口的大小相同</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X = torch.arange(<span style="color:#ff0;font-weight:bold">16</span>, dtype=torch.float32).reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">4</span>)) <span style="color:#007f7f">#转换为4维的输入</span>
</span></span><span style="display:flex;"><span>X
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pool2d = nn.MaxPool2d(<span style="color:#ff0;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>pool2d(X) <span style="color:#007f7f">#只返回一个值</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 其它灵活设置</span>
</span></span><span style="display:flex;"><span>pool2d = nn.MaxPool2d(<span style="color:#ff0;font-weight:bold">3</span>, padding=<span style="color:#ff0;font-weight:bold">1</span>, stride=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>pool2d(X) 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pool2d = nn.MaxPool2d((<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">3</span>), stride=(<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">3</span>), padding=(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>pool2d(X)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="53-多个通道">5.3 多个通道<a hidden class="anchor" aria-hidden="true" href="#53-多个通道">#</a></h2>
<ul>
<li>对于多个通道，汇聚层将在每个通道单独运算，分别作为输出；即输出通道与输入通道数相同。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 将原有X的第二个维度上，增加一组数据；即两个输入通道</span>
</span></span><span style="display:flex;"><span>X = torch.cat((X, X + <span style="color:#ff0;font-weight:bold">1</span>), <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>X
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pool2d = nn.MaxPool2d(<span style="color:#ff0;font-weight:bold">3</span>, padding=<span style="color:#ff0;font-weight:bold">1</span>, stride=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>pool2d(X) <span style="color:#007f7f">#汇聚后输出通道的数量仍然是2。</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="6-卷积神经网络lenet">6 卷积神经网络(LeNet)<a hidden class="anchor" aria-hidden="true" href="#6-卷积神经网络lenet">#</a></h1>
<h2 id="61-lenet">6.1 LeNet<a hidden class="anchor" aria-hidden="true" href="#61-lenet">#</a></h2>
<ul>
<li>LeNet是最早发布的卷积神经网络之一，用于是被图像的手写数字，由AT&amp;T贝尔实验室的研究员Yann LeCun在1989年提出；</li>
<li>主要分为卷积编码器（两个卷积层）与全连接层密集块（三个全连接层）两部分；</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240801211808356.png" alt="image-20240801211808356"  />
</p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>net = nn.Sequential(
</span></span><span style="display:flex;"><span>    nn.Conv2d(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">6</span>, kernel_size=<span style="color:#ff0;font-weight:bold">5</span>, padding=<span style="color:#ff0;font-weight:bold">2</span>), nn.Sigmoid(),
</span></span><span style="display:flex;"><span>    nn.AvgPool2d(kernel_size=<span style="color:#ff0;font-weight:bold">2</span>, stride=<span style="color:#ff0;font-weight:bold">2</span>),
</span></span><span style="display:flex;"><span>    nn.Conv2d(<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">16</span>, kernel_size=<span style="color:#ff0;font-weight:bold">5</span>), nn.Sigmoid(),
</span></span><span style="display:flex;"><span>    nn.AvgPool2d(kernel_size=<span style="color:#ff0;font-weight:bold">2</span>, stride=<span style="color:#ff0;font-weight:bold">2</span>),
</span></span><span style="display:flex;"><span>    nn.Flatten(),
</span></span><span style="display:flex;"><span>    nn.Linear(<span style="color:#ff0;font-weight:bold">16</span> * <span style="color:#ff0;font-weight:bold">5</span> * <span style="color:#ff0;font-weight:bold">5</span>, <span style="color:#ff0;font-weight:bold">120</span>), nn.Sigmoid(),
</span></span><span style="display:flex;"><span>    nn.Linear(<span style="color:#ff0;font-weight:bold">120</span>, <span style="color:#ff0;font-weight:bold">84</span>), nn.Sigmoid(),
</span></span><span style="display:flex;"><span>    nn.Linear(<span style="color:#ff0;font-weight:bold">84</span>, <span style="color:#ff0;font-weight:bold">10</span>))
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>模型组成特点：
<ul>
<li>每个卷积层与全连接层（输出层除外）后均连接一个激活函数；</li>
<li>第一个卷积层有6个输出通道，第二个卷积层有16个输出通道；</li>
<li>第一个卷积层通过填充使得输出形状不变，第二个卷积层未使用；</li>
<li>汇聚层的步幅设置使得输出的高宽形状减半；</li>
<li>在接入全连接层之前需要将图像输出展开为一维的形式。</li>
</ul>
</li>
</ul>
<blockquote>
<p>为了构造高性能的卷积神经网络，通常对卷积层进行排列，逐渐<strong>降低其表示的空间分辨率</strong>，同时<strong>增加通道数</strong>。</p></blockquote>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X = torch.rand(size=(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">28</span>, <span style="color:#ff0;font-weight:bold">28</span>), dtype=torch.float32)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> layer in net:
</span></span><span style="display:flex;"><span>    X = layer(X)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(layer.__class__.__name__,<span style="color:#0ff;font-weight:bold">&#39;output shape: </span><span style="color:#0ff;font-weight:bold">\t</span><span style="color:#0ff;font-weight:bold">&#39;</span>,X.shape)
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240801221129822.png" alt="image-20240801221129822"  />
</p>
<h2 id="62-模型训练">6.2 模型训练<a hidden class="anchor" aria-hidden="true" href="#62-模型训练">#</a></h2>
<ul>
<li>数据迭代器</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>batch_size = <span style="color:#ff0;font-weight:bold">256</span>
</span></span><span style="display:flex;"><span>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义GPU版本的准确率评价指标</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> evaluate_accuracy_gpu(net, data_iter, device=<span style="color:#fff;font-weight:bold">None</span>): <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;使用GPU计算模型在数据集上的精度&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(net, nn.Module):
</span></span><span style="display:flex;"><span>        net.eval()  <span style="color:#007f7f"># 设置为评估模式</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> not device:
</span></span><span style="display:flex;"><span>            device = <span style="color:#fff;font-weight:bold">next</span>(<span style="color:#fff;font-weight:bold">iter</span>(net.parameters())).device <span style="color:#007f7f">#与模型的device保持一致</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 正确预测的数量，总预测的数量</span>
</span></span><span style="display:flex;"><span>    metric = d2l.Accumulator(<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">with</span> torch.no_grad():
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> X, y in data_iter:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(X, <span style="color:#fff;font-weight:bold">list</span>): <span style="color:#007f7f">#判断是否为list</span>
</span></span><span style="display:flex;"><span>                <span style="color:#007f7f"># BERT微调所需的（之后将介绍）</span>
</span></span><span style="display:flex;"><span>                X = [x.to(device) <span style="color:#fff;font-weight:bold">for</span> x in X]
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>                X = X.to(device)
</span></span><span style="display:flex;"><span>            y = y.to(device)
</span></span><span style="display:flex;"><span>            metric.add(d2l.accuracy(net(X), y), y.numel())
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> metric[<span style="color:#ff0;font-weight:bold">0</span>] / metric[<span style="color:#ff0;font-weight:bold">1</span>]
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义GPU版本的训练函数</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">43
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;用GPU训练模型(在第六章定义)&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> init_weights(m):  <span style="color:#007f7f">#模型参数初始化</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) == nn.Linear or <span style="color:#fff;font-weight:bold">type</span>(m) == nn.Conv2d:
</span></span><span style="display:flex;"><span>            nn.init.xavier_uniform_(m.weight)
</span></span><span style="display:flex;"><span>    net.apply(init_weights)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;training on&#39;</span>, device)
</span></span><span style="display:flex;"><span>    net.to(device)
</span></span><span style="display:flex;"><span>    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
</span></span><span style="display:flex;"><span>    loss = nn.CrossEntropyLoss()
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(xlabel=<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, xlim=[<span style="color:#ff0;font-weight:bold">1</span>, num_epochs],
</span></span><span style="display:flex;"><span>                            legend=[<span style="color:#0ff;font-weight:bold">&#39;train loss&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;train acc&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;test acc&#39;</span>])
</span></span><span style="display:flex;"><span>    timer, num_batches = d2l.Timer(), <span style="color:#fff;font-weight:bold">len</span>(train_iter)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 训练损失之和，训练准确率之和，样本数</span>
</span></span><span style="display:flex;"><span>        metric = d2l.Accumulator(<span style="color:#ff0;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 训练模型</span>
</span></span><span style="display:flex;"><span>        net.train()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> i, (X, y) in <span style="color:#fff;font-weight:bold">enumerate</span>(train_iter):
</span></span><span style="display:flex;"><span>            timer.start()
</span></span><span style="display:flex;"><span>            optimizer.zero_grad()
</span></span><span style="display:flex;"><span>            X, y = X.to(device), y.to(device)
</span></span><span style="display:flex;"><span>            y_hat = net(X)
</span></span><span style="display:flex;"><span>            l = loss(y_hat, y)
</span></span><span style="display:flex;"><span>            l.backward()
</span></span><span style="display:flex;"><span>            optimizer.step()
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">with</span> torch.no_grad():
</span></span><span style="display:flex;"><span>                metric.add(l * X.shape[<span style="color:#ff0;font-weight:bold">0</span>], d2l.accuracy(y_hat, y), X.shape[<span style="color:#ff0;font-weight:bold">0</span>])
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># 下述代码用于可视化</span>
</span></span><span style="display:flex;"><span>            timer.stop()
</span></span><span style="display:flex;"><span>            train_l = metric[<span style="color:#ff0;font-weight:bold">0</span>] / metric[<span style="color:#ff0;font-weight:bold">2</span>]
</span></span><span style="display:flex;"><span>            train_acc = metric[<span style="color:#ff0;font-weight:bold">1</span>] / metric[<span style="color:#ff0;font-weight:bold">2</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> (i + <span style="color:#ff0;font-weight:bold">1</span>) % (num_batches // <span style="color:#ff0;font-weight:bold">5</span>) == <span style="color:#ff0;font-weight:bold">0</span> or i == num_batches - <span style="color:#ff0;font-weight:bold">1</span>:
</span></span><span style="display:flex;"><span>                animator.add(epoch + (i + <span style="color:#ff0;font-weight:bold">1</span>) / num_batches,
</span></span><span style="display:flex;"><span>                             (train_l, train_acc, <span style="color:#fff;font-weight:bold">None</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f">#每次epoch后的测试集评价</span>
</span></span><span style="display:flex;"><span>        test_acc = evaluate_accuracy_gpu(net, test_iter)
</span></span><span style="display:flex;"><span>        animator.add(epoch + <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#fff;font-weight:bold">None</span>, <span style="color:#fff;font-weight:bold">None</span>, test_acc))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;loss </span><span style="color:#0ff;font-weight:bold">{</span>train_l<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, train acc </span><span style="color:#0ff;font-weight:bold">{</span>train_acc<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, &#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;test acc </span><span style="color:#0ff;font-weight:bold">{</span>test_acc<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">{</span>metric[<span style="color:#ff0;font-weight:bold">2</span>] * num_epochs / timer.sum()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold"> examples/sec &#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;on </span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">str</span>(device)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>开始训练</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>lr, num_epochs = <span style="color:#ff0;font-weight:bold">0.9</span>, <span style="color:#ff0;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lishensuo.github.io/en/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
      <li><a href="https://lishensuo.github.io/en/tags/d2l/">D2L</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lishensuo.github.io/en/posts/bioinfo/708d2l-%E7%AC%AC%E4%BA%94%E7%AB%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97/">
    <span class="title">« Prev Page</span>
    <br>
    <span>D2L--第五章深度学习计算</span>
  </a>
  <a class="next" href="https://lishensuo.github.io/en/posts/bioinfo/710d2l-%E7%AC%AC%E4%B8%83%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
    <span class="title">Next Page »</span>
    <br>
    <span>D2L--第七章现代卷积神经网络</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lishensuo.github.io/en/">Li&#39;s Bioinfo-Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
		<br/>您是本站第 <span id="busuanzi_value_site_uv"></span> 位访问者，总浏览量为 <span id="busuanzi_value_site_pv"></span> 次
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>

<script type="text/javascript"
async
src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
displayMath: [['$$','$$'], ['\[\[','\]\]']],
processEscapes: true,
processEnvironments: true,
skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
TeX: { equationNumbers: { autoNumber: "AMS" },
extensions: ["AMSmath.js", "AMSsymbols.js"] }
}
});

MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style></body>
</html>

<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">

<link rel="icon" href="/favicon.ico" type="image/x-icon"> 
<title>D2L--第八章循环神经网络 | Li&#39;s Bioinfo-Blog</title>
<meta name="keywords" content="深度学习, D2L">
<meta name="description" content="1. 序列模型
1.1 自回归模型
（1）自回归模型：对于一个包含T个&rsquo;时间&rsquo;节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据">
<meta name="author" content="Lishensuo">
<link rel="canonical" href="https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.9e4de5e3ba61ea358168341aa7cdf70abfaafb7c697dfe8624af3ddff9a35c2f.css" integrity="sha256-nk3l47ph6jWBaDQap833Cr&#43;q&#43;3xpff6GJK893/mjXC8=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.555af97124d54bb1457985dd081b8f5616a48103aafeb30ac89fde835d65aa6c.js" integrity="sha256-VVr5cSTVS7FFeYXdCBuPVhakgQOq/rMKyJ/eg11lqmw="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://lishensuo.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://lishensuo.github.io/Q.gif">
<link rel="mask-icon" href="https://lishensuo.github.io/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="D2L--第八章循环神经网络" />
<meta property="og:description" content="1. 序列模型
1.1 自回归模型
（1）自回归模型：对于一个包含T个&rsquo;时间&rsquo;节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-11T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-08-11T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="D2L--第八章循环神经网络"/>
<meta name="twitter:description" content="1. 序列模型
1.1 自回归模型
（1）自回归模型：对于一个包含T个&rsquo;时间&rsquo;节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "分类",
      "item": "https://lishensuo.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📖 生信数据分析--分析流程，工具包等",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "D2L--第八章循环神经网络",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "D2L--第八章循环神经网络",
  "name": "D2L--第八章循环神经网络",
  "description": "1. 序列模型 1.1 自回归模型 （1）自回归模型：对于一个包含T个\u0026rsquo;时间\u0026rsquo;节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据\n",
  "keywords": [
    "深度学习", "D2L"
  ],
  "articleBody": "1. 序列模型 1.1 自回归模型 （1）自回归模型：对于一个包含T个’时间’节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据\n基于此，对于整个序列的估计值，可以表示为： 然而这对于长序列则计算量过大。我们可以使用该节点前面的τ个样本建模，控制模型参数的数量。 如果序列可以按这种方式计算，则认为其满足马尔科夫条件。 当τ=1（根据前一个节点推测后一个节点）时，序列估计可以写成如下形式。 Tips：称为自回归的原因是输入与输出预测同一类型的数据。\n（2）隐变量自回归模型 通过一个隐藏(latent):的变量推测Xt的值。而该隐藏变量来自于上一状态的隐变量以及当前Xt-1节点的值。（RNN, Recurrent Neural Network)的思想）\n1.2 训练 如下将演示如何根据正弦函数的样本点，建立τ=4的自回归模型\n第一步：模拟正弦函数的数据，x轴从0到1000 1 2 3 4 5 6 7 8 9 %matplotlib inline import torch from torch import nn from d2l import torch as d2l T = 1000 # 总共产生1000个点 time = torch.arange(1, T + 1, dtype=torch.float32) x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,)) #添加一点噪音 d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3)) 第二步：生成特征与标签数据（前4个样本作为输入，第5个样本作为预测） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 tau = 4 features = torch.zeros((T - tau, tau)) #tau列 for i in range(tau): #逐列填充，每次错开一个元素 features[:, i] = x[i: T - tau + i] labels = x[tau:].reshape((-1, 1)) features[:4,:], labels[:4] # (tensor([[-0.1026, -0.2982, 0.1424, 0.0798], # [-0.2982, 0.1424, 0.0798, 0.1033], # [ 0.1424, 0.0798, 0.1033, 0.0814], # [ 0.0798, 0.1033, 0.0814, -0.3063]]), # tensor([[ 0.1033], # [ 0.0814], # [-0.3063], # [ 0.1354]])) batch_size, n_train = 16, 600 # 只有前n_train个样本用于训练 # 批量数据迭代 train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=True) 第三步：建立模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 初始化网络权重的函数 def init_weights(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight) # 一个简单的多层感知机 def get_net(): net = nn.Sequential(nn.Linear(4, 10), nn.ReLU(), nn.Linear(10, 1)) net.apply(init_weights) return net # 平方损失，不做聚合操作 loss = nn.MSELoss(reduction='none') 第四步：训练模型 1 2 3 4 5 6 7 8 9 10 11 12 13 def train(net, train_iter, loss, epochs, lr): trainer = torch.optim.Adam(net.parameters(), lr) #优化算法 for epoch in range(epochs): for X, y in train_iter: trainer.zero_grad() l = loss(net(X), y) l.sum().backward() trainer.step() print(f'epoch {epoch + 1}, ' f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}') net = get_net() train(net, train_iter, loss, 5, 0.01) 1.3 预测 预测方式1：特征数据全部来自已知数据 1 2 3 4 5 6 onestep_preds = net(features) d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.detach().numpy()], 'time', 'x', legend=['data', '1-step preds'], xlim=[1, 1000], figsize=(6, 3)) # 下图左 预测方式2：前604个样本来训练集的已知数据。再后面预测时，每次将新预测的样本作为输入预测下一个输出。 1 2 3 4 5 6 7 8 9 10 11 12 13 multistep_preds = torch.zeros(T) #初始化全0 multistep_preds[: n_train + tau] = x[: n_train + tau] #前面的训练集数据已知，不做预测 for i in range(n_train + tau, T): # 将新预测的结果加入特征中，作为下一次预测的输入 multistep_preds[i] = net( multistep_preds[i - tau:i].reshape((1, -1))) d2l.plot([time, time[tau:], time[n_train + tau:]], [x.detach().numpy(), onestep_preds.detach().numpy(), multistep_preds[n_train + tau:].detach().numpy()], 'time', 'x', legend=['data', '1-step preds', 'multistep preds'], xlim=[1, 1000], figsize=(6, 3)) # 下图右 如上可以看出： 在单步预测（输入均为实际观测数据）时，模型效果不错； 而在预测多步（将最近的预测作为下一步输入）时，即更远的预测时，模型效果不尽如人意。 2 文本预处理 一篇文章可以视为一串单词的序列，需要进行必要的预处理操作步骤：\n（1）将文本作为字符串进行加载；\n（2）将字符串拆分为词元（单词或字符）；\n（3）建立一个词表，将词元映射到数字索引；\n（4）将文本转换为数字索引序列。\n2.1 读取数据集 示例数据：时光机器（The Time Machine）小说 如下操作，按行读取全部小说文本。结果为list，其中每个元素表示一行的文本。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #@save d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a') def read_time_machine(): #@save \"\"\"将时间机器数据集加载到文本行的列表中\"\"\" with open(d2l.download('time_machine'), 'r') as f: lines = f.readlines() return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines] lines = read_time_machine() # list print(f'# 文本总行数: {len(lines)}') # 文本总行数: 3221 print(lines[0]) # the time machine by h g wells print(lines[10]) # twinkled and his usually pale face was flushed and animated the 2.2 词元化 词元(token)，通常指一个单词或字符 如下操作将每一行以词元为单位，拆分为一个list，结果返回一个list of list 1 2 3 4 5 6 7 8 9 10 11 12 def tokenize(lines, token='word'): #@save \"\"\"将文本行拆分为单词或字符词元\"\"\" if token == 'word': return [line.split() for line in lines] elif token == 'char': return [list(line) for line in lines] else: print('错误：未知词元类型：' + token) tokens = tokenize(lines) #list of list, 内部list的元素即为词元 print(tokens[0]) # ['the', 'time', 'machine', 'by', 'h', 'g', 'wells'] 2.3 词表 词元的类型是字符串，而模型需要的是数字； 词表(Vocabulary)：类似于Python中的字典，将输入的词元转换为数字索引； 语料库(Corpus)：对所有文本中唯一词元的统计结果，按频率降序排。 对于低频率出现的词元，可设置一定标准的阈值过滤； 对于语料库中不存在，或者已过滤的词元，将被映射到未知词元’’, 其数字索引记为0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 class Vocab: #@save \"\"\"文本词表\"\"\" def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): if tokens is None: tokens = [] if reserved_tokens is None: reserved_tokens = [] # 按出现频率排序 counter = count_corpus(tokens) # counter.items() e.g. [('word1', 5), ('word2', 3), ('word3', 8)] self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True) # 未知词元的索引为0 self.idx_to_token = [''] + reserved_tokens self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)} for token, freq in self._token_freqs: if freq \u003c min_freq: break if token not in self.token_to_idx: self.idx_to_token.append(token) self.token_to_idx[token] = len(self.idx_to_token) - 1 def __len__(self): return len(self.idx_to_token) # 如果传入单个词元，则返回其索引；如果传入词元列表，则返回对应的索引列表。 def __getitem__(self, tokens): if not isinstance(tokens, (list, tuple)): return self.token_to_idx.get(tokens, self.unk) return [self.__getitem__(token) for token in tokens] # 根据输入的索引或索引列表返回对应的词元。 def to_tokens(self, indices): if not isinstance(indices, (list, tuple)): return self.idx_to_token[indices] return [self.idx_to_token[index] for index in indices] @property def unk(self): # 未知词元的索引为0 return 0 @property def token_freqs(self): return self._token_freqs def count_corpus(tokens): #@save \"\"\"统计词元的频率\"\"\" # 这里的tokens是1D列表或2D列表 if len(tokens) == 0 or isinstance(tokens[0], list): # 将词元list of list列表展平成一个列表 tokens = [token for line in tokens for token in line] return collections.Counter(tokens) vocab = Vocab(tokens) list(vocab.token_to_idx.items())[:5] # [('', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4)] vocab.token_freqs[:5] # [('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816)] 2.4 整合所有功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def load_corpus_time_machine(max_tokens=-1): #@save \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\" lines = read_time_machine() tokens = tokenize(lines, 'char') #词元为字符 vocab = Vocab(tokens) # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落， # 所以将所有文本行展平到一个列表中 corpus = [vocab[token] for line in tokens for token in line] if max_tokens \u003e 0: corpus = corpus[:max_tokens] return corpus, vocab # corpus 全部文本的词元 corpus, vocab = load_corpus_time_machine() len(corpus), len(vocab) # (170580, 28) corpus[:5] # [3, 9, 2, 1, 3] vocab.token_freqs[:5] # [(' ', 29927), ('e', 17838), ('t', 13515), ('a', 11704), ('i', 10138)] 3. 语言模型和数据集 3.1 自然语言统计 单个词元统计（一元语法） 1 2 3 4 5 6 7 8 9 10 11 import random import torch from d2l import torch as d2l tokens = d2l.tokenize(d2l.read_time_machine()) # 将list of list转为list corpus = [token for line in tokens for token in line] vocab = d2l.Vocab(corpus) vocab.token_freqs[:10] # [('the', 2261), ('i', 1267), ('and', 1245)] 两个连续词元统计（二元语法） 1 2 3 4 5 6 bigram_tokens = [pair for pair in zip(corpus[:-1], corpus[1:])] bigram_tokens[:3] # [('the', 'time'), ('time', 'machine'), ('machine', 'by')] bigram_vocab = d2l.Vocab(bigram_tokens) bigram_vocab.token_freqs[:3] # [(('of', 'the'), 309), (('in', 'the'), 169), (('i', 'had'), 130)] 三个连续词元统计（三元语法） 1 2 3 4 5 6 7 trigram_tokens = [triple for triple in zip( corpus[:-2], corpus[1:-1], corpus[2:])] trigram_vocab = d2l.Vocab(trigram_tokens) trigram_vocab.token_freqs[:3] # [(('the', 'time', 'traveller'), 59), # (('the', 'time', 'machine'), 30), # (('the', 'medical', 'man'), 24)] 根据下图的频率分布可视化，可以看出： 三者均不同程度上遵循齐普夫定律，呈现较为显著的衰减 少数高频词占了全部语料库的大多数，大部分可能形式的n元组很少出现 1 2 3 4 5 6 freqs = [freq for token, freq in vocab.token_freqs] bigram_freqs = [freq for token, freq in bigram_vocab.token_freqs] trigram_freqs = [freq for token, freq in trigram_vocab.token_freqs] d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel='token: x', ylabel='frequency: n(x)', xscale='log', yscale='log', legend=['unigram', 'bigram', 'trigram']) 3.2 读取长序列数据 如前所述，在处理长序列时，通常仅考虑待预测数据前的若干节点的观测数据。\nbatch_size：每个小批量同时处理的子序列样本数目；\nnum_steps：每个子序列中预定义的时间步数。\n在小批量采样时，由如下两种方式（子序列的时间步数都不重叠）\n随机偏移量：从一个随机起始点开始截取序列，增加每个epoch迭代的随机性\n（1）随机抽样\n每个批量样本之间的起始时间步数无顺序关系 e.g. 第一个小批量的第一个序列与第二个小批量的第一个序列无相邻的顺序关系 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def seq_data_iter_random(corpus, batch_size, num_steps): #@save \"\"\"使用随机抽样生成一个小批量子序列\"\"\" # 从随机偏移量开始对序列进行分区(随机丢弃开头的几个位置数据)，随机范围包括num_steps-1 corpus = corpus[random.randint(0, num_steps - 1):] # 计算可以生成多少个不重叠的子序列(减去1，是因为我们需要考虑标签) num_subseqs = (len(corpus) - 1) // num_steps # 每个子序列的起始索引 initial_indices = list(range(0, num_subseqs * num_steps, num_steps)) # 打乱初始索引 random.shuffle(initial_indices) def data(pos): # 返回从pos位置开始的长度为num_steps的序列 return corpus[pos: pos + num_steps] #根据每个小批量包含的子序列数，计算有多少个批量 num_batches = num_subseqs // batch_size for i in range(0, batch_size * num_batches, batch_size): # 在这里，每个批量内所有子序列的起始索引 initial_indices_per_batch = initial_indices[i: i + batch_size] X = [data(j) for j in initial_indices_per_batch] Y = [data(j + 1) for j in initial_indices_per_batch] yield torch.tensor(X), torch.tensor(Y) 示例 1 2 3 4 5 6 7 8 9 10 11 12 random_iter = seq_data_iter_random(list(range(35)), batch_size=2, num_steps=5) next(iter(random_iter)) # (tensor([[24, 25, 26, 27, 28], # [14, 15, 16, 17, 18]]), # tensor([[25, 26, 27, 28, 29], # [15, 16, 17, 18, 19]])) next(iter(random_iter)) # (tensor([[ 9, 10, 11, 12, 13], # [ 4, 5, 6, 7, 8]]), # tensor([[10, 11, 12, 13, 14], # [ 5, 6, 7, 8, 9]])) （2）顺序分区\n保证两个相邻的小批量中的子序列在原始序列上也是相邻的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def seq_data_iter_sequential(corpus, batch_size, num_steps): #@save \"\"\"使用顺序分区生成一个小批量子序列\"\"\" # 从随机偏移量开始划分序列 offset = random.randint(0, num_steps) # 确保可以被整除的tokens词元数量 num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size # 所有作为特征的输入序列 Xs = torch.tensor(corpus[offset: offset + num_tokens]) # 所有的标签值 Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens]) # 行数表示每个批量包含的子序列数 Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1) num_batches = Xs.shape[1] // num_steps for i in range(0, num_steps * num_batches, num_steps): X = Xs[:, i: i + num_steps] Y = Ys[:, i: i + num_steps] yield X, Y 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 iter_seq = seq_data_iter_sequential(list(range(35)), batch_size=2, num_steps=5) next(iter(iter_seq)) # (tensor([[ 2, 3, 4, 5, 6], # [18, 19, 20, 21, 22]]), # tensor([[ 3, 4, 5, 6, 7], # [19, 20, 21, 22, 23]])) next(iter(iter_seq)) # (tensor([[ 7, 8, 9, 10, 11], # [23, 24, 25, 26, 27]]), # tensor([[ 8, 9, 10, 11, 12], # [24, 25, 26, 27, 28]])) Tips：无论上述哪一种方式，生成的序列样本数据都是不重叠的。\n整合上述迭代方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 定义一个类，生成数据迭代器 class SeqDataLoader: #@save \"\"\"加载序列数据的迭代器\"\"\" def __init__(self, batch_size, num_steps, use_random_iter, max_tokens): if use_random_iter: self.data_iter_fn = d2l.seq_data_iter_random else: self.data_iter_fn = d2l.seq_data_iter_sequential # 返回所有文档的词元索引列表，以及词表vocab self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens) self.batch_size, self.num_steps = batch_size, num_steps def __iter__(self): return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps) # 综合词表与数据迭代器 def load_data_time_machine(batch_size, num_steps, #@save use_random_iter=False, max_tokens=10000): \"\"\"返回时光机器数据集的迭代器和词表\"\"\" data_iter = SeqDataLoader( batch_size, num_steps, use_random_iter, max_tokens) return data_iter, data_iter.vocab 4. 循环神经网络 循环神经网络是具有隐状态的神经网络； 隐状态与隐藏层的概念截然不同 隐藏层是指在从输入到输出的路径上，隐藏的层； 隐状态可以理解为RNN中的记忆单元，它保存了序列中先前时间步的信息，并传递给后续的时间步。 4.1 无隐状态的神经网络 以简单的单隐藏层MLP为例：\n输入X，隐藏层输出H，隐藏层权重参数Wxh，偏置参数b 输出层O，权重参数Whq，偏置参数b 4.2 有隐状态的神经网络 对于一个特定时间步长的序列：\nXt步的输出(Ot，表示对于Xt+1的预测)，取决于当前时间序列的隐状态Ht； 而当前的隐状态Ht由当前时间步的输入Xt与前一个时间步的隐状态Ht-1共同计算得出。 对于输入的小批量数据，由n个长度为T的序列样本组成。若样本特征长度为d时，则每次训练输入数据为 Xt：n×d 基于Xt的输入，参与Ht计算的权重参数为Wxh；基于Ht-1隐状态，参与Ht计算的权重参数为Whh，此外还有偏置； 从Ht隐状态，最终计算Ot的权重参数为Whq，以及偏置。 （1）如上可以看出，有隐状态的神经网络从公式上来看，与单隐藏层的神经网络非常类似。只是多了一项Wxh参数的计算过程。\n（2）在同一批量的不同时间节点迭代时，仍然是上述这些模型参数。即模型参数的开销不会随着时间步的增加而增加。\n如下，演示同时对特定一个批量内多个子序列的第i个词元的隐状态计算： 输入的批量包含3条子序列，每条子序列中单个词元的特征长度为1； 隐状态的神经元个数设置为4。 1 2 3 4 5 6 7 import torch from d2l import torch as d2l X, W_xh = torch.normal(0, 1, (3, 1)), torch.normal(0, 1, (1, 4)) H, W_hh = torch.normal(0, 1, (3, 4)), torch.normal(0, 1, (4, 4)) torch.matmul(X, W_xh) + torch.matmul(H, W_hh) 4.3 基于RNN的字符级语言模型 在字符级语言模型中，文本词元为字符而不是单词； 如下可以理解为小批量大小为1，文本序列为’machine' 4.4 困惑度 语言模型大部分情况下可以理解为分类问题，可以利用交叉熵计算模型输入与标签之间的差异； 模型性能(损失)可根据一个序列中所有词元(n)的平均交叉熵损失来衡量； 实际建模时，自然语言处理的科学家更喜欢使用困惑度(Perplexity)指标。本质上只是对上述进行exp指数运算。 该指标可以理解为对下一个词元的实际选择数的调和平均数。 困惑度越低，说明模型的预测效果越好。最好的情况为1，即完美地估计了标签词元； 如果困惑度为 kk，那么可以理解为模型预测下一个词时的候选词数量大致为 k。 5. RNN的从零实现 从零开始基于RNN实现字符级语言模型\n读取数据集 batch_size表示每个批量同时读取/处理多少条子序列 num_steps表示每条子序列的长度 1 2 3 4 5 6 7 8 9 %matplotlib inline import math import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) 5.1 独热编码 每个词元经转换后表示为一个数字索引，然后经独热编码表示为特征向量； 若词表的唯一词元有N个(len(vocab))，则词元索引范围是 0~N-1，其特征向量长度为N 1 2 F.one_hot(torch.tensor([0, 2]), len(vocab)).shape # torch.Size([2, 28]) 特征编码前，小批量输入形状为二维张量（批量大小，时间步数/序列长度） 编码后则为3维张量，需要再调整下维度的顺序，方便后续操作。（时间步数/序列长度，批量大小，词表大小/特征长度） 1 2 3 4 5 6 # 批量大小为2，序列长度为5 X = torch.arange(10).reshape((2, 5)) #X.T转置操作，将序列长度维数放在前面之后，再进行独热编码 F.one_hot(X.T, 28).shape # torch.Size([5, 2, 28]) 5.2 初始化模型参数 RNN模型参数可参考4.2部分介绍，主要分为隐状态参数与输出层参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def get_params(vocab_size, num_hiddens, device): # 输入与输出的词元的特征向量长度相同 num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device) * 0.01 # 隐藏层参数 W_xh = normal((num_inputs, num_hiddens)) W_hh = normal((num_hiddens, num_hiddens)) b_h = torch.zeros(num_hiddens, device=device) # 输出层参数，num_outputs等于词元类别数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params 5.3 RNN模型 初始化隐状态，形状为（批量大小，隐藏单元数） 1 2 3 def init_rnn_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), ) # 这里返回元组，因为后面章节的隐状态会有多个变量（LSTM） 定义前向传播函数，返回一轮batch的预测结果（批量大小×序列长度，词表大小），以及更新的隐状态 输入inputs为上述5.1所介绍的三维张量 1 2 3 4 5 6 7 8 9 10 11 12 13 def rnn(inputs, state, params): # inputs的形状：(时间步数量，批量大小，词表大小) W_xh, W_hh, b_h, W_hq, b_q = params H, = state outputs = [] # 逐时间步迭代：X的形状为(批量大小，词表大小) for X in inputs: H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h) Y = torch.mm(H, W_hq) + b_q # Y形状：(批量大小，词表大小) outputs.append(Y) return torch.cat(outputs, dim=0), (H,) #纵向叠加，增加行数，列数不变，维度不变 定义模型的类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class RNNModelScratch: #@save \"\"\"从零开始实现的循环神经网络模型\"\"\" def __init__(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn): self.vocab_size, self.num_hiddens = vocab_size, num_hiddens self.params = get_params(vocab_size, num_hiddens, device) self.init_state, self.forward_fn = init_state, forward_fn def __call__(self, X, state): X = F.one_hot(X.T, self.vocab_size).type(torch.float32) return self.forward_fn(X, state, self.params) def begin_state(self, batch_size, device): return self.init_state(batch_size, self.num_hiddens, device) 示例输出 1 2 3 4 5 6 7 8 9 10 11 12 13 num_hiddens = 512 net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params, init_rnn_state, rnn) state = net.begin_state(X.shape[0], d2l.try_gpu()) # 批量包含的序列数为2，序列长度为5 X = torch.arange(10).reshape((2, 5)) Y, new_state = net(X.to(d2l.try_gpu()), state) Y.shape # torch.Size([10, 28]) new_state[0].shape #批量内每个子序列最后一个时间步的隐状态 # torch.Size([2, 512]) 5.4 预测 prefix：包含若干词元的初始文本 num_preds：往后预测多少个词元 在预测过程中，首先逐个遍历给定的初始词元，但不做预测，仅用于更新隐状态。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def predict_ch8(prefix, num_preds, net, vocab, device): #@save \"\"\"在prefix后面生成新字符\"\"\" # batch_size=1表示单批量逐个预测 state = net.begin_state(batch_size=1, device=device) # 首先将prefix的第一个词元加入到outputs中 outputs = [vocab[prefix[0]]] # 取outputs里最新的一个词元，作为预测下一个词元的输入 get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1)) for y in prefix[1:]: # 预热期 _, state = net(get_input(), state) outputs.append(vocab[y]) #传入真实值 for _ in range(num_preds): # 预测num_preds步 y, state = net(get_input(), state) outputs.append(int(y.argmax(dim=1).reshape(1))) #传入预测值 return ''.join([vocab.idx_to_token[i] for i in outputs]) 示例 1 2 predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu()) # 'time traveller xejnnnnnnn' 5.5 梯度剪裁 对于长度为T的序列，训练时会执行T次矩阵乘法，来进行反向传播、更新梯度。 这对于较长的序列，可能会导致梯度爆炸，模型无法收敛。 此时，可以通过梯度剪裁，将参数的梯度的范数设置一个上限θ（不改变方向）。 1 2 3 4 5 6 7 8 9 10 11 def grad_clipping(net, theta): #@save \"\"\"裁剪梯度\"\"\" if isinstance(net, nn.Module): params = [p for p in net.parameters() if p.requires_grad] else: params = net.params norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params)) #若范数长度大于θ，就设置其值为θ if norm \u003e theta: for param in params: param.grad[:] *= theta / norm 5.6 训练 在3.2小节中，学习了两种小批量序列样本迭代方法：（1）顺序分区；（2）随机抽样 对于顺序分区，相邻两个batch iteration中，对应的第i个子序列的位序也是相邻的。 隐状态仅需要在刚开始时初始化一次。在后面的多轮小批量训练时，可以继承。 为减少计算量，在处理每个批量数据前，对隐状态参数梯度分离。 对于随机抽样，相邻两个batch iteration的序列样本无确定关系（更常用些） 隐状态在每个batch iteration时，都需要随机初始化（其权重参数是持续更新的）。 如下为训练一个epoch的代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #@save def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter): \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\" state, timer = None, d2l.Timer() metric = d2l.Accumulator(2) # 训练损失之和,词元数量 for X, Y in train_iter: if state is None or use_random_iter: # 在第一次迭代或使用随机抽样时初始化state state = net.begin_state(batch_size=X.shape[0], device=device) else: if isinstance(net, nn.Module) and not isinstance(state, tuple): # state对于nn.GRU是个张量 state.detach_() else: # state对于nn.LSTM或对于我们从零开始实现的模型是个张量 for s in state: s.detach_() y = Y.T.reshape(-1) X, y = X.to(device), y.to(device) y_hat, state = net(X, state) l = loss(y_hat, y.long()).mean() # y转为长整型(64位整数) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.backward() grad_clipping(net, 1) updater.step() else: l.backward() grad_clipping(net, 1) # 因为已经调用了mean函数 updater(batch_size=1) metric.add(l * y.numel(), y.numel()) return math.exp(metric[0] / metric[1]), metric[1] / timer.stop() 如下为训练的最终形式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #@save def train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter=False): \"\"\"训练模型（定义见第8章）\"\"\" loss = nn.CrossEntropyLoss() animator = d2l.Animator(xlabel='epoch', ylabel='perplexity', legend=['train'], xlim=[10, num_epochs]) # 初始化 if isinstance(net, nn.Module): updater = torch.optim.SGD(net.parameters(), lr) else: updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size) predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device) # 训练和预测 for epoch in range(num_epochs): ppl, speed = train_epoch_ch8( net, train_iter, loss, updater, device, use_random_iter) if (epoch + 1) % 10 == 0: print(predict('time traveller')) animator.add(epoch + 1, [ppl]) print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}') print(predict('time traveller')) print(predict('traveller')) 实际训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 训练--顺序分区（下图左） num_epochs, lr = 500, 1 train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu()) # 困惑度 1.0, 38769.2 词元/秒 cuda:0 # time travelleryou can show black is white by argument said filby # travelleryou can show black is white by argument said filby ## 训练--随机抽样（下图右） net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params, init_rnn_state, rnn) train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(), use_random_iter=True) # 困惑度 1.5, 37930.8 词元/秒 cuda:0 # time travellerit s against reason said filbywas allaing the time # travellerit s against reason said filbywas allaing the time 6. RNN的简洁实现 准备数据 1 2 3 4 5 6 7 import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) 6.1 定义模型 基于torch的nn.RNN，定义一个具有256个隐藏单元的单隐藏层，其不涉及输出层的计算 1 2 num_hiddens = 256 rnn_layer = nn.RNN(len(vocab), num_hiddens) 初始化隐状态，形状为（隐藏层数，批量大小，隐藏单元数） 1 2 3 state = torch.zeros((1, batch_size, num_hiddens)) state.shape # torch.Size([1, 32, 256]) 模拟计算，更新隐状态 如下的Y表示，所有批量的子序列的最后一层的隐状态（一般后面需要再接MLP预测Ot输出） state_new表示所有批量的子序列的最后一步的隐状态 1 2 3 4 5 6 7 X = torch.rand(size=(num_steps, batch_size, len(vocab))) Y, state_new = rnn_layer(X, state) Y.shape, state_new.shape # (torch.Size([35, 32, 256]), torch.Size([1, 32, 256])) # 35为序列长度 # 32为批量大小 # 256 隐藏层单元数 定义一个完整的RNNModel类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #@save class RNNModel(nn.Module): \"\"\"循环神经网络模型\"\"\" def __init__(self, rnn_layer, vocab_size, **kwargs): super(RNNModel, self).__init__(**kwargs) self.rnn = rnn_layer self.vocab_size = vocab_size self.num_hiddens = self.rnn.hidden_size # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1 if not self.rnn.bidirectional: self.num_directions = 1 self.linear = nn.Linear(self.num_hiddens, self.vocab_size) else: self.num_directions = 2 self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size) def forward(self, inputs, state): X = F.one_hot(inputs.T.long(), self.vocab_size) X = X.to(torch.float32) Y, state = self.rnn(X, state) # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数) # 它的输出形状是(时间步数*批量大小,词表大小)。 output = self.linear(Y.reshape((-1, Y.shape[-1]))) return output, state def begin_state(self, device, batch_size=1): if not isinstance(self.rnn, nn.LSTM): # nn.GRU以张量作为隐状态 return torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device) else: # nn.LSTM以元组作为隐状态 return (torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device), torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)) 6.2 训练与预测 训练函数仍参考5.6小节 实例化模型 1 2 3 4 5 device = d2l.try_gpu() net = RNNModel(rnn_layer, vocab_size=len(vocab)) net = net.to(device) d2l.predict_ch8('time traveller', 10, net, vocab, device) # 'time travellerpppwllllll' 训练模型 1 2 3 4 5 num_epochs, lr = 500, 1 d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device) # perplexity 1.3, 255236.1 tokens/sec on cuda:0 # time traveller but now you be in aly has we mave the gratienttan # travellerit s ala to be accupted is an absolute procimind a ",
  "wordCount" : "7871",
  "inLanguage": "en",
  "datePublished": "2024-08-11T00:00:00Z",
  "dateModified": "2024-08-11T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lishensuo"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Li's Bioinfo-Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lishensuo.github.io/img/Q.gif"
    }
  }
}
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lishensuo.github.io/en/" accesskey="h" title="Li&#39;s Bioinfo-Blog (Alt + H)">Li&#39;s Bioinfo-Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lishensuo.github.io/en/" title="主页">
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/posts" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/about" title="关于">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/search" title="搜索 (Alt &#43; /)" accesskey=/>
                    <span>搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lishensuo.github.io/en/">Home</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/">分类</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/bioinfo/">📖 生信数据分析--分析流程，工具包等</a></div>
    <h1 class="post-title">
      D2L--第八章循环神经网络
    </h1>
    <div class="post-meta">













Create:&amp;nbsp;&lt;span title=&#39;2024-08-11 00:00:00 &#43;0000 UTC&#39;&gt;2024-08-11&lt;/span&gt;&amp;nbsp;|&amp;nbsp;Update:&amp;nbsp;2024-08-11&amp;nbsp;|&amp;nbsp;Words:&amp;nbsp;7871&amp;nbsp;|&amp;nbsp;16 min&amp;nbsp;|&amp;nbsp;Lishensuo

|  Viewers: <span id="busuanzi_value_page_pv"></span> 
	  
    </div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#1-%e5%ba%8f%e5%88%97%e6%a8%a1%e5%9e%8b" aria-label="1. 序列模型">1. 序列模型</a><ul>
                            
                    <li>
                        <a href="#11-%e8%87%aa%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8b" aria-label="1.1 自回归模型">1.1 自回归模型</a></li>
                    <li>
                        <a href="#12-%e8%ae%ad%e7%bb%83" aria-label="1.2 训练">1.2 训练</a></li>
                    <li>
                        <a href="#13-%e9%a2%84%e6%b5%8b" aria-label="1.3 预测">1.3 预测</a></li></ul>
                    </li>
                    <li>
                        <a href="#2-%e6%96%87%e6%9c%ac%e9%a2%84%e5%a4%84%e7%90%86" aria-label="2 文本预处理">2 文本预处理</a><ul>
                            
                    <li>
                        <a href="#21-%e8%af%bb%e5%8f%96%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="2.1 读取数据集">2.1 读取数据集</a></li>
                    <li>
                        <a href="#22-%e8%af%8d%e5%85%83%e5%8c%96" aria-label="2.2 词元化">2.2 词元化</a></li>
                    <li>
                        <a href="#23-%e8%af%8d%e8%a1%a8" aria-label="2.3 词表">2.3 词表</a></li>
                    <li>
                        <a href="#24-%e6%95%b4%e5%90%88%e6%89%80%e6%9c%89%e5%8a%9f%e8%83%bd" aria-label="2.4 整合所有功能">2.4 整合所有功能</a></li></ul>
                    </li>
                    <li>
                        <a href="#3-%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e5%92%8c%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="3. 语言模型和数据集">3. 语言模型和数据集</a><ul>
                            
                    <li>
                        <a href="#31-%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e7%bb%9f%e8%ae%a1" aria-label="3.1 自然语言统计">3.1 自然语言统计</a></li>
                    <li>
                        <a href="#32-%e8%af%bb%e5%8f%96%e9%95%bf%e5%ba%8f%e5%88%97%e6%95%b0%e6%8d%ae" aria-label="3.2 读取长序列数据">3.2 读取长序列数据</a></li></ul>
                    </li>
                    <li>
                        <a href="#4-%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" aria-label="4. 循环神经网络">4. 循环神经网络</a><ul>
                            
                    <li>
                        <a href="#41-%e6%97%a0%e9%9a%90%e7%8a%b6%e6%80%81%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" aria-label="4.1 无隐状态的神经网络">4.1 无隐状态的神经网络</a></li>
                    <li>
                        <a href="#42-%e6%9c%89%e9%9a%90%e7%8a%b6%e6%80%81%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" aria-label="4.2 有隐状态的神经网络">4.2 有隐状态的神经网络</a></li>
                    <li>
                        <a href="#43-%e5%9f%ba%e4%ba%8ernn%e7%9a%84%e5%ad%97%e7%ac%a6%e7%ba%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b" aria-label="4.3 基于RNN的字符级语言模型">4.3 基于RNN的字符级语言模型</a></li>
                    <li>
                        <a href="#44-%e5%9b%b0%e6%83%91%e5%ba%a6" aria-label="4.4 困惑度">4.4 困惑度</a></li></ul>
                    </li>
                    <li>
                        <a href="#5-rnn%e7%9a%84%e4%bb%8e%e9%9b%b6%e5%ae%9e%e7%8e%b0" aria-label="5. RNN的从零实现">5. RNN的从零实现</a><ul>
                            
                    <li>
                        <a href="#51-%e7%8b%ac%e7%83%ad%e7%bc%96%e7%a0%81" aria-label="5.1 独热编码">5.1 独热编码</a></li>
                    <li>
                        <a href="#52-%e5%88%9d%e5%a7%8b%e5%8c%96%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0" aria-label="5.2 初始化模型参数">5.2 初始化模型参数</a></li>
                    <li>
                        <a href="#53-rnn%e6%a8%a1%e5%9e%8b" aria-label="5.3 RNN模型">5.3 RNN模型</a></li>
                    <li>
                        <a href="#54-%e9%a2%84%e6%b5%8b" aria-label="5.4 预测">5.4 预测</a></li>
                    <li>
                        <a href="#55-%e6%a2%af%e5%ba%a6%e5%89%aa%e8%a3%81" aria-label="5.5 梯度剪裁">5.5 梯度剪裁</a></li>
                    <li>
                        <a href="#56-%e8%ae%ad%e7%bb%83" aria-label="5.6 训练">5.6 训练</a></li></ul>
                    </li>
                    <li>
                        <a href="#6-rnn%e7%9a%84%e7%ae%80%e6%b4%81%e5%ae%9e%e7%8e%b0" aria-label="6. RNN的简洁实现">6. RNN的简洁实现</a><ul>
                            
                    <li>
                        <a href="#61-%e5%ae%9a%e4%b9%89%e6%a8%a1%e5%9e%8b" aria-label="6.1 定义模型">6.1 定义模型</a></li>
                    <li>
                        <a href="#62-%e8%ae%ad%e7%bb%83%e4%b8%8e%e9%a2%84%e6%b5%8b" aria-label="6.2 训练与预测">6.2 训练与预测</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>


  <div class="post-content"><h1 id="1-序列模型">1. 序列模型<a hidden class="anchor" aria-hidden="true" href="#1-序列模型">#</a></h1>
<h2 id="11-自回归模型">1.1 自回归模型<a hidden class="anchor" aria-hidden="true" href="#11-自回归模型">#</a></h2>
<p>（1）<strong>自回归模型</strong>：对于一个包含T个&rsquo;时间&rsquo;节点的输入序列，若预测其中的第t个数据，则依赖于该节点前面的观察数据</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240806194905905.png" alt="image-20240806194905905"  />
</p>
<ul>
<li>基于此，对于整个序列的估计值，可以表示为：</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240806195042014.png" alt="image-20240806195042014"  />
</p>
<ul>
<li>然而这对于长序列则计算量过大。我们可以使用该节点前面的τ个样本建模，控制模型参数的数量。
<ul>
<li>如果序列可以按这种方式计算，则认为其满足马尔科夫条件。</li>
<li>当τ=1（根据前一个节点推测后一个节点）时，序列估计可以写成如下形式。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240806201637200.png" alt="image-20240806201637200"  />
</p>
<blockquote>
<p>Tips：称为自回归的原因是输入与输出预测同一类型的数据。</p></blockquote>
<p>（2）<strong>隐变量自回归模型</strong> 通过一个隐藏(latent):的变量推测Xt的值。而该隐藏变量来自于上一状态的隐变量以及当前Xt-1节点的值。（RNN, Recurrent Neural Network)的思想）</p>
<p><img loading="lazy" src="C:%5cUsers%5cxiaoxin%5cAppData%5cRoaming%5cTypora%5ctypora-user-images%5cimage-20240806171721063.png" alt="image-20240806171721063"  />
</p>
<h2 id="12-训练">1.2 训练<a hidden class="anchor" aria-hidden="true" href="#12-训练">#</a></h2>
<p>如下将演示如何根据正弦函数的样本点，建立τ=4的自回归模型</p>
<ul>
<li>第一步：模拟正弦函数的数据，x轴从0到1000</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>T = <span style="color:#ff0;font-weight:bold">1000</span>  <span style="color:#007f7f"># 总共产生1000个点</span>
</span></span><span style="display:flex;"><span>time = torch.arange(<span style="color:#ff0;font-weight:bold">1</span>, T + <span style="color:#ff0;font-weight:bold">1</span>, dtype=torch.float32)
</span></span><span style="display:flex;"><span>x = torch.sin(<span style="color:#ff0;font-weight:bold">0.01</span> * time) + torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">0.2</span>, (T,)) <span style="color:#007f7f">#添加一点噪音</span>
</span></span><span style="display:flex;"><span>d2l.plot(time, [x], <span style="color:#0ff;font-weight:bold">&#39;time&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;x&#39;</span>, xlim=[<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1000</span>], figsize=(<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">3</span>))
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240806205930245.png" alt="image-20240806205930245"  />
</p>
<ul>
<li>第二步：生成特征与标签数据（前4个样本作为输入，第5个样本作为预测）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tau = <span style="color:#ff0;font-weight:bold">4</span>
</span></span><span style="display:flex;"><span>features = torch.zeros((T - tau, tau)) <span style="color:#007f7f">#tau列</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(tau): <span style="color:#007f7f">#逐列填充，每次错开一个元素</span>
</span></span><span style="display:flex;"><span>    features[:, i] = x[i: T - tau + i]
</span></span><span style="display:flex;"><span>labels = x[tau:].reshape((-<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>features[:<span style="color:#ff0;font-weight:bold">4</span>,:], labels[:<span style="color:#ff0;font-weight:bold">4</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([[-0.1026, -0.2982,  0.1424,  0.0798],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [-0.2982,  0.1424,  0.0798,  0.1033],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 0.1424,  0.0798,  0.1033,  0.0814],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 0.0798,  0.1033,  0.0814, -0.3063]]),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[ 0.1033],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 0.0814],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [-0.3063],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 0.1354]]))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, n_train = <span style="color:#ff0;font-weight:bold">16</span>, <span style="color:#ff0;font-weight:bold">600</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 只有前n_train个样本用于训练</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 批量数据迭代</span>
</span></span><span style="display:flex;"><span>train_iter = d2l.load_array((features[:n_train], labels[:n_train]),
</span></span><span style="display:flex;"><span>                            batch_size, is_train=<span style="color:#fff;font-weight:bold">True</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>第三步：建立模型</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 初始化网络权重的函数</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> init_weights(m):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) == nn.Linear:
</span></span><span style="display:flex;"><span>        nn.init.xavier_uniform_(m.weight)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 一个简单的多层感知机</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_net():
</span></span><span style="display:flex;"><span>    net = nn.Sequential(nn.Linear(<span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">10</span>),
</span></span><span style="display:flex;"><span>                        nn.ReLU(),
</span></span><span style="display:flex;"><span>                        nn.Linear(<span style="color:#ff0;font-weight:bold">10</span>, <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>    net.apply(init_weights)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> net
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 平方损失，不做聚合操作</span>
</span></span><span style="display:flex;"><span>loss = nn.MSELoss(reduction=<span style="color:#0ff;font-weight:bold">&#39;none&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>第四步：训练模型</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train(net, train_iter, loss, epochs, lr):
</span></span><span style="display:flex;"><span>    trainer = torch.optim.Adam(net.parameters(), lr) <span style="color:#007f7f">#优化算法</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(epochs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> X, y in train_iter:
</span></span><span style="display:flex;"><span>            trainer.zero_grad()
</span></span><span style="display:flex;"><span>            l = loss(net(X), y)
</span></span><span style="display:flex;"><span>            l.sum().backward()
</span></span><span style="display:flex;"><span>            trainer.step()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;epoch </span><span style="color:#0ff;font-weight:bold">{</span>epoch + <span style="color:#ff0;font-weight:bold">1</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, &#39;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;loss: </span><span style="color:#0ff;font-weight:bold">{</span>d2l.evaluate_loss(net, train_iter, loss)<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>net = get_net()
</span></span><span style="display:flex;"><span>train(net, train_iter, loss, <span style="color:#ff0;font-weight:bold">5</span>, <span style="color:#ff0;font-weight:bold">0.01</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="13-预测">1.3 预测<a hidden class="anchor" aria-hidden="true" href="#13-预测">#</a></h2>
<ul>
<li>预测方式1：特征数据全部来自已知数据</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>onestep_preds = net(features)
</span></span><span style="display:flex;"><span>d2l.plot([time, time[tau:]],
</span></span><span style="display:flex;"><span>         [x.detach().numpy(), onestep_preds.detach().numpy()], <span style="color:#0ff;font-weight:bold">&#39;time&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#0ff;font-weight:bold">&#39;x&#39;</span>, legend=[<span style="color:#0ff;font-weight:bold">&#39;data&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;1-step preds&#39;</span>], xlim=[<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1000</span>],
</span></span><span style="display:flex;"><span>         figsize=(<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">3</span>))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 下图左</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>预测方式2：前604个样本来训练集的已知数据。再后面预测时，每次将新预测的样本作为输入预测下一个输出。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>multistep_preds = torch.zeros(T) <span style="color:#007f7f">#初始化全0</span>
</span></span><span style="display:flex;"><span>multistep_preds[: n_train + tau] = x[: n_train + tau] <span style="color:#007f7f">#前面的训练集数据已知，不做预测</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(n_train + tau, T):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 将新预测的结果加入特征中，作为下一次预测的输入</span>
</span></span><span style="display:flex;"><span>    multistep_preds[i] = net(
</span></span><span style="display:flex;"><span>        multistep_preds[i - tau:i].reshape((<span style="color:#ff0;font-weight:bold">1</span>, -<span style="color:#ff0;font-weight:bold">1</span>)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d2l.plot([time, time[tau:], time[n_train + tau:]],
</span></span><span style="display:flex;"><span>         [x.detach().numpy(), onestep_preds.detach().numpy(),
</span></span><span style="display:flex;"><span>          multistep_preds[n_train + tau:].detach().numpy()], <span style="color:#0ff;font-weight:bold">&#39;time&#39;</span>,
</span></span><span style="display:flex;"><span>         <span style="color:#0ff;font-weight:bold">&#39;x&#39;</span>, legend=[<span style="color:#0ff;font-weight:bold">&#39;data&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;1-step preds&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;multistep preds&#39;</span>],
</span></span><span style="display:flex;"><span>         xlim=[<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1000</span>], figsize=(<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">3</span>))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 下图右</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240806211506715.png" alt="image-20240806211506715"  />
</p>
<ul>
<li>如上可以看出：
<ul>
<li>在单步预测（输入均为实际观测数据）时，模型效果不错；</li>
<li>而在预测多步（将最近的预测作为下一步输入）时，即更远的预测时，模型效果不尽如人意。</li>
</ul>
</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/76fd30983b088e2540cd4e2b1c9aa6e0.png" alt="skforecast：一款解决时序预测的神库-CSDN博客" style="zoom:50%;" />
<h1 id="2-文本预处理">2 文本预处理<a hidden class="anchor" aria-hidden="true" href="#2-文本预处理">#</a></h1>
<p>一篇文章可以视为一串单词的序列，需要进行必要的预处理操作步骤：</p>
<p>（1）将文本作为字符串进行加载；</p>
<p>（2）将字符串拆分为词元（单词或字符）；</p>
<p>（3）建立一个词表，将词元映射到数字索引；</p>
<p>（4）将文本转换为数字索引序列。</p>
<h2 id="21-读取数据集">2.1 读取数据集<a hidden class="anchor" aria-hidden="true" href="#21-读取数据集">#</a></h2>
<ul>
<li>示例数据：时光机器（The Time Machine）小说</li>
<li>如下操作，按行读取全部小说文本。结果为list，其中每个元素表示一行的文本。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>d2l.DATA_HUB[<span style="color:#0ff;font-weight:bold">&#39;time_machine&#39;</span>] = (d2l.DATA_URL + <span style="color:#0ff;font-weight:bold">&#39;timemachine.txt&#39;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#0ff;font-weight:bold">&#39;090b5e7e70c295757f55df93cb0a180b9691891a&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> read_time_machine():  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;将时间机器数据集加载到文本行的列表中&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(d2l.download(<span style="color:#0ff;font-weight:bold">&#39;time_machine&#39;</span>), <span style="color:#0ff;font-weight:bold">&#39;r&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> f:
</span></span><span style="display:flex;"><span>        lines = f.readlines()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> [re.sub(<span style="color:#0ff;font-weight:bold">&#39;[^A-Za-z]+&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39; &#39;</span>, line).strip().lower() <span style="color:#fff;font-weight:bold">for</span> line in lines]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lines = read_time_machine() <span style="color:#007f7f"># list</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;# 文本总行数: </span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">len</span>(lines)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 文本总行数: 3221</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(lines[<span style="color:#ff0;font-weight:bold">0</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># the time machine by h g wells</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(lines[<span style="color:#ff0;font-weight:bold">10</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># twinkled and his usually pale face was flushed and animated the</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="22-词元化">2.2 词元化<a hidden class="anchor" aria-hidden="true" href="#22-词元化">#</a></h2>
<ul>
<li>词元(token)，通常指一个单词或字符</li>
<li>如下操作将每一行以词元为单位，拆分为一个list，结果返回一个list of list</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> tokenize(lines, token=<span style="color:#0ff;font-weight:bold">&#39;word&#39;</span>):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;将文本行拆分为单词或字符词元&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> token == <span style="color:#0ff;font-weight:bold">&#39;word&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> [line.split() <span style="color:#fff;font-weight:bold">for</span> line in lines]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">elif</span> token == <span style="color:#0ff;font-weight:bold">&#39;char&#39;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> [<span style="color:#fff;font-weight:bold">list</span>(line) <span style="color:#fff;font-weight:bold">for</span> line in lines]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;错误：未知词元类型：&#39;</span> + token)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens = tokenize(lines) <span style="color:#007f7f">#list of list, 内部list的元素即为词元</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(tokens[<span style="color:#ff0;font-weight:bold">0</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [&#39;the&#39;, &#39;time&#39;, &#39;machine&#39;, &#39;by&#39;, &#39;h&#39;, &#39;g&#39;, &#39;wells&#39;]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="23-词表">2.3 词表<a hidden class="anchor" aria-hidden="true" href="#23-词表">#</a></h2>
<ul>
<li>词元的类型是字符串，而模型需要的是数字；</li>
<li><strong>词表</strong>(Vocabulary)：类似于Python中的字典，将输入的词元转换为数字索引；</li>
<li><strong>语料库</strong>(Corpus)：对所有文本中唯一词元的统计结果，按频率降序排。
<ul>
<li>对于低频率出现的词元，可设置一定标准的阈值过滤；</li>
<li>对于语料库中不存在，或者已过滤的词元，将被映射到未知词元&rsquo;&lt;unk&gt;&rsquo;, 其数字索引记为0</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">59
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Vocab:  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;文本词表&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, tokens=<span style="color:#fff;font-weight:bold">None</span>, min_freq=<span style="color:#ff0;font-weight:bold">0</span>, reserved_tokens=<span style="color:#fff;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> tokens is <span style="color:#fff;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            tokens = []
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> reserved_tokens is <span style="color:#fff;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            reserved_tokens = []
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 按出现频率排序</span>
</span></span><span style="display:flex;"><span>        counter = count_corpus(tokens)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># counter.items() e.g. [(&#39;word1&#39;, 5), (&#39;word2&#39;, 3), (&#39;word3&#39;, 8)] </span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>._token_freqs = <span style="color:#fff;font-weight:bold">sorted</span>(counter.items(), key=<span style="color:#fff;font-weight:bold">lambda</span> x: x[<span style="color:#ff0;font-weight:bold">1</span>],
</span></span><span style="display:flex;"><span>                                   reverse=<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 未知词元的索引为0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.idx_to_token = [<span style="color:#0ff;font-weight:bold">&#39;&lt;unk&gt;&#39;</span>] + reserved_tokens
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.token_to_idx = {token: idx
</span></span><span style="display:flex;"><span>                             <span style="color:#fff;font-weight:bold">for</span> idx, token in <span style="color:#fff;font-weight:bold">enumerate</span>(<span style="color:#fff;font-weight:bold">self</span>.idx_to_token)}
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> token, freq in <span style="color:#fff;font-weight:bold">self</span>._token_freqs:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> freq &lt; min_freq:
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">break</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> token not in <span style="color:#fff;font-weight:bold">self</span>.token_to_idx:
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">self</span>.idx_to_token.append(token)
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">self</span>.token_to_idx[token] = <span style="color:#fff;font-weight:bold">len</span>(<span style="color:#fff;font-weight:bold">self</span>.idx_to_token) - <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __len__(<span style="color:#fff;font-weight:bold">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">len</span>(<span style="color:#fff;font-weight:bold">self</span>.idx_to_token)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>	<span style="color:#007f7f"># 如果传入单个词元，则返回其索引；如果传入词元列表，则返回对应的索引列表。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __getitem__(<span style="color:#fff;font-weight:bold">self</span>, tokens):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> not <span style="color:#fff;font-weight:bold">isinstance</span>(tokens, (<span style="color:#fff;font-weight:bold">list</span>, <span style="color:#fff;font-weight:bold">tuple</span>)):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.token_to_idx.get(tokens, <span style="color:#fff;font-weight:bold">self</span>.unk)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> [<span style="color:#fff;font-weight:bold">self</span>.__getitem__(token) <span style="color:#fff;font-weight:bold">for</span> token in tokens]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 根据输入的索引或索引列表返回对应的词元。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> to_tokens(<span style="color:#fff;font-weight:bold">self</span>, indices):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> not <span style="color:#fff;font-weight:bold">isinstance</span>(indices, (<span style="color:#fff;font-weight:bold">list</span>, <span style="color:#fff;font-weight:bold">tuple</span>)):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.idx_to_token[indices]
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> [<span style="color:#fff;font-weight:bold">self</span>.idx_to_token[index] <span style="color:#fff;font-weight:bold">for</span> index in indices]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    @property
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> unk(<span style="color:#fff;font-weight:bold">self</span>):  <span style="color:#007f7f"># 未知词元的索引为0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    @property
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> token_freqs(<span style="color:#fff;font-weight:bold">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>._token_freqs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> count_corpus(tokens):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;统计词元的频率&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 这里的tokens是1D列表或2D列表</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">len</span>(tokens) == <span style="color:#ff0;font-weight:bold">0</span> or <span style="color:#fff;font-weight:bold">isinstance</span>(tokens[<span style="color:#ff0;font-weight:bold">0</span>], <span style="color:#fff;font-weight:bold">list</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 将词元list of list列表展平成一个列表</span>
</span></span><span style="display:flex;"><span>        tokens = [token <span style="color:#fff;font-weight:bold">for</span> line in tokens <span style="color:#fff;font-weight:bold">for</span> token in line]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> collections.Counter(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vocab = Vocab(tokens)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">list</span>(vocab.token_to_idx.items())[:<span style="color:#ff0;font-weight:bold">5</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [(&#39;&lt;unk&gt;&#39;, 0), (&#39;the&#39;, 1), (&#39;i&#39;, 2), (&#39;and&#39;, 3), (&#39;of&#39;, 4)]</span>
</span></span><span style="display:flex;"><span>vocab.token_freqs[:<span style="color:#ff0;font-weight:bold">5</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [(&#39;the&#39;, 2261), (&#39;i&#39;, 1267), (&#39;and&#39;, 1245), (&#39;of&#39;, 1155), (&#39;a&#39;, 816)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="24-整合所有功能">2.4 整合所有功能<a hidden class="anchor" aria-hidden="true" href="#24-整合所有功能">#</a></h2>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> load_corpus_time_machine(max_tokens=-<span style="color:#ff0;font-weight:bold">1</span>):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;返回时光机器数据集的词元索引列表和词表&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    lines = read_time_machine()
</span></span><span style="display:flex;"><span>    tokens = tokenize(lines, <span style="color:#0ff;font-weight:bold">&#39;char&#39;</span>) <span style="color:#007f7f">#词元为字符</span>
</span></span><span style="display:flex;"><span>    vocab = Vocab(tokens)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 所以将所有文本行展平到一个列表中</span>
</span></span><span style="display:flex;"><span>    corpus = [vocab[token] <span style="color:#fff;font-weight:bold">for</span> line in tokens <span style="color:#fff;font-weight:bold">for</span> token in line]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> max_tokens &gt; <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>        corpus = corpus[:max_tokens]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> corpus, vocab
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># corpus 全部文本的词元</span>
</span></span><span style="display:flex;"><span>corpus, vocab = load_corpus_time_machine()
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">len</span>(corpus), <span style="color:#fff;font-weight:bold">len</span>(vocab)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (170580, 28)</span>
</span></span><span style="display:flex;"><span>corpus[:<span style="color:#ff0;font-weight:bold">5</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [3, 9, 2, 1, 3]</span>
</span></span><span style="display:flex;"><span>vocab.token_freqs[:<span style="color:#ff0;font-weight:bold">5</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [(&#39; &#39;, 29927), (&#39;e&#39;, 17838), (&#39;t&#39;, 13515), (&#39;a&#39;, 11704), (&#39;i&#39;, 10138)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="3-语言模型和数据集">3. 语言模型和数据集<a hidden class="anchor" aria-hidden="true" href="#3-语言模型和数据集">#</a></h1>
<h2 id="31-自然语言统计">3.1 自然语言统计<a hidden class="anchor" aria-hidden="true" href="#31-自然语言统计">#</a></h2>
<ul>
<li>单个词元统计（一元语法）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens = d2l.tokenize(d2l.read_time_machine())
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 将list of list转为list</span>
</span></span><span style="display:flex;"><span>corpus = [token <span style="color:#fff;font-weight:bold">for</span> line in tokens <span style="color:#fff;font-weight:bold">for</span> token in line]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vocab = d2l.Vocab(corpus)
</span></span><span style="display:flex;"><span>vocab.token_freqs[:<span style="color:#ff0;font-weight:bold">10</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [(&#39;the&#39;, 2261), (&#39;i&#39;, 1267), (&#39;and&#39;, 1245)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>两个连续词元统计（二元语法）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>bigram_tokens = [pair <span style="color:#fff;font-weight:bold">for</span> pair in <span style="color:#fff;font-weight:bold">zip</span>(corpus[:-<span style="color:#ff0;font-weight:bold">1</span>], corpus[<span style="color:#ff0;font-weight:bold">1</span>:])]
</span></span><span style="display:flex;"><span>bigram_tokens[:<span style="color:#ff0;font-weight:bold">3</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [(&#39;the&#39;, &#39;time&#39;), (&#39;time&#39;, &#39;machine&#39;), (&#39;machine&#39;, &#39;by&#39;)]</span>
</span></span><span style="display:flex;"><span>bigram_vocab = d2l.Vocab(bigram_tokens)
</span></span><span style="display:flex;"><span>bigram_vocab.token_freqs[:<span style="color:#ff0;font-weight:bold">3</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [((&#39;of&#39;, &#39;the&#39;), 309), ((&#39;in&#39;, &#39;the&#39;), 169), ((&#39;i&#39;, &#39;had&#39;), 130)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>三个连续词元统计（三元语法）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>trigram_tokens = [triple <span style="color:#fff;font-weight:bold">for</span> triple in <span style="color:#fff;font-weight:bold">zip</span>(
</span></span><span style="display:flex;"><span>    corpus[:-<span style="color:#ff0;font-weight:bold">2</span>], corpus[<span style="color:#ff0;font-weight:bold">1</span>:-<span style="color:#ff0;font-weight:bold">1</span>], corpus[<span style="color:#ff0;font-weight:bold">2</span>:])]
</span></span><span style="display:flex;"><span>trigram_vocab = d2l.Vocab(trigram_tokens)
</span></span><span style="display:flex;"><span>trigram_vocab.token_freqs[:<span style="color:#ff0;font-weight:bold">3</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [((&#39;the&#39;, &#39;time&#39;, &#39;traveller&#39;), 59),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  ((&#39;the&#39;, &#39;time&#39;, &#39;machine&#39;), 30),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  ((&#39;the&#39;, &#39;medical&#39;, &#39;man&#39;), 24)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>根据下图的频率分布可视化，可以看出：
<ul>
<li>三者均不同程度上遵循齐<a href="https://zh.wikipedia.org/zh-cn/%E9%BD%8A%E5%A4%AB%E5%AE%9A%E5%BE%8B">普夫定律</a>，呈现较为显著的衰减</li>
<li>少数高频词占了全部语料库的大多数，大部分可能形式的n元组很少出现</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>freqs = [freq <span style="color:#fff;font-weight:bold">for</span> token, freq in vocab.token_freqs]
</span></span><span style="display:flex;"><span>bigram_freqs = [freq <span style="color:#fff;font-weight:bold">for</span> token, freq in bigram_vocab.token_freqs]
</span></span><span style="display:flex;"><span>trigram_freqs = [freq <span style="color:#fff;font-weight:bold">for</span> token, freq in trigram_vocab.token_freqs]
</span></span><span style="display:flex;"><span>d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel=<span style="color:#0ff;font-weight:bold">&#39;token: x&#39;</span>,
</span></span><span style="display:flex;"><span>         ylabel=<span style="color:#0ff;font-weight:bold">&#39;frequency: n(x)&#39;</span>, xscale=<span style="color:#0ff;font-weight:bold">&#39;log&#39;</span>, yscale=<span style="color:#0ff;font-weight:bold">&#39;log&#39;</span>,
</span></span><span style="display:flex;"><span>         legend=[<span style="color:#0ff;font-weight:bold">&#39;unigram&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;bigram&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;trigram&#39;</span>])
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://zh-v2.d2l.ai/_images/output_language-models-and-dataset_789d14_66_0.svg" alt="../_images/output_language-models-and-dataset_789d14_66_0.svg"  />
</p>
<h2 id="32-读取长序列数据">3.2 读取长序列数据<a hidden class="anchor" aria-hidden="true" href="#32-读取长序列数据">#</a></h2>
<p>如前所述，在处理长序列时，通常仅考虑待预测数据前的若干节点的观测数据。</p>
<ul>
<li>
<p>batch_size：每个小批量同时处理的子序列样本数目；</p>
</li>
<li>
<p>num_steps：每个子序列中预定义的时间步数。</p>
</li>
<li>
<p>在小批量采样时，由如下两种方式（子序列的时间步数都不重叠）</p>
</li>
<li>
<p>随机偏移量：从一个随机起始点开始截取序列，增加每个epoch迭代的随机性</p>
</li>
</ul>
<p><strong>（1）随机抽样</strong></p>
<ul>
<li>每个批量样本之间的起始时间步数无顺序关系
<ul>
<li>e.g. 第一个小批量的第一个序列与第二个小批量的第一个序列无相邻的顺序关系</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> seq_data_iter_random(corpus, batch_size, num_steps):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;使用随机抽样生成一个小批量子序列&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 从随机偏移量开始对序列进行分区(随机丢弃开头的几个位置数据)，随机范围包括num_steps-1</span>
</span></span><span style="display:flex;"><span>    corpus = corpus[random.randint(<span style="color:#ff0;font-weight:bold">0</span>, num_steps - <span style="color:#ff0;font-weight:bold">1</span>):]
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 计算可以生成多少个不重叠的子序列(减去1，是因为我们需要考虑标签)</span>
</span></span><span style="display:flex;"><span>    num_subseqs = (<span style="color:#fff;font-weight:bold">len</span>(corpus) - <span style="color:#ff0;font-weight:bold">1</span>) // num_steps
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 每个子序列的起始索引</span>
</span></span><span style="display:flex;"><span>    initial_indices = <span style="color:#fff;font-weight:bold">list</span>(<span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, num_subseqs * num_steps, num_steps))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 打乱初始索引</span>
</span></span><span style="display:flex;"><span>    random.shuffle(initial_indices)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> data(pos):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 返回从pos位置开始的长度为num_steps的序列</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> corpus[pos: pos + num_steps]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#根据每个小批量包含的子序列数，计算有多少个批量</span>
</span></span><span style="display:flex;"><span>    num_batches = num_subseqs // batch_size
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, batch_size * num_batches, batch_size):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 在这里，每个批量内所有子序列的起始索引</span>
</span></span><span style="display:flex;"><span>        initial_indices_per_batch = initial_indices[i: i + batch_size]
</span></span><span style="display:flex;"><span>        X = [data(j) <span style="color:#fff;font-weight:bold">for</span> j in initial_indices_per_batch]
</span></span><span style="display:flex;"><span>        Y = [data(j + <span style="color:#ff0;font-weight:bold">1</span>) <span style="color:#fff;font-weight:bold">for</span> j in initial_indices_per_batch]
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">yield</span> torch.tensor(X), torch.tensor(Y)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>random_iter = seq_data_iter_random(<span style="color:#fff;font-weight:bold">list</span>(<span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">35</span>)), batch_size=<span style="color:#ff0;font-weight:bold">2</span>, num_steps=<span style="color:#ff0;font-weight:bold">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">next</span>(<span style="color:#fff;font-weight:bold">iter</span>(random_iter))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([[24, 25, 26, 27, 28],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [14, 15, 16, 17, 18]]),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[25, 26, 27, 28, 29],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [15, 16, 17, 18, 19]]))</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">next</span>(<span style="color:#fff;font-weight:bold">iter</span>(random_iter))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([[ 9, 10, 11, 12, 13],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 4,  5,  6,  7,  8]]),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[10, 11, 12, 13, 14],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [ 5,  6,  7,  8,  9]]))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>（2）顺序分区</p>
<ul>
<li>保证两个相邻的小批量中的子序列在原始序列上也是相邻的。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> seq_data_iter_sequential(corpus, batch_size, num_steps):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;使用顺序分区生成一个小批量子序列&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 从随机偏移量开始划分序列</span>
</span></span><span style="display:flex;"><span>    offset = random.randint(<span style="color:#ff0;font-weight:bold">0</span>, num_steps)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 确保可以被整除的tokens词元数量</span>
</span></span><span style="display:flex;"><span>    num_tokens = ((<span style="color:#fff;font-weight:bold">len</span>(corpus) - offset - <span style="color:#ff0;font-weight:bold">1</span>) // batch_size) * batch_size
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 所有作为特征的输入序列</span>
</span></span><span style="display:flex;"><span>    Xs = torch.tensor(corpus[offset: offset + num_tokens])
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 所有的标签值</span>
</span></span><span style="display:flex;"><span>    Ys = torch.tensor(corpus[offset + <span style="color:#ff0;font-weight:bold">1</span>: offset + <span style="color:#ff0;font-weight:bold">1</span> + num_tokens])
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 行数表示每个批量包含的子序列数</span>
</span></span><span style="display:flex;"><span>    Xs, Ys = Xs.reshape(batch_size, -<span style="color:#ff0;font-weight:bold">1</span>), Ys.reshape(batch_size, -<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>    num_batches = Xs.shape[<span style="color:#ff0;font-weight:bold">1</span>] // num_steps
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, num_steps * num_batches, num_steps):
</span></span><span style="display:flex;"><span>        X = Xs[:, i: i + num_steps]
</span></span><span style="display:flex;"><span>        Y = Ys[:, i: i + num_steps]
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">yield</span> X, Y
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>iter_seq = seq_data_iter_sequential(<span style="color:#fff;font-weight:bold">list</span>(<span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">35</span>)), batch_size=<span style="color:#ff0;font-weight:bold">2</span>, num_steps=<span style="color:#ff0;font-weight:bold">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">next</span>(<span style="color:#fff;font-weight:bold">iter</span>(iter_seq))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([[ 2,  3,  4,  5,  6],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [18, 19, 20, 21, 22]]),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[ 3,  4,  5,  6,  7],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [19, 20, 21, 22, 23]]))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">next</span>(<span style="color:#fff;font-weight:bold">iter</span>(iter_seq))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([[ 7,  8,  9, 10, 11],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [23, 24, 25, 26, 27]]),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[ 8,  9, 10, 11, 12],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#          [24, 25, 26, 27, 28]]))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Tips：无论上述哪一种方式，生成的序列样本数据都是不重叠的。</p></blockquote>
<p><strong>整合上述迭代方法</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 定义一个类，生成数据迭代器</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> SeqDataLoader:  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;加载序列数据的迭代器&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, batch_size, num_steps, use_random_iter, max_tokens):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> use_random_iter:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.data_iter_fn = d2l.seq_data_iter_random
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.data_iter_fn = d2l.seq_data_iter_sequential
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 返回所有文档的词元索引列表，以及词表vocab</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.corpus, <span style="color:#fff;font-weight:bold">self</span>.vocab = d2l.load_corpus_time_machine(max_tokens)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_steps = batch_size, num_steps
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __iter__(<span style="color:#fff;font-weight:bold">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.data_iter_fn(<span style="color:#fff;font-weight:bold">self</span>.corpus, <span style="color:#fff;font-weight:bold">self</span>.batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_steps)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 综合词表与数据迭代器</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> load_data_time_machine(batch_size, num_steps,  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>                           use_random_iter=<span style="color:#fff;font-weight:bold">False</span>, max_tokens=<span style="color:#ff0;font-weight:bold">10000</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;返回时光机器数据集的迭代器和词表&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    data_iter = SeqDataLoader(
</span></span><span style="display:flex;"><span>        batch_size, num_steps, use_random_iter, max_tokens)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> data_iter, data_iter.vocab
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="4-循环神经网络">4. 循环神经网络<a hidden class="anchor" aria-hidden="true" href="#4-循环神经网络">#</a></h1>
<ul>
<li>循环神经网络是具有<strong>隐状态</strong>的神经网络；</li>
<li>隐状态与隐藏层的概念截然不同
<ul>
<li>隐藏层是指在从输入到输出的路径上，隐藏的层；</li>
<li>隐状态可以理解为RNN中的记忆单元，它保存了序列中先前时间步的信息，并传递给后续的时间步。</li>
</ul>
</li>
</ul>
<h2 id="41-无隐状态的神经网络">4.1 无隐状态的神经网络<a hidden class="anchor" aria-hidden="true" href="#41-无隐状态的神经网络">#</a></h2>
<p>以简单的单隐藏层MLP为例：</p>
<ul>
<li>输入<strong>X</strong>，隐藏层输出<strong>H</strong>，隐藏层权重参数<strong>W</strong>xh，偏置参数<strong>b</strong></li>
<li>输出层<strong>O</strong>，权重参数<strong>W</strong>hq，偏置参数<strong>b</strong></li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807135451800.png" alt="image-20240807135451800"  />
</p>
<h2 id="42-有隐状态的神经网络">4.2 有隐状态的神经网络<a hidden class="anchor" aria-hidden="true" href="#42-有隐状态的神经网络">#</a></h2>
<p>对于一个特定时间步长的序列：</p>
<ul>
<li><strong>X</strong>t步的输出(<strong>O</strong>t，表示对于<strong>X</strong>t+1的预测)，取决于当前时间序列的隐状态<strong>H</strong>t；</li>
<li>而当前的隐状态<strong>H</strong>t由当前时间步的输入<strong>X</strong>t与前一个时间步的隐状态<strong>H</strong>t-1共同计算得出。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807140351095.png" alt="image-20240807140351095"  />
</p>
<ul>
<li>对于输入的小批量数据，由n个长度为T的序列样本组成。若样本特征长度为d时，则每次训练输入数据为 <strong>X</strong>t：n×d</li>
<li>基于<strong>X</strong>t的输入，参与<strong>H</strong>t计算的权重参数为<strong>W</strong>xh；基于<strong>H</strong>t-1隐状态，参与<strong>H</strong>t计算的权重参数为<strong>W</strong>hh，此外还有偏置；</li>
<li>从<strong>H</strong>t隐状态，最终计算<strong>O</strong>t的权重参数为<strong>W</strong>hq，以及偏置。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807143437717.png" alt="image-20240807143437717"  />
</p>
<blockquote>
<p>（1）如上可以看出，有隐状态的神经网络从公式上来看，与单隐藏层的神经网络非常类似。只是多了一项<strong>W</strong>xh参数的计算过程。</p>
<p>（2）在同一批量的不同时间节点迭代时，仍然是上述这些模型参数。即模型参数的开销不会随着时间步的增加而增加。</p></blockquote>
<ul>
<li>如下，演示同时对特定一个批量内多个子序列的第i个词元的隐状态计算：
<ul>
<li>输入的批量包含3条子序列，每条子序列中单个词元的特征长度为1；</li>
<li>隐状态的神经元个数设置为4。</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X, W_xh = torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">1</span>)), torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">4</span>))
</span></span><span style="display:flex;"><span>H, W_hh = torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">4</span>)), torch.normal(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span>, (<span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">4</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch.matmul(X, W_xh) + torch.matmul(H, W_hh)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="43-基于rnn的字符级语言模型">4.3 基于RNN的字符级语言模型<a hidden class="anchor" aria-hidden="true" href="#43-基于rnn的字符级语言模型">#</a></h2>
<ul>
<li>在字符级语言模型中，文本词元为字符而不是单词；</li>
<li>如下可以理解为小批量大小为1，文本序列为&rsquo;machine'</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807145613774.png" alt="image-20240807145613774"  />
</p>
<h2 id="44-困惑度">4.4 困惑度<a hidden class="anchor" aria-hidden="true" href="#44-困惑度">#</a></h2>
<ul>
<li>语言模型大部分情况下可以理解为<strong>分类</strong>问题，可以利用<strong>交叉熵</strong>计算模型输入与标签之间的差异；</li>
<li>模型性能(损失)可根据一个序列中所有词元(n)的平均交叉熵损失来衡量；</li>
<li>实际建模时，自然语言处理的科学家更喜欢使用<strong>困惑度</strong>(Perplexity)指标。本质上只是对上述进行<a href="https://zh.wikipedia.org/zh-cn/%E6%8C%87%E6%95%B0%E5%87%BD%E6%95%B0">exp指数运算</a>。</li>
<li>该指标可以理解为对下一个词元的实际选择数的调和平均数。
<ul>
<li>困惑度越低，说明模型的预测效果越好。最好的情况为1，即完美地估计了标签词元；</li>
<li>如果困惑度为 k<em>k</em>，那么可以理解为模型预测下一个词时的候选词数量大致为 k。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807151122573.png" alt="image-20240807151122573"  />
</p>
<h1 id="5-rnn的从零实现">5. RNN的从零实现<a hidden class="anchor" aria-hidden="true" href="#5-rnn的从零实现">#</a></h1>
<p>从零开始基于RNN实现字符级语言模型</p>
<ul>
<li>读取数据集
<ul>
<li>batch_size表示每个批量同时读取/处理多少条子序列</li>
<li>num_steps表示每条子序列的长度</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> functional <span style="color:#fff;font-weight:bold">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="51-独热编码">5.1 独热编码<a hidden class="anchor" aria-hidden="true" href="#51-独热编码">#</a></h2>
<ul>
<li>每个词元经转换后表示为一个数字索引，然后经独热编码表示为特征向量；</li>
<li>若词表的唯一词元有N个(<code>len(vocab)</code>)，则词元索引范围是 0~N-1，其特征向量长度为N</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>F.one_hot(torch.tensor([<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>]), <span style="color:#fff;font-weight:bold">len</span>(vocab)).shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([2, 28])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>特征编码前，小批量输入形状为二维张量（批量大小，时间步数/序列长度）</li>
<li>编码后则为3维张量，需要再调整下维度的顺序，方便后续操作。（时间步数/序列长度，批量大小，词表大小/特征长度）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 批量大小为2，序列长度为5</span>
</span></span><span style="display:flex;"><span>X = torch.arange(<span style="color:#ff0;font-weight:bold">10</span>).reshape((<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#X.T转置操作，将序列长度维数放在前面之后，再进行独热编码</span>
</span></span><span style="display:flex;"><span>F.one_hot(X.T, <span style="color:#ff0;font-weight:bold">28</span>).shape 
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([5, 2, 28])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="52-初始化模型参数">5.2 初始化模型参数<a hidden class="anchor" aria-hidden="true" href="#52-初始化模型参数">#</a></h2>
<ul>
<li>RNN模型参数可参考4.2部分介绍，主要分为隐状态参数与输出层参数</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_params(vocab_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 输入与输出的词元的特征向量长度相同</span>
</span></span><span style="display:flex;"><span>    num_inputs = num_outputs = vocab_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> normal(shape):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> torch.randn(size=shape, device=device) * <span style="color:#ff0;font-weight:bold">0.01</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 隐藏层参数</span>
</span></span><span style="display:flex;"><span>    W_xh = normal((num_inputs, num_hiddens))
</span></span><span style="display:flex;"><span>    W_hh = normal((num_hiddens, num_hiddens))
</span></span><span style="display:flex;"><span>    b_h = torch.zeros(num_hiddens, device=device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 输出层参数，num_outputs等于词元类别数</span>
</span></span><span style="display:flex;"><span>    W_hq = normal((num_hiddens, num_outputs))
</span></span><span style="display:flex;"><span>    b_q = torch.zeros(num_outputs, device=device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 附加梯度</span>
</span></span><span style="display:flex;"><span>    params = [W_xh, W_hh, b_h, W_hq, b_q]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> param in params:
</span></span><span style="display:flex;"><span>        param.requires_grad_(<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> params
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="53-rnn模型">5.3 RNN模型<a hidden class="anchor" aria-hidden="true" href="#53-rnn模型">#</a></h2>
<ul>
<li>初始化隐状态，形状为（批量大小，隐藏单元数）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> init_rnn_state(batch_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> (torch.zeros((batch_size, num_hiddens), device=device), )
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 这里返回元组，因为后面章节的隐状态会有多个变量（LSTM）</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义前向传播函数，返回一轮batch的预测结果（批量大小×序列长度，词表大小），以及更新的隐状态
<ul>
<li>输入inputs为上述5.1所介绍的三维张量</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> rnn(inputs, state, params):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># inputs的形状：(时间步数量，批量大小，词表大小)</span>
</span></span><span style="display:flex;"><span>    W_xh, W_hh, b_h, W_hq, b_q = params
</span></span><span style="display:flex;"><span>    H, = state
</span></span><span style="display:flex;"><span>    outputs = []
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 逐时间步迭代：X的形状为(批量大小，词表大小)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> X in inputs:
</span></span><span style="display:flex;"><span>        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
</span></span><span style="display:flex;"><span>        Y = torch.mm(H, W_hq) + b_q
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># Y形状：(批量大小，词表大小)</span>
</span></span><span style="display:flex;"><span>        outputs.append(Y)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> torch.cat(outputs, dim=<span style="color:#ff0;font-weight:bold">0</span>), (H,) 
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#纵向叠加，增加行数，列数不变，维度不变</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义模型的类</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> RNNModelScratch: <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;从零开始实现的循环神经网络模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, vocab_size, num_hiddens, device,
</span></span><span style="display:flex;"><span>                 get_params, init_state, forward_fn):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.vocab_size, <span style="color:#fff;font-weight:bold">self</span>.num_hiddens = vocab_size, num_hiddens
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.params = get_params(vocab_size, num_hiddens, device)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.init_state, <span style="color:#fff;font-weight:bold">self</span>.forward_fn = init_state, forward_fn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __call__(<span style="color:#fff;font-weight:bold">self</span>, X, state):
</span></span><span style="display:flex;"><span>        X = F.one_hot(X.T, <span style="color:#fff;font-weight:bold">self</span>.vocab_size).type(torch.float32)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.forward_fn(X, state, <span style="color:#fff;font-weight:bold">self</span>.params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> begin_state(<span style="color:#fff;font-weight:bold">self</span>, batch_size, device):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.init_state(batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_hiddens, device)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例输出</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_hiddens = <span style="color:#ff0;font-weight:bold">512</span>
</span></span><span style="display:flex;"><span>net = RNNModelScratch(<span style="color:#fff;font-weight:bold">len</span>(vocab), num_hiddens, d2l.try_gpu(), get_params,
</span></span><span style="display:flex;"><span>                      init_rnn_state, rnn)
</span></span><span style="display:flex;"><span>state = net.begin_state(X.shape[<span style="color:#ff0;font-weight:bold">0</span>], d2l.try_gpu())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 批量包含的序列数为2，序列长度为5</span>
</span></span><span style="display:flex;"><span>X = torch.arange(<span style="color:#ff0;font-weight:bold">10</span>).reshape((<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y, new_state = net(X.to(d2l.try_gpu()), state)
</span></span><span style="display:flex;"><span>Y.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([10, 28])</span>
</span></span><span style="display:flex;"><span>new_state[<span style="color:#ff0;font-weight:bold">0</span>].shape <span style="color:#007f7f">#批量内每个子序列最后一个时间步的隐状态</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([2, 512])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="54-预测">5.4 预测<a hidden class="anchor" aria-hidden="true" href="#54-预测">#</a></h2>
<ul>
<li>prefix：包含若干词元的初始文本</li>
<li>num_preds：往后预测多少个词元</li>
<li>在预测过程中，首先逐个遍历给定的初始词元，但不做预测，仅用于更新隐状态。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> predict_ch8(prefix, num_preds, net, vocab, device):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;在prefix后面生成新字符&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># batch_size=1表示单批量逐个预测</span>
</span></span><span style="display:flex;"><span>    state = net.begin_state(batch_size=<span style="color:#ff0;font-weight:bold">1</span>, device=device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 首先将prefix的第一个词元加入到outputs中</span>
</span></span><span style="display:flex;"><span>    outputs = [vocab[prefix[<span style="color:#ff0;font-weight:bold">0</span>]]]
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 取outputs里最新的一个词元，作为预测下一个词元的输入</span>
</span></span><span style="display:flex;"><span>    get_input = <span style="color:#fff;font-weight:bold">lambda</span>: torch.tensor([outputs[-<span style="color:#ff0;font-weight:bold">1</span>]], device=device).reshape((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> y in prefix[<span style="color:#ff0;font-weight:bold">1</span>:]:  <span style="color:#007f7f"># 预热期</span>
</span></span><span style="display:flex;"><span>        _, state = net(get_input(), state)
</span></span><span style="display:flex;"><span>        outputs.append(vocab[y]) <span style="color:#007f7f">#传入真实值</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> _ in <span style="color:#fff;font-weight:bold">range</span>(num_preds):  <span style="color:#007f7f"># 预测num_preds步</span>
</span></span><span style="display:flex;"><span>        y, state = net(get_input(), state)
</span></span><span style="display:flex;"><span>        outputs.append(<span style="color:#fff;font-weight:bold">int</span>(y.argmax(dim=<span style="color:#ff0;font-weight:bold">1</span>).reshape(<span style="color:#ff0;font-weight:bold">1</span>))) <span style="color:#007f7f">#传入预测值</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> <span style="color:#0ff;font-weight:bold">&#39;&#39;</span>.join([vocab.idx_to_token[i] <span style="color:#fff;font-weight:bold">for</span> i in outputs])
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>predict_ch8(<span style="color:#0ff;font-weight:bold">&#39;time traveller &#39;</span>, <span style="color:#ff0;font-weight:bold">10</span>, net, vocab, d2l.try_gpu())
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># &#39;time traveller xejnnnnnnn&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="55-梯度剪裁">5.5 梯度剪裁<a hidden class="anchor" aria-hidden="true" href="#55-梯度剪裁">#</a></h2>
<ul>
<li>对于长度为T的序列，训练时会执行T次矩阵乘法，来进行反向传播、更新梯度。</li>
<li>这对于较长的序列，可能会导致梯度爆炸，模型无法收敛。</li>
<li>此时，可以通过梯度剪裁，将参数的梯度的范数设置一个上限θ（不改变方向）。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> grad_clipping(net, theta):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;裁剪梯度&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(net, nn.Module):
</span></span><span style="display:flex;"><span>        params = [p <span style="color:#fff;font-weight:bold">for</span> p in net.parameters() <span style="color:#fff;font-weight:bold">if</span> p.requires_grad]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        params = net.params
</span></span><span style="display:flex;"><span>    norm = torch.sqrt(<span style="color:#fff;font-weight:bold">sum</span>(torch.sum((p.grad ** <span style="color:#ff0;font-weight:bold">2</span>)) <span style="color:#fff;font-weight:bold">for</span> p in params))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#若范数长度大于θ，就设置其值为θ</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> norm &gt; theta:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> param in params:
</span></span><span style="display:flex;"><span>            param.grad[:] *= theta / norm
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="56-训练">5.6 训练<a hidden class="anchor" aria-hidden="true" href="#56-训练">#</a></h2>
<ul>
<li>在3.2小节中，学习了两种小批量序列样本迭代方法：（1）顺序分区；（2）随机抽样</li>
<li>对于顺序分区，相邻两个batch iteration中，对应的第i个子序列的位序也是相邻的。
<ul>
<li>隐状态仅需要在刚开始时初始化一次。在后面的多轮小批量训练时，可以继承。</li>
<li>为减少计算量，在处理每个批量数据前，对隐状态参数梯度分离。</li>
</ul>
</li>
<li>对于随机抽样，相邻两个batch iteration的序列样本无确定关系（更常用些）
<ul>
<li>隐状态在每个batch iteration时，都需要随机初始化（其权重参数是持续更新的）。</li>
</ul>
</li>
<li>如下为训练一个epoch的代码</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;训练网络一个迭代周期（定义见第8章）&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    state, timer = <span style="color:#fff;font-weight:bold">None</span>, d2l.Timer()
</span></span><span style="display:flex;"><span>    metric = d2l.Accumulator(<span style="color:#ff0;font-weight:bold">2</span>)  <span style="color:#007f7f"># 训练损失之和,词元数量</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> X, Y in train_iter:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> state is <span style="color:#fff;font-weight:bold">None</span> or use_random_iter:
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># 在第一次迭代或使用随机抽样时初始化state</span>
</span></span><span style="display:flex;"><span>            state = net.begin_state(batch_size=X.shape[<span style="color:#ff0;font-weight:bold">0</span>], device=device)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(net, nn.Module) and not <span style="color:#fff;font-weight:bold">isinstance</span>(state, <span style="color:#fff;font-weight:bold">tuple</span>):
</span></span><span style="display:flex;"><span>                <span style="color:#007f7f"># state对于nn.GRU是个张量</span>
</span></span><span style="display:flex;"><span>                state.detach_()
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#007f7f"># state对于nn.LSTM或对于我们从零开始实现的模型是个张量</span>
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">for</span> s in state:
</span></span><span style="display:flex;"><span>                    s.detach_()
</span></span><span style="display:flex;"><span>        y = Y.T.reshape(-<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>        X, y = X.to(device), y.to(device)
</span></span><span style="display:flex;"><span>        y_hat, state = net(X, state)
</span></span><span style="display:flex;"><span>        l = loss(y_hat, y.long()).mean() <span style="color:#007f7f"># y转为长整型(64位整数)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(updater, torch.optim.Optimizer):
</span></span><span style="display:flex;"><span>            updater.zero_grad()
</span></span><span style="display:flex;"><span>            l.backward()
</span></span><span style="display:flex;"><span>            grad_clipping(net, <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>            updater.step()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            l.backward()
</span></span><span style="display:flex;"><span>            grad_clipping(net, <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># 因为已经调用了mean函数</span>
</span></span><span style="display:flex;"><span>            updater(batch_size=<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>        metric.add(l * y.numel(), y.numel())
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> math.exp(metric[<span style="color:#ff0;font-weight:bold">0</span>] / metric[<span style="color:#ff0;font-weight:bold">1</span>]), metric[<span style="color:#ff0;font-weight:bold">1</span>] / timer.stop()
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>如下为训练的最终形式</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_ch8(net, train_iter, vocab, lr, num_epochs, device,
</span></span><span style="display:flex;"><span>              use_random_iter=<span style="color:#fff;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;训练模型（定义见第8章）&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    loss = nn.CrossEntropyLoss()
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(xlabel=<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, ylabel=<span style="color:#0ff;font-weight:bold">&#39;perplexity&#39;</span>,
</span></span><span style="display:flex;"><span>                            legend=[<span style="color:#0ff;font-weight:bold">&#39;train&#39;</span>], xlim=[<span style="color:#ff0;font-weight:bold">10</span>, num_epochs])
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 初始化</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(net, nn.Module):
</span></span><span style="display:flex;"><span>        updater = torch.optim.SGD(net.parameters(), lr)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        updater = <span style="color:#fff;font-weight:bold">lambda</span> batch_size: d2l.sgd(net.params, lr, batch_size)
</span></span><span style="display:flex;"><span>    predict = <span style="color:#fff;font-weight:bold">lambda</span> prefix: predict_ch8(prefix, <span style="color:#ff0;font-weight:bold">50</span>, net, vocab, device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 训练和预测</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        ppl, speed = train_epoch_ch8(
</span></span><span style="display:flex;"><span>            net, train_iter, loss, updater, device, use_random_iter)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> (epoch + <span style="color:#ff0;font-weight:bold">1</span>) % <span style="color:#ff0;font-weight:bold">10</span> == <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">print</span>(predict(<span style="color:#0ff;font-weight:bold">&#39;time traveller&#39;</span>))
</span></span><span style="display:flex;"><span>            animator.add(epoch + <span style="color:#ff0;font-weight:bold">1</span>, [ppl])
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;困惑度 </span><span style="color:#0ff;font-weight:bold">{</span>ppl<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, </span><span style="color:#0ff;font-weight:bold">{</span>speed<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold"> 词元/秒 </span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">str</span>(device)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(predict(<span style="color:#0ff;font-weight:bold">&#39;time traveller&#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(predict(<span style="color:#0ff;font-weight:bold">&#39;traveller&#39;</span>))
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>实际训练</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">## 训练--顺序分区（下图左）</span>
</span></span><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 困惑度 1.0, 38769.2 词元/秒 cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time travelleryou can show black is white by argument said filby</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travelleryou can show black is white by argument said filby</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">## 训练--随机抽样（下图右）</span>
</span></span><span style="display:flex;"><span>net = RNNModelScratch(<span style="color:#fff;font-weight:bold">len</span>(vocab), num_hiddens, d2l.try_gpu(), get_params,
</span></span><span style="display:flex;"><span>                      init_rnn_state, rnn)
</span></span><span style="display:flex;"><span>train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),
</span></span><span style="display:flex;"><span>          use_random_iter=<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 困惑度 1.5, 37930.8 词元/秒 cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time travellerit s against reason said filbywas allaing the time</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travellerit s against reason said filbywas allaing the time</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240807190952553.png" alt="image-20240807190952553"  />
</p>
<h1 id="6-rnn的简洁实现">6. RNN的简洁实现<a hidden class="anchor" aria-hidden="true" href="#6-rnn的简洁实现">#</a></h1>
<ul>
<li>准备数据</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> functional <span style="color:#fff;font-weight:bold">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="61-定义模型">6.1 定义模型<a hidden class="anchor" aria-hidden="true" href="#61-定义模型">#</a></h2>
<ul>
<li>基于torch的<code>nn.RNN</code>，定义一个具有256个隐藏单元的单隐藏层，其不涉及输出层的计算</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_hiddens = <span style="color:#ff0;font-weight:bold">256</span>
</span></span><span style="display:flex;"><span>rnn_layer = nn.RNN(<span style="color:#fff;font-weight:bold">len</span>(vocab), num_hiddens)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>初始化隐状态，形状为（隐藏层数，批量大小，隐藏单元数）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>state = torch.zeros((<span style="color:#ff0;font-weight:bold">1</span>, batch_size, num_hiddens))
</span></span><span style="display:flex;"><span>state.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([1, 32, 256])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>模拟计算，更新隐状态
<ul>
<li>如下的Y表示，所有批量的子序列的最后一层的隐状态（一般后面需要再接MLP预测<strong>O</strong>t输出）</li>
<li>state_new表示所有批量的子序列的最后一步的隐状态</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X = torch.rand(size=(num_steps, batch_size, <span style="color:#fff;font-weight:bold">len</span>(vocab)))
</span></span><span style="display:flex;"><span>Y, state_new = rnn_layer(X, state)
</span></span><span style="display:flex;"><span>Y.shape, state_new.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 35为序列长度</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 32为批量大小</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 256 隐藏层单元数</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义一个完整的RNNModel类</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> RNNModel(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;循环神经网络模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, rnn_layer, vocab_size, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(RNNModel, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.rnn = rnn_layer
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.vocab_size = vocab_size
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.num_hiddens = <span style="color:#fff;font-weight:bold">self</span>.rnn.hidden_size
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> not <span style="color:#fff;font-weight:bold">self</span>.rnn.bidirectional:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.num_directions = <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.linear = nn.Linear(<span style="color:#fff;font-weight:bold">self</span>.num_hiddens, <span style="color:#fff;font-weight:bold">self</span>.vocab_size)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.num_directions = <span style="color:#ff0;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">self</span>.linear = nn.Linear(<span style="color:#fff;font-weight:bold">self</span>.num_hiddens * <span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#fff;font-weight:bold">self</span>.vocab_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, inputs, state):
</span></span><span style="display:flex;"><span>        X = F.one_hot(inputs.T.long(), <span style="color:#fff;font-weight:bold">self</span>.vocab_size)
</span></span><span style="display:flex;"><span>        X = X.to(torch.float32)
</span></span><span style="display:flex;"><span>        Y, state = <span style="color:#fff;font-weight:bold">self</span>.rnn(X, state)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 它的输出形状是(时间步数*批量大小,词表大小)。</span>
</span></span><span style="display:flex;"><span>        output = <span style="color:#fff;font-weight:bold">self</span>.linear(Y.reshape((-<span style="color:#ff0;font-weight:bold">1</span>, Y.shape[-<span style="color:#ff0;font-weight:bold">1</span>])))
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> output, state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> begin_state(<span style="color:#fff;font-weight:bold">self</span>, device, batch_size=<span style="color:#ff0;font-weight:bold">1</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> not <span style="color:#fff;font-weight:bold">isinstance</span>(<span style="color:#fff;font-weight:bold">self</span>.rnn, nn.LSTM):
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># nn.GRU以张量作为隐状态</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">return</span>  torch.zeros((<span style="color:#fff;font-weight:bold">self</span>.num_directions * <span style="color:#fff;font-weight:bold">self</span>.rnn.num_layers,
</span></span><span style="display:flex;"><span>                                 batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_hiddens),
</span></span><span style="display:flex;"><span>                                device=device)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># nn.LSTM以元组作为隐状态</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">return</span> (torch.zeros((
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">self</span>.num_directions * <span style="color:#fff;font-weight:bold">self</span>.rnn.num_layers,
</span></span><span style="display:flex;"><span>                batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_hiddens), device=device),
</span></span><span style="display:flex;"><span>                    torch.zeros((
</span></span><span style="display:flex;"><span>                        <span style="color:#fff;font-weight:bold">self</span>.num_directions * <span style="color:#fff;font-weight:bold">self</span>.rnn.num_layers,
</span></span><span style="display:flex;"><span>                        batch_size, <span style="color:#fff;font-weight:bold">self</span>.num_hiddens), device=device))
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="62-训练与预测">6.2 训练与预测<a hidden class="anchor" aria-hidden="true" href="#62-训练与预测">#</a></h2>
<ul>
<li>训练函数仍参考5.6小节</li>
<li>实例化模型</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>device = d2l.try_gpu()
</span></span><span style="display:flex;"><span>net = RNNModel(rnn_layer, vocab_size=<span style="color:#fff;font-weight:bold">len</span>(vocab))
</span></span><span style="display:flex;"><span>net = net.to(device)
</span></span><span style="display:flex;"><span>d2l.predict_ch8(<span style="color:#0ff;font-weight:bold">&#39;time traveller&#39;</span>, <span style="color:#ff0;font-weight:bold">10</span>, net, vocab, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># &#39;time travellerpppwllllll&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>训练模型</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.3, 255236.1 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time traveller but now you be in aly has we mave the gratienttan</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travellerit s ala to be accupted is an absolute procimind a</span>
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lishensuo.github.io/en/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
      <li><a href="https://lishensuo.github.io/en/tags/d2l/">D2L</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lishensuo.github.io/en/posts/bioinfo/710d2l-%E7%AC%AC%E4%B8%83%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
    <span class="title">« Prev Page</span>
    <br>
    <span>D2L--第七章现代卷积神经网络</span>
  </a>
  <a class="next" href="https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
    <span class="title">Next Page »</span>
    <br>
    <span>D2L--第九章现代循环神经网络</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lishensuo.github.io/en/">Li&#39;s Bioinfo-Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
		<br/>您是本站第 <span id="busuanzi_value_site_uv"></span> 位访问者，总浏览量为 <span id="busuanzi_value_site_pv"></span> 次
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>

<script type="text/javascript"
async
src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
displayMath: [['$$','$$'], ['\[\[','\]\]']],
processEscapes: true,
processEnvironments: true,
skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
TeX: { equationNumbers: { autoNumber: "AMS" },
extensions: ["AMSmath.js", "AMSsymbols.js"] }
}
});

MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style></body>
</html>

<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">

<link rel="icon" href="/favicon.ico" type="image/x-icon"> 
<title>D2L--第十一及十二章优化算法&amp;多GPU并行 | Li&#39;s Bioinfo-Blog</title>
<meta name="keywords" content="深度学习, D2L">
<meta name="description" content="
在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以最小化损失函数。

由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。




NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。">
<meta name="author" content="Lishensuo">
<link rel="canonical" href="https://lishensuo.github.io/en/posts/bioinfo/715d2l-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8F%8A%E5%8D%81%E4%BA%8C%E7%AB%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%A4%9Agpu%E5%B9%B6%E8%A1%8C/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.9e4de5e3ba61ea358168341aa7cdf70abfaafb7c697dfe8624af3ddff9a35c2f.css" integrity="sha256-nk3l47ph6jWBaDQap833Cr&#43;q&#43;3xpff6GJK893/mjXC8=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.555af97124d54bb1457985dd081b8f5616a48103aafeb30ac89fde835d65aa6c.js" integrity="sha256-VVr5cSTVS7FFeYXdCBuPVhakgQOq/rMKyJ/eg11lqmw="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://lishensuo.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://lishensuo.github.io/Q.gif">
<link rel="mask-icon" href="https://lishensuo.github.io/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lishensuo.github.io/en/posts/bioinfo/715d2l-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8F%8A%E5%8D%81%E4%BA%8C%E7%AB%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%A4%9Agpu%E5%B9%B6%E8%A1%8C/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="D2L--第十一及十二章优化算法&amp;多GPU并行" />
<meta property="og:description" content="
在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以最小化损失函数。

由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。




NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lishensuo.github.io/en/posts/bioinfo/715d2l-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8F%8A%E5%8D%81%E4%BA%8C%E7%AB%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%A4%9Agpu%E5%B9%B6%E8%A1%8C/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-24T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-08-24T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="D2L--第十一及十二章优化算法&amp;多GPU并行"/>
<meta name="twitter:description" content="
在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以最小化损失函数。

由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。




NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "分类",
      "item": "https://lishensuo.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📖 生信数据分析--分析流程，工具包等",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "D2L--第十一及十二章优化算法\u0026多GPU并行",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/715d2l-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8F%8A%E5%8D%81%E4%BA%8C%E7%AB%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%A4%9Agpu%E5%B9%B6%E8%A1%8C/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "D2L--第十一及十二章优化算法\u0026多GPU并行",
  "name": "D2L--第十一及十二章优化算法\u0026多GPU并行",
  "description": " 在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以最小化损失函数。 由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。 NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。\n",
  "keywords": [
    "深度学习", "D2L"
  ],
  "articleBody": " 在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以最小化损失函数。 由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少训练误差。 NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。\n深度学习问题绝大部分都是非凸函数，使得优化算法可能陷入这些局部最小值而不是找到全局最小值。 不过在实践中，对于很多深度学习任务，即使找到的是局部最小值，模型的表现也可以是非常好的。 本章节将简单学习目前深度学习领域比较常用的几种优化算法 1. 示例任务 NASA开发的测试机翼的数据集不同飞行器产生的噪声 使用前1500样本，并将数据进行归一化处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 %matplotlib inline import numpy as np import torch from torch import nn from d2l import torch as d2l #@save d2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat', '76e5be1548fd8222e5074cf0faae75edff8cf93f') #@save def get_data_ch11(batch_size=10, n=1500): data = np.genfromtxt(d2l.download('airfoil'), dtype=np.float32, delimiter='\\t') data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0)) data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]), #最后一列作为标签 batch_size, is_train=True) return data_iter, data.shape[1]-1 定义一个通用的训练函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #@save def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4): # 初始化模型：只有一个隐藏层的MLP net = nn.Sequential(nn.Linear(5, 1)) def init_weights(m): if type(m) == nn.Linear: torch.nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) #优化器 optimizer = trainer_fn(net.parameters(), **hyperparams) #损失函数 loss = nn.MSELoss(reduction='none') animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[0, num_epochs], ylim=[0.22, 0.35]) n, timer = 0, d2l.Timer() for _ in range(num_epochs): #每个epoch for X, y in data_iter: #每个batch optimizer.zero_grad() out = net(X) y = y.reshape(out.shape) l = loss(out, y) l.mean().backward() optimizer.step() n += X.shape[0] if n % 200 == 0: timer.stop() # MSELoss计算平方误差时不带系数1/2 animator.add(n/X.shape[0]/len(data_iter), (d2l.evaluate_loss(net, data_iter, loss) / 2,)) timer.start() print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch') 2. SGD 梯度下降(Gradient Descent): 在每次迭代中，批量梯度下降会使用所有训练样本计算损失函数的梯度，然后根据这个梯度更新模型参数。 计算代价高，因为每次迭代都需要遍历整个训练集。 随机梯度下降(Stochastic Gradient Descent, SGD): 在每次迭代中，随机梯度下降只选取一个训练样本（或者随机选择一个样本）来计算损失函数的梯度，然后根据这个梯度更新模型参数。 收敛过程可能会比较震荡，并且无法完全利用CPU/GPU硬件资源。 小批量随机梯度下降(Mini-batch SGD): 在每次迭代中，小批量随机梯度下降从训练集中随机抽取一个小批量（batch）的样本集合来计算损失函数的梯度，然后根据这个梯度更新模型参数。 为上述两种优化方式的折中方案，比批量梯度下降快，比随机梯度下降更稳定。 可通过torch的torch.optim.SGD快速实现 1 2 3 4 5 data_iter, _ = get_data_ch11(10) # 定义优化器 trainer = torch.optim.SGD # 训练 train_concise_ch11(trainer, {'lr': 0.01}, data_iter) 3. 动量法 如下公式，gt表示在t时刻计算的损失函数梯度；vt则考虑了过去梯度的累加，称为动量(momentum)。 β值越大，则考虑了过去时刻的梯度越多 常见的β取值包括0.5, 0.9, 0.95, 0.99 通常来说，动量法通过在参数更新时引入“动量”，使得梯度下降更稳定和快速。 可以直接在torch.optim.SGD中添加momentum参数，设置动量法 1 2 3 4 5 # 定义优化器 trainer = torch.optim.SGD # 训练 d2l.train_concise_ch11(trainer, {'lr': 0.005, 'momentum': 0.9}, data_iter) SGD+动量法的优化效果对于某些任务不必Adam差。\n4. 自适应学习率 4.1 AdaGrad 梯度下降方法使用固定的学习率，这意味着所有参数以相同的速度更新。自适应学习率方法为每个参数提供一个动态调整的学习率，这允许算法更加灵活地适应不同的参数需求。\n**AdaGrad (Adaptive Gradient)**使用每个参数的历史梯度平方的累积和来调整学习率。 在梯度较大的参数上采用较小的学习率，而在梯度较小的参数上采用较大的学习率。 缺点在于，学习率随着训练时间的增加会变得非常小，导致训练提前停止。 可通过torch的torch.optim.Adagrad快速实现。 1 2 3 4 5 # 定义优化器 trainer = torch.optim.Adagrad # 训练 d2l.train_concise_ch11(trainer, {'lr': 0.1}, data_iter) #初始学习率 4.2 RMSprop **RMSprop (Root Mean Square Propagation)**是 AdaGrad 的一个改进版本 它通过使用指数加权平均数来平滑历史梯度的平方，解决了 AdaGrad 中学习率过早衰减的问题。 alpha参数用于设置平滑方式： 当 alpha 接近 1 时，算法更加重视过去的历史梯度信息； 当 alpha 接近 0 时，则更多地依赖于最近的梯度信息。 可通过torch的torch.optim.RMSprop快速实现。 1 2 3 4 5 # 定义优化器 trainer = torch.optim.RMSprop # 训练 d2l.train_concise_ch11(trainer, {'lr': 0.01, 'alpha': 0.9}, data_iter) 4.3 Adam **Adam (Adaptive Moment Estimation)**是一种结合了动量法和 RMSprop 的优点的自适应学习率优化算法，是目前最常用的优化算法之一。 它同时使用了一阶矩（动量）和二阶矩（梯度平方的指数加权平均）来更新参数。 一阶矩用来平滑梯度（β1,通常取0.9）； 二阶矩（β2）用来平滑梯度的平方（β2,通常取0.999）。 可通过torch的torch.optim.Adam快速实现。 1 2 3 4 5 # 定义优化器 trainer = torch.optim.Adam # 训练 d2l.train_concise_ch11(trainer, {'lr': 0.01}, data_iter) Yogi 是对 Adam 优化器的一种改进，旨在解决 Adam 可能遇到的一些问题，特别是当 Adam 在某些情况下过度估计梯度平方的均值时可能导致的性能下降。\n5. 多GPU训练 5.1 并行化思路 （1）网络并行：将一个模型拆成多个部分，分别部署到不同的GPU中。 尤其适用于大模型的训练，单个GPU的显存无法存储批量大小为1的全部模型参数； 数据同步与传输有较大难度，不做推荐 （2）按层并行：将每一层的计算分给多个GPU 同样需要大量的同步操作，不推荐 （3）数据并行：模型相同，训练样本不同。 只要GPU的内存足够大，这种并行方式最方便。 对于具有两个GPU的数据并行训练过程为： 在任何一次训练迭代中，给定的随机的小批量样本都将被分成2个部分，并均匀地分配到GPU上； 每个GPU根据分配给它的小批量子集，计算模型参数的损失和梯度； 将2个GPU中的局部梯度聚合，以获得当前全部小批量的梯度； 聚合梯度被重新分发到每个GPU中； 每个GPU使用这个小批量随机梯度，来更新它所维护的完整的模型参数集 TIP：当原本小批量为b的单GPU训练，增加到k个GPU时，此时总的小批量需要扩展到k×b，从而确保每个GPU训练的小批量还是b。\n1 2 3 4 5 %matplotlib inline import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l 5.2 从零实现 （1）示例模型：简化的LeNet模型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 初始化模型参数 scale = 0.01 W1 = torch.randn(size=(20, 1, 3, 3)) * scale b1 = torch.zeros(20) W2 = torch.randn(size=(50, 20, 5, 5)) * scale b2 = torch.zeros(50) W3 = torch.randn(size=(800, 128)) * scale b3 = torch.zeros(128) W4 = torch.randn(size=(128, 10)) * scale b4 = torch.zeros(10) params = [W1, b1, W2, b2, W3, b3, W4, b4] # 定义模型 def lenet(X, params): # 1个输入通道，20个输出通道 h1_conv = F.conv2d(input=X, weight=params[0], bias=params[1]) h1_activation = F.relu(h1_conv) # 激活层 h1 = F.avg_pool2d(input=h1_activation, kernel_size=(2, 2), stride=(2, 2)) # 平均汇聚层 # 20个输入通道，50个输出通道 h2_conv = F.conv2d(input=h1, weight=params[2], bias=params[3]) h2_activation = F.relu(h2_conv) # 激活层 h2 = F.avg_pool2d(input=h2_activation, kernel_size=(2, 2), stride=(2, 2)) # 平均汇聚层 h2 = h2.reshape(h2.shape[0], -1) h3_linear = torch.mm(h2, params[4]) + params[5] #全连接层 h3 = F.relu(h3_linear) y_hat = torch.mm(h3, params[6]) + params[7] return y_hat # 交叉熵损失函数 loss = nn.CrossEntropyLoss(reduction='none') （2）定义两个数据同步函数\n函数1：将模型参数复制到指定的GPU中 1 2 3 4 5 6 7 8 9 10 11 12 13 def get_params(params, device): new_params = [p.to(device) for p in params] for p in new_params: p.requires_grad_() return new_params # 示例 new_params = get_params(params, d2l.try_gpu(0)) print('b1 权重:', new_params[1]) # b1 权重: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # device='cuda:0', requires_grad=True) print('b1 梯度:', new_params[1].grad) #初始梯度为None # b1 梯度: None 函数2：将所有GPU计算的梯度结果汇总（cuda:0）后，再返回给每个GPU 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def allreduce(data): for i in range(1, len(data)): data[0][:] += data[i].to(data[0].device) for i in range(1, len(data)): data[i][:] = data[0].to(data[i].device) # 示例 data = [torch.ones((1, 2), device=d2l.try_gpu(i)) * (i + 1) for i in range(2)] print('allreduce之前：\\n', data[0], '\\n', data[1]) # allreduce之前： # tensor([[1., 1.]], device='cuda:0') # tensor([[2., 2.]], device='cuda:1') allreduce(data) print('allreduce之后：\\n', data[0], '\\n', data[1]) # allreduce之后： # tensor([[3., 3.]], device='cuda:0') # tensor([[3., 3.]], device='cuda:1') （3）将总的小批量数据分给各个GPU\n这里为了方便，利用了torch提供的nn.parallel.scatter() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 data = torch.arange(12).reshape(4, 3) devices = [torch.device('cuda:0'), torch.device('cuda:1')] print('input :', data) # input : tensor([[ 0, 1, 2], # [ 3, 4, 5], # [ 6, 7, 8], # [ 9, 10, 11]]) print('load into', devices) # load into [device(type='cuda', index=0), device(type='cuda', index=1)] split = nn.parallel.scatter(data, devices) #按行平均分给多个GPU print('output:', split) # output: (tensor([[0, 1, 2], # [3, 4, 5]], device='cuda:0'), # tensor([[ 6, 7, 8], # [ 9, 10, 11]], device='cuda:1')) #@save def split_batch(X, y, devices): \"\"\"将X和y拆分到多个设备上\"\"\" assert X.shape[0] == y.shape[0] return (nn.parallel.scatter(X, devices), nn.parallel.scatter(y, devices)) （4）小批量训练函数\n根据如下代码，多个GPU看上去好像是顺序执行的。 其实是因为计算图在小批量内的设备之间没有任何依赖关系，因此它是“自动地”并行执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def train_batch(X, y, device_params, devices, lr): X_shards, y_shards = split_batch(X, y, devices) # 在每个GPU上分别计算损失 ls = [loss(lenet(X_shard, device_W), y_shard).sum() for X_shard, y_shard, device_W in zip( X_shards, y_shards, device_params)] for l in ls: # 反向传播，计算每个GPU的当前梯度 l.backward() # 将每个GPU的所有梯度相加，并将其广播到所有GPU with torch.no_grad(): for i in range(len(device_params[0])): # device_params为list，为每个GPU的模型参数 allreduce( [device_params[c][i].grad for c in range(len(devices))]) # 在每个GPU上分别更新模型参数 for param in device_params: d2l.sgd(param, lr, X.shape[0]) # 在这里，我们使用全尺寸的小批量 （5）定义最终的训练函数\ntest精度计算只根据其中一个GPU的模型（所有GPU的模型参数都是同步的，所以影响不大） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def train(num_gpus, batch_size, lr): train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) devices = [d2l.try_gpu(i) for i in range(num_gpus)] # 将模型参数复制到num_gpus个GPU device_params = [get_params(params, d) for d in devices] num_epochs = 10 animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs]) timer = d2l.Timer() for epoch in range(num_epochs): timer.start() for X, y in train_iter: # 为单个小批量执行多GPU训练 train_batch(X, y, device_params, devices, lr) torch.cuda.synchronize() # 确保当前指定GPU已经训练完成 timer.stop() # 在GPU0上评估模型 animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu( lambda x: lenet(x, device_params[0]), test_iter, devices[0]),)) print(f'测试精度：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}秒/轮，' f'在{str(devices)}') （6）比较\n如下，我们发现使用1个GPU与2个GPU的训练时间并没有差别； 主要原因是由于模型太小了，并且数据集也很小。 1 2 3 4 5 train(num_gpus=1, batch_size=256, lr=0.2) # 测试精度：0.76，4.9秒/轮，在[device(type='cuda', index=0)] train(num_gpus=2, batch_size=256, lr=0.2) # 测试精度：0.83，5.0秒/轮，在[device(type='cuda', index=0), device(type='cuda', index=1)] 5.3 简洁实现 （1）示例模型：Resnet18\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #@save def resnet18(num_classes, in_channels=1): \"\"\"稍加修改的ResNet-18模型\"\"\" def resnet_block(in_channels, out_channels, num_residuals, first_block=False): blk = [] for i in range(num_residuals): if i == 0 and not first_block: blk.append(d2l.Residual(in_channels, out_channels, use_1x1conv=True, strides=2)) else: blk.append(d2l.Residual(out_channels, out_channels)) return nn.Sequential(*blk) # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层 net = nn.Sequential( nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU()) net.add_module(\"resnet_block1\", resnet_block( 64, 64, 2, first_block=True)) net.add_module(\"resnet_block2\", resnet_block(64, 128, 2)) net.add_module(\"resnet_block3\", resnet_block(128, 256, 2)) net.add_module(\"resnet_block4\", resnet_block(256, 512, 2)) net.add_module(\"resnet_block5\", resnet_block(512, 1024, 2)) net.add_module(\"resnet_block6\", resnet_block(1024, 1024, 2)) # net.add_module(\"resnet_block7\", resnet_block(1024, 1024, 2)) # net.add_module(\"resnet_block8\", resnet_block(1024, 1024, 2)) net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1))) net.add_module(\"fc\", nn.Sequential(nn.Flatten(), nn.Linear(1024, num_classes))) return net # 实例化模型 net = resnet18(10) # 获取所有的GPU列表 devices = d2l.try_all_gpus() devices # [device(type='cuda', index=0), # device(type='cuda', index=1), # device(type='cuda', index=2)] # 我们将在训练代码实现中初始化网络 （2）定义训练函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def train(net, num_gpus, batch_size, lr): train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 定义所使用的多个GPU devices = [d2l.try_gpu(i) for i in range(num_gpus)] def init_weights(m): if type(m) in [nn.Linear, nn.Conv2d]: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 在多个GPU上设置模型 net = nn.DataParallel(net, device_ids=devices) trainer = torch.optim.SGD(net.parameters(), lr) #优化器 loss = nn.CrossEntropyLoss() #损失函数 timer, num_epochs = d2l.Timer(), 10 animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs]) for epoch in range(num_epochs): net.train() timer.start() for X, y in train_iter: trainer.zero_grad() X, y = X.to(devices[0]), y.to(devices[0]) # 先把批量样本数据都暂时放到cuda:0中 l = loss(net(X), y) #模型会自动将样本分发给多个GPU l.backward() trainer.step() timer.stop() animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),)) print(f'测试精度：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}秒/轮，' f'在{str(devices)}') （3）比较\n发现在批量数较大时，才能发挥并行计算的优势 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ## Batch size = 256 train(net, num_gpus=1,batch_size=256,lr=0.1) # 测试精度：0.90，7.9秒/轮，在[device(type='cuda', index=0)] train(net, num_gpus=2,batch_size=512,lr=0.2) # 测试精度：0.75，13.8秒/轮，在[device(type='cuda', index=0), device(type='cuda', index=1)] ## Batch size = 512 train(net, num_gpus=1,batch_size=512,lr=0.1) # 测试精度：0.87，7.6秒/轮，在[device(type='cuda', index=0)] train(net, num_gpus=2,batch_size=1024,lr=0.2) # 测试精度：0.90，8.6秒/轮，在[device(type='cuda', index=0), device(type='cuda', index=1)] ## Batch size = 1024 train(net, num_gpus=1,batch_size=1024,lr=0.1) # 测试精度：0.69，7.7秒/轮，在[device(type='cuda', index=0)] train(net, num_gpus=2,batch_size=1024*2,lr=0.1*2) # 测试精度：0.79，6.4秒/轮，在[device(type='cuda', index=0), device(type='cuda', index=1)] train(net, num_gpus=3,batch_size=1024*3,lr=0.1*3) # 测试精度：0.79，5.4秒/轮，在[device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2)] TIP：当训练的批量大小增大时，学习率也要相应的增加。\n",
  "wordCount" : "4818",
  "inLanguage": "en",
  "datePublished": "2024-08-24T00:00:00Z",
  "dateModified": "2024-08-24T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lishensuo"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lishensuo.github.io/en/posts/bioinfo/715d2l-%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8F%8A%E5%8D%81%E4%BA%8C%E7%AB%A0%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%A4%9Agpu%E5%B9%B6%E8%A1%8C/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Li's Bioinfo-Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lishensuo.github.io/img/Q.gif"
    }
  }
}
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lishensuo.github.io/en/" accesskey="h" title="Li&#39;s Bioinfo-Blog (Alt + H)">Li&#39;s Bioinfo-Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lishensuo.github.io/en/" title="主页">
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/posts" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/about" title="关于">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/search" title="搜索 (Alt &#43; /)" accesskey=/>
                    <span>搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lishensuo.github.io/en/">Home</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/">分类</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/bioinfo/">📖 生信数据分析--分析流程，工具包等</a></div>
    <h1 class="post-title">
      D2L--第十一及十二章优化算法&amp;多GPU并行
    </h1>
    <div class="post-meta">













Create:&amp;nbsp;&lt;span title=&#39;2024-08-24 00:00:00 &#43;0000 UTC&#39;&gt;2024-08-24&lt;/span&gt;&amp;nbsp;|&amp;nbsp;Update:&amp;nbsp;2024-08-24&amp;nbsp;|&amp;nbsp;Words:&amp;nbsp;4818&amp;nbsp;|&amp;nbsp;10 min&amp;nbsp;|&amp;nbsp;Lishensuo

|  Viewers: <span id="busuanzi_value_page_pv"></span> 
	  
    </div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#1-%e7%a4%ba%e4%be%8b%e4%bb%bb%e5%8a%a1" aria-label="1. 示例任务">1. 示例任务</a></li>
                    <li>
                        <a href="#2-sgd" aria-label="2. SGD">2. SGD</a></li>
                    <li>
                        <a href="#3-%e5%8a%a8%e9%87%8f%e6%b3%95" aria-label="3. 动量法">3. 动量法</a></li>
                    <li>
                        <a href="#4-%e8%87%aa%e9%80%82%e5%ba%94%e5%ad%a6%e4%b9%a0%e7%8e%87" aria-label="4. 自适应学习率">4. 自适应学习率</a><ul>
                            
                    <li>
                        <a href="#41-adagrad" aria-label="4.1 AdaGrad">4.1 AdaGrad</a></li>
                    <li>
                        <a href="#42-rmsprop" aria-label="4.2 RMSprop">4.2 RMSprop</a></li>
                    <li>
                        <a href="#43-adam" aria-label="4.3 Adam">4.3 Adam</a></li></ul>
                    </li>
                    <li>
                        <a href="#5-%e5%a4%9agpu%e8%ae%ad%e7%bb%83" aria-label="5. 多GPU训练">5. 多GPU训练</a><ul>
                            
                    <li>
                        <a href="#51-%e5%b9%b6%e8%a1%8c%e5%8c%96%e6%80%9d%e8%b7%af" aria-label="5.1 并行化思路">5.1 并行化思路</a></li>
                    <li>
                        <a href="#52-%e4%bb%8e%e9%9b%b6%e5%ae%9e%e7%8e%b0" aria-label="5.2 从零实现">5.2 从零实现</a></li>
                    <li>
                        <a href="#53-%e7%ae%80%e6%b4%81%e5%ae%9e%e7%8e%b0" aria-label="5.3 简洁实现">5.3 简洁实现</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>


  <div class="post-content"><ul>
<li>在深度学习中，优化算法是训练模型的关键部分，它们用于更新网络的参数以<strong>最小化损失函数</strong>。
<ul>
<li>由于优化算法的目标函数通常是基于训练数据集的损失函数，因此优化的目标是减少<strong>训练误差</strong>。</li>
</ul>
</li>
</ul>
<blockquote>
<p>NOTE: 深度学习的最终目标是减小泛化误差，所以在关注优化算法的同时，也要注意过拟合。</p></blockquote>
<ul>
<li>深度学习问题绝大部分都是<strong>非凸</strong>函数，使得优化算法可能陷入这些局部最小值而不是找到全局最小值。
<ul>
<li>不过在实践中，对于很多深度学习任务，即使找到的是局部最小值，模型的表现也可以是非常好的。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://zh-v2.d2l.ai/_images/output_optimization-intro_70d214_51_0.svg" alt="../_images/output_optimization-intro_70d214_51_0.svg"  />
</p>
<ul>
<li>本章节将简单学习目前深度学习领域比较常用的几种优化算法</li>
</ul>
<h1 id="1-示例任务">1. 示例任务<a hidden class="anchor" aria-hidden="true" href="#1-示例任务">#</a></h1>
<ul>
<li>NASA开发的测试机翼的数据集不同飞行器产生的噪声
<ul>
<li>使用前1500样本，并将数据进行归一化处理</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> numpy <span style="color:#fff;font-weight:bold">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>d2l.DATA_HUB[<span style="color:#0ff;font-weight:bold">&#39;airfoil&#39;</span>] = (d2l.DATA_URL + <span style="color:#0ff;font-weight:bold">&#39;airfoil_self_noise.dat&#39;</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#0ff;font-weight:bold">&#39;76e5be1548fd8222e5074cf0faae75edff8cf93f&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_data_ch11(batch_size=<span style="color:#ff0;font-weight:bold">10</span>, n=<span style="color:#ff0;font-weight:bold">1500</span>):
</span></span><span style="display:flex;"><span>    data = np.genfromtxt(d2l.download(<span style="color:#0ff;font-weight:bold">&#39;airfoil&#39;</span>),
</span></span><span style="display:flex;"><span>                         dtype=np.float32, delimiter=<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\t</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>    data = torch.from_numpy((data - data.mean(axis=<span style="color:#ff0;font-weight:bold">0</span>)) / data.std(axis=<span style="color:#ff0;font-weight:bold">0</span>))
</span></span><span style="display:flex;"><span>    data_iter = d2l.load_array((data[:n, :-<span style="color:#ff0;font-weight:bold">1</span>], data[:n, -<span style="color:#ff0;font-weight:bold">1</span>]), <span style="color:#007f7f">#最后一列作为标签</span>
</span></span><span style="display:flex;"><span>                               batch_size, is_train=<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> data_iter, data.shape[<span style="color:#ff0;font-weight:bold">1</span>]-<span style="color:#ff0;font-weight:bold">1</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义一个通用的训练函数</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=<span style="color:#ff0;font-weight:bold">4</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 初始化模型：只有一个隐藏层的MLP</span>
</span></span><span style="display:flex;"><span>    net = nn.Sequential(nn.Linear(<span style="color:#ff0;font-weight:bold">5</span>, <span style="color:#ff0;font-weight:bold">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> init_weights(m):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) == nn.Linear:
</span></span><span style="display:flex;"><span>            torch.nn.init.normal_(m.weight, std=<span style="color:#ff0;font-weight:bold">0.01</span>)
</span></span><span style="display:flex;"><span>    net.apply(init_weights)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#优化器</span>
</span></span><span style="display:flex;"><span>    optimizer = trainer_fn(net.parameters(), **hyperparams)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#损失函数</span>
</span></span><span style="display:flex;"><span>    loss = nn.MSELoss(reduction=<span style="color:#0ff;font-weight:bold">&#39;none&#39;</span>)
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(xlabel=<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, ylabel=<span style="color:#0ff;font-weight:bold">&#39;loss&#39;</span>,
</span></span><span style="display:flex;"><span>                            xlim=[<span style="color:#ff0;font-weight:bold">0</span>, num_epochs], ylim=[<span style="color:#ff0;font-weight:bold">0.22</span>, <span style="color:#ff0;font-weight:bold">0.35</span>])
</span></span><span style="display:flex;"><span>    n, timer = <span style="color:#ff0;font-weight:bold">0</span>, d2l.Timer()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> _ in <span style="color:#fff;font-weight:bold">range</span>(num_epochs): <span style="color:#007f7f">#每个epoch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> X, y in data_iter:  <span style="color:#007f7f">#每个batch</span>
</span></span><span style="display:flex;"><span>            optimizer.zero_grad()
</span></span><span style="display:flex;"><span>            out = net(X)
</span></span><span style="display:flex;"><span>            y = y.reshape(out.shape)
</span></span><span style="display:flex;"><span>            l = loss(out, y)
</span></span><span style="display:flex;"><span>            l.mean().backward()
</span></span><span style="display:flex;"><span>            optimizer.step()
</span></span><span style="display:flex;"><span>            n += X.shape[<span style="color:#ff0;font-weight:bold">0</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> n % <span style="color:#ff0;font-weight:bold">200</span> == <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>                timer.stop()
</span></span><span style="display:flex;"><span>                <span style="color:#007f7f"># MSELoss计算平方误差时不带系数1/2</span>
</span></span><span style="display:flex;"><span>                animator.add(n/X.shape[<span style="color:#ff0;font-weight:bold">0</span>]/<span style="color:#fff;font-weight:bold">len</span>(data_iter),
</span></span><span style="display:flex;"><span>                             (d2l.evaluate_loss(net, data_iter, loss) / <span style="color:#ff0;font-weight:bold">2</span>,))
</span></span><span style="display:flex;"><span>                timer.start()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;loss: </span><span style="color:#0ff;font-weight:bold">{</span>animator.Y[<span style="color:#ff0;font-weight:bold">0</span>][-<span style="color:#ff0;font-weight:bold">1</span>]<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, </span><span style="color:#0ff;font-weight:bold">{</span>timer.avg()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold"> sec/epoch&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="2-sgd">2. SGD<a hidden class="anchor" aria-hidden="true" href="#2-sgd">#</a></h1>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240820203200138.png" alt="image-20240820203200138"  />
</p>
<ul>
<li><strong>梯度下降(Gradient Descent)</strong>: 在每次迭代中，批量梯度下降会使用所有训练样本计算损失函数的梯度，然后根据这个梯度更新模型参数。
<ul>
<li>计算代价高，因为每次迭代都需要遍历整个训练集。</li>
</ul>
</li>
<li><strong>随机梯度下降(Stochastic Gradient Descent, SGD)</strong>: 在每次迭代中，随机梯度下降只选取一个训练样本（或者随机选择一个样本）来计算损失函数的梯度，然后根据这个梯度更新模型参数。
<ul>
<li>收敛过程可能会比较震荡，并且无法完全利用CPU/GPU硬件资源。</li>
</ul>
</li>
<li><strong>小批量随机梯度下降(Mini-batch SGD)</strong>: 在每次迭代中，小批量随机梯度下降从训练集中随机抽取一个小批量（batch）的样本集合来计算损失函数的梯度，然后根据这个梯度更新模型参数。
<ul>
<li>为上述两种优化方式的折中方案，比批量梯度下降快，比随机梯度下降更稳定。</li>
<li>可通过torch的<code>torch.optim.SGD</code>快速实现</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data_iter, _ = get_data_ch11(<span style="color:#ff0;font-weight:bold">10</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 定义优化器</span>
</span></span><span style="display:flex;"><span>trainer = torch.optim.SGD
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>train_concise_ch11(trainer, {<span style="color:#0ff;font-weight:bold">&#39;lr&#39;</span>: <span style="color:#ff0;font-weight:bold">0.01</span>}, data_iter)
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="3-动量法">3. 动量法<a hidden class="anchor" aria-hidden="true" href="#3-动量法">#</a></h1>
<ul>
<li>如下公式，<strong>g</strong>t表示在t时刻计算的损失函数梯度；<strong>v</strong>t则考虑了过去梯度的累加，称为动量(momentum)。
<ul>
<li>β值越大，则考虑了过去时刻的梯度越多</li>
<li>常见的β取值包括0.5, 0.9, 0.95, 0.99</li>
</ul>
</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240820204917387.png" alt="image-20240820204917387" style="zoom:67%;" />
<ul>
<li>通常来说，动量法通过在参数更新时引入“动量”，使得梯度下降更稳定和快速。</li>
<li>可以直接在<code>torch.optim.SGD</code>中添加momentum参数，设置动量法</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 定义优化器</span>
</span></span><span style="display:flex;"><span>trainer = torch.optim.SGD
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>d2l.train_concise_ch11(trainer, {<span style="color:#0ff;font-weight:bold">&#39;lr&#39;</span>: <span style="color:#ff0;font-weight:bold">0.005</span>, <span style="color:#0ff;font-weight:bold">&#39;momentum&#39;</span>: <span style="color:#ff0;font-weight:bold">0.9</span>}, data_iter)
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>SGD+动量法的优化效果对于某些任务不必Adam差。</p></blockquote>
<h1 id="4-自适应学习率">4. 自适应学习率<a hidden class="anchor" aria-hidden="true" href="#4-自适应学习率">#</a></h1>
<h2 id="41-adagrad">4.1 AdaGrad<a hidden class="anchor" aria-hidden="true" href="#41-adagrad">#</a></h2>
<blockquote>
<p>梯度下降方法使用固定的学习率，这意味着所有参数以相同的速度更新。<strong>自适应学习率</strong>方法为每个参数提供一个动态调整的学习率，这允许算法更加灵活地适应不同的参数需求。</p></blockquote>
<ul>
<li>**AdaGrad (Adaptive Gradient)**使用每个参数的历史梯度平方的累积和来调整学习率。
<ul>
<li>在梯度较大的参数上采用较小的学习率，而在梯度较小的参数上采用较大的学习率。</li>
</ul>
</li>
<li>缺点在于，学习率随着训练时间的增加会变得非常小，导致训练提前停止。</li>
<li>可通过torch的<code>torch.optim.Adagrad</code>快速实现。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 定义优化器</span>
</span></span><span style="display:flex;"><span>trainer = torch.optim.Adagrad
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>d2l.train_concise_ch11(trainer, {<span style="color:#0ff;font-weight:bold">&#39;lr&#39;</span>: <span style="color:#ff0;font-weight:bold">0.1</span>}, data_iter) <span style="color:#007f7f">#初始学习率</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="42-rmsprop">4.2 RMSprop<a hidden class="anchor" aria-hidden="true" href="#42-rmsprop">#</a></h2>
<ul>
<li>**RMSprop (Root Mean Square Propagation)**是 AdaGrad 的一个改进版本</li>
<li>它通过使用指数加权平均数来平滑历史梯度的平方，解决了 AdaGrad 中学习率过早衰减的问题。</li>
<li>alpha参数用于设置平滑方式：
<ul>
<li>当 <code>alpha</code> 接近 1 时，算法更加重视过去的历史梯度信息；</li>
<li>当 <code>alpha</code> 接近 0 时，则更多地依赖于最近的梯度信息。</li>
</ul>
</li>
<li>可通过torch的<code>torch.optim.RMSprop</code>快速实现。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 定义优化器</span>
</span></span><span style="display:flex;"><span>trainer = torch.optim.RMSprop
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>d2l.train_concise_ch11(trainer, {<span style="color:#0ff;font-weight:bold">&#39;lr&#39;</span>: <span style="color:#ff0;font-weight:bold">0.01</span>, <span style="color:#0ff;font-weight:bold">&#39;alpha&#39;</span>: <span style="color:#ff0;font-weight:bold">0.9</span>}, data_iter)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="43-adam">4.3 Adam<a hidden class="anchor" aria-hidden="true" href="#43-adam">#</a></h2>
<ul>
<li>**Adam (Adaptive Moment Estimation)**是一种结合了动量法和 RMSprop 的优点的自适应学习率优化算法，是目前最常用的优化算法之一。</li>
<li>它同时使用了一阶矩（动量）和二阶矩（梯度平方的指数加权平均）来更新参数。</li>
<li>一阶矩用来平滑梯度（β1,通常取0.9）；</li>
<li>二阶矩（β2）用来平滑梯度的平方（β2,通常取0.999）。</li>
<li>可通过torch的<code>torch.optim.Adam</code>快速实现。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 定义优化器</span>
</span></span><span style="display:flex;"><span>trainer = torch.optim.Adam
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>d2l.train_concise_ch11(trainer, {<span style="color:#0ff;font-weight:bold">&#39;lr&#39;</span>: <span style="color:#ff0;font-weight:bold">0.01</span>}, data_iter)
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Yogi 是对 Adam 优化器的一种改进，旨在解决 Adam 可能遇到的一些问题，特别是当 Adam 在某些情况下过度估计梯度平方的均值时可能导致的性能下降。</p></blockquote>
<hr>
<h1 id="5-多gpu训练">5. 多GPU训练<a hidden class="anchor" aria-hidden="true" href="#5-多gpu训练">#</a></h1>
<h2 id="51-并行化思路">5.1 并行化思路<a hidden class="anchor" aria-hidden="true" href="#51-并行化思路">#</a></h2>
<ul>
<li><strong>（1）网络并行</strong>：将一个模型拆成多个部分，分别部署到不同的GPU中。
<ul>
<li>尤其适用于大模型的训练，单个GPU的显存无法存储批量大小为1的全部模型参数；</li>
<li>数据同步与传输有较大难度，不做推荐</li>
</ul>
</li>
<li><strong>（2）按层并行</strong>：将每一层的计算分给多个GPU
<ul>
<li>同样需要大量的同步操作，不推荐</li>
</ul>
</li>
<li><strong>（3）数据并行</strong>：模型相同，训练样本不同。
<ul>
<li>只要GPU的内存足够大，这种并行方式最方便。</li>
</ul>
</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20241108121359188.png" alt="image-20240823205742276" style="zoom:67%;" />
<ul>
<li>对于具有两个GPU的数据并行训练过程为：
<ol>
<li>在任何一次训练迭代中，给定的随机的小批量样本都将被分成2个部分，并均匀地分配到GPU上；</li>
<li>每个GPU根据分配给它的小批量子集，计算模型参数的损失和梯度；</li>
<li>将2个GPU中的局部梯度聚合，以获得当前全部小批量的梯度；</li>
<li>聚合梯度被重新分发到每个GPU中；</li>
<li>每个GPU使用这个小批量随机梯度，来更新它所维护的完整的模型参数集</li>
</ol>
</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240823232521945.png" alt="image-20240823232521945"  />
<blockquote>
<p>TIP：当原本小批量为b的单GPU训练，增加到k个GPU时，此时总的小批量需要扩展到k×b，从而确保每个GPU训练的小批量还是b。</p></blockquote>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>%matplotlib inline
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> functional <span style="color:#fff;font-weight:bold">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="52-从零实现">5.2 从零实现<a hidden class="anchor" aria-hidden="true" href="#52-从零实现">#</a></h2>
<p><strong>（1）示例模型：简化的LeNet模型</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 初始化模型参数</span>
</span></span><span style="display:flex;"><span>scale = <span style="color:#ff0;font-weight:bold">0.01</span>
</span></span><span style="display:flex;"><span>W1 = torch.randn(size=(<span style="color:#ff0;font-weight:bold">20</span>, <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">3</span>, <span style="color:#ff0;font-weight:bold">3</span>)) * scale
</span></span><span style="display:flex;"><span>b1 = torch.zeros(<span style="color:#ff0;font-weight:bold">20</span>)
</span></span><span style="display:flex;"><span>W2 = torch.randn(size=(<span style="color:#ff0;font-weight:bold">50</span>, <span style="color:#ff0;font-weight:bold">20</span>, <span style="color:#ff0;font-weight:bold">5</span>, <span style="color:#ff0;font-weight:bold">5</span>)) * scale
</span></span><span style="display:flex;"><span>b2 = torch.zeros(<span style="color:#ff0;font-weight:bold">50</span>)
</span></span><span style="display:flex;"><span>W3 = torch.randn(size=(<span style="color:#ff0;font-weight:bold">800</span>, <span style="color:#ff0;font-weight:bold">128</span>)) * scale
</span></span><span style="display:flex;"><span>b3 = torch.zeros(<span style="color:#ff0;font-weight:bold">128</span>)
</span></span><span style="display:flex;"><span>W4 = torch.randn(size=(<span style="color:#ff0;font-weight:bold">128</span>, <span style="color:#ff0;font-weight:bold">10</span>)) * scale
</span></span><span style="display:flex;"><span>b4 = torch.zeros(<span style="color:#ff0;font-weight:bold">10</span>)
</span></span><span style="display:flex;"><span>params = [W1, b1, W2, b2, W3, b3, W4, b4]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 定义模型</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> lenet(X, params):
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 1个输入通道，20个输出通道</span>
</span></span><span style="display:flex;"><span>    h1_conv = F.conv2d(<span style="color:#fff;font-weight:bold">input</span>=X, weight=params[<span style="color:#ff0;font-weight:bold">0</span>], bias=params[<span style="color:#ff0;font-weight:bold">1</span>])
</span></span><span style="display:flex;"><span>    h1_activation = F.relu(h1_conv) <span style="color:#007f7f"># 激活层</span>
</span></span><span style="display:flex;"><span>    h1 = F.avg_pool2d(<span style="color:#fff;font-weight:bold">input</span>=h1_activation, kernel_size=(<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>), stride=(<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>)) <span style="color:#007f7f"># 平均汇聚层</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 20个输入通道，50个输出通道</span>
</span></span><span style="display:flex;"><span>    h2_conv = F.conv2d(<span style="color:#fff;font-weight:bold">input</span>=h1, weight=params[<span style="color:#ff0;font-weight:bold">2</span>], bias=params[<span style="color:#ff0;font-weight:bold">3</span>])
</span></span><span style="display:flex;"><span>    h2_activation = F.relu(h2_conv) <span style="color:#007f7f"># 激活层</span>
</span></span><span style="display:flex;"><span>    h2 = F.avg_pool2d(<span style="color:#fff;font-weight:bold">input</span>=h2_activation, kernel_size=(<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>), stride=(<span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">2</span>)) <span style="color:#007f7f"># 平均汇聚层</span>
</span></span><span style="display:flex;"><span>    h2 = h2.reshape(h2.shape[<span style="color:#ff0;font-weight:bold">0</span>], -<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>    h3_linear = torch.mm(h2, params[<span style="color:#ff0;font-weight:bold">4</span>]) + params[<span style="color:#ff0;font-weight:bold">5</span>] <span style="color:#007f7f">#全连接层</span>
</span></span><span style="display:flex;"><span>    h3 = F.relu(h3_linear)
</span></span><span style="display:flex;"><span>    y_hat = torch.mm(h3, params[<span style="color:#ff0;font-weight:bold">6</span>]) + params[<span style="color:#ff0;font-weight:bold">7</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> y_hat
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 交叉熵损失函数</span>
</span></span><span style="display:flex;"><span>loss = nn.CrossEntropyLoss(reduction=<span style="color:#0ff;font-weight:bold">&#39;none&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（2）定义两个数据同步函数</strong></p>
<ul>
<li>函数1：将模型参数复制到指定的GPU中</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_params(params, device):
</span></span><span style="display:flex;"><span>    new_params = [p.to(device) <span style="color:#fff;font-weight:bold">for</span> p in params]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> p in new_params:
</span></span><span style="display:flex;"><span>        p.requires_grad_()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> new_params
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 示例</span>
</span></span><span style="display:flex;"><span>new_params = get_params(params, d2l.try_gpu(<span style="color:#ff0;font-weight:bold">0</span>))
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;b1 权重:&#39;</span>, new_params[<span style="color:#ff0;font-weight:bold">1</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># b1 权重: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#        		  device=&#39;cuda:0&#39;, requires_grad=True)</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;b1 梯度:&#39;</span>, new_params[<span style="color:#ff0;font-weight:bold">1</span>].grad) <span style="color:#007f7f">#初始梯度为None</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># b1 梯度: None</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>函数2：将所有GPU计算的梯度结果汇总（cuda:0）后，再返回给每个GPU</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> allreduce(data):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#fff;font-weight:bold">len</span>(data)):
</span></span><span style="display:flex;"><span>        data[<span style="color:#ff0;font-weight:bold">0</span>][:] += data[i].to(data[<span style="color:#ff0;font-weight:bold">0</span>].device)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#fff;font-weight:bold">len</span>(data)):
</span></span><span style="display:flex;"><span>        data[i][:] = data[<span style="color:#ff0;font-weight:bold">0</span>].to(data[i].device)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 示例</span>
</span></span><span style="display:flex;"><span>data = [torch.ones((<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">2</span>), device=d2l.try_gpu(i)) * (i + <span style="color:#ff0;font-weight:bold">1</span>) <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">2</span>)]
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;allreduce之前：</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>, data[<span style="color:#ff0;font-weight:bold">0</span>], <span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>, data[<span style="color:#ff0;font-weight:bold">1</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># allreduce之前：</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[1., 1.]], device=&#39;cuda:0&#39;) </span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[2., 2.]], device=&#39;cuda:1&#39;)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>allreduce(data)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;allreduce之后：</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>, data[<span style="color:#ff0;font-weight:bold">0</span>], <span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>, data[<span style="color:#ff0;font-weight:bold">1</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># allreduce之后：</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[3., 3.]], device=&#39;cuda:0&#39;) </span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([[3., 3.]], device=&#39;cuda:1&#39;)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（3）将总的小批量数据分给各个GPU</strong></p>
<ul>
<li>这里为了方便，利用了torch提供的<code>nn.parallel.scatter()</code></li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data = torch.arange(<span style="color:#ff0;font-weight:bold">12</span>).reshape(<span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>devices = [torch.device(<span style="color:#0ff;font-weight:bold">&#39;cuda:0&#39;</span>), torch.device(<span style="color:#0ff;font-weight:bold">&#39;cuda:1&#39;</span>)]
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;input :&#39;</span>, data)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># input : tensor([[ 0,  1,  2],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#                 [ 3,  4,  5],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#                 [ 6,  7,  8],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#                 [ 9, 10, 11]])</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;load into&#39;</span>, devices)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># load into [device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>split = nn.parallel.scatter(data, devices) <span style="color:#007f7f">#按行平均分给多个GPU</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;output:&#39;</span>, split)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># output: (tensor([[0, 1, 2],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#                  [3, 4, 5]], device=&#39;cuda:0&#39;), </span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#         tensor([[ 6,  7,  8],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#                 [ 9, 10, 11]], device=&#39;cuda:1&#39;))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> split_batch(X, y, devices):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;将X和y拆分到多个设备上&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">assert</span> X.shape[<span style="color:#ff0;font-weight:bold">0</span>] == y.shape[<span style="color:#ff0;font-weight:bold">0</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> (nn.parallel.scatter(X, devices),
</span></span><span style="display:flex;"><span>            nn.parallel.scatter(y, devices))
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（4）小批量训练函数</strong></p>
<ul>
<li>根据如下代码，多个GPU看上去好像是顺序执行的。</li>
<li>其实是因为计算图在小批量内的设备之间没有任何依赖关系，因此它是“自动地”并行执行</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_batch(X, y, device_params, devices, lr):
</span></span><span style="display:flex;"><span>    X_shards, y_shards = split_batch(X, y, devices)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 在每个GPU上分别计算损失</span>
</span></span><span style="display:flex;"><span>    ls = [loss(lenet(X_shard, device_W), y_shard).sum()
</span></span><span style="display:flex;"><span>          <span style="color:#fff;font-weight:bold">for</span> X_shard, y_shard, device_W in <span style="color:#fff;font-weight:bold">zip</span>(
</span></span><span style="display:flex;"><span>              X_shards, y_shards, device_params)]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> l in ls:  <span style="color:#007f7f"># 反向传播，计算每个GPU的当前梯度</span>
</span></span><span style="display:flex;"><span>        l.backward()
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 将每个GPU的所有梯度相加，并将其广播到所有GPU</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">with</span> torch.no_grad():
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#fff;font-weight:bold">len</span>(device_params[<span style="color:#ff0;font-weight:bold">0</span>])): <span style="color:#007f7f"># device_params为list，为每个GPU的模型参数</span>
</span></span><span style="display:flex;"><span>            allreduce(
</span></span><span style="display:flex;"><span>                [device_params[c][i].grad <span style="color:#fff;font-weight:bold">for</span> c in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#fff;font-weight:bold">len</span>(devices))])
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 在每个GPU上分别更新模型参数</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> param in device_params:
</span></span><span style="display:flex;"><span>        d2l.sgd(param, lr, X.shape[<span style="color:#ff0;font-weight:bold">0</span>]) <span style="color:#007f7f"># 在这里，我们使用全尺寸的小批量</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（5）定义最终的训练函数</strong></p>
<ul>
<li>test精度计算只根据其中一个GPU的模型（所有GPU的模型参数都是同步的，所以影响不大）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train(num_gpus, batch_size, lr):
</span></span><span style="display:flex;"><span>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
</span></span><span style="display:flex;"><span>    devices = [d2l.try_gpu(i) <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(num_gpus)]
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 将模型参数复制到num_gpus个GPU</span>
</span></span><span style="display:flex;"><span>    device_params = [get_params(params, d) <span style="color:#fff;font-weight:bold">for</span> d in devices]
</span></span><span style="display:flex;"><span>    num_epochs = <span style="color:#ff0;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;test acc&#39;</span>, xlim=[<span style="color:#ff0;font-weight:bold">1</span>, num_epochs])
</span></span><span style="display:flex;"><span>    timer = d2l.Timer()
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        timer.start()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> X, y in train_iter:
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># 为单个小批量执行多GPU训练</span>
</span></span><span style="display:flex;"><span>            train_batch(X, y, device_params, devices, lr)
</span></span><span style="display:flex;"><span>            torch.cuda.synchronize() <span style="color:#007f7f"># 确保当前指定GPU已经训练完成</span>
</span></span><span style="display:flex;"><span>        timer.stop()
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 在GPU0上评估模型</span>
</span></span><span style="display:flex;"><span>        animator.add(epoch + <span style="color:#ff0;font-weight:bold">1</span>, (d2l.evaluate_accuracy_gpu(
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">lambda</span> x: lenet(x, device_params[<span style="color:#ff0;font-weight:bold">0</span>]), test_iter, devices[<span style="color:#ff0;font-weight:bold">0</span>]),))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;测试精度：</span><span style="color:#0ff;font-weight:bold">{</span>animator.Y[<span style="color:#ff0;font-weight:bold">0</span>][-<span style="color:#ff0;font-weight:bold">1</span>]<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.2f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">，</span><span style="color:#0ff;font-weight:bold">{</span>timer.avg()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">秒/轮，&#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;在</span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">str</span>(devices)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（6）比较</strong></p>
<ul>
<li>如下，我们发现使用1个GPU与2个GPU的训练时间并没有差别；</li>
<li>主要原因是由于模型太小了，并且数据集也很小。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train(num_gpus=<span style="color:#ff0;font-weight:bold">1</span>, batch_size=<span style="color:#ff0;font-weight:bold">256</span>, lr=<span style="color:#ff0;font-weight:bold">0.2</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.76，4.9秒/轮，在[device(type=&#39;cuda&#39;, index=0)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train(num_gpus=<span style="color:#ff0;font-weight:bold">2</span>, batch_size=<span style="color:#ff0;font-weight:bold">256</span>, lr=<span style="color:#ff0;font-weight:bold">0.2</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.83，5.0秒/轮，在[device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="53-简洁实现">5.3 简洁实现<a hidden class="anchor" aria-hidden="true" href="#53-简洁实现">#</a></h2>
<p><strong>（1）示例模型：Resnet18</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">45
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> resnet18(num_classes, in_channels=<span style="color:#ff0;font-weight:bold">1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;稍加修改的ResNet-18模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> resnet_block(in_channels, out_channels, num_residuals,
</span></span><span style="display:flex;"><span>                     first_block=<span style="color:#fff;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>        blk = []
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(num_residuals):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> i == <span style="color:#ff0;font-weight:bold">0</span> and not first_block:
</span></span><span style="display:flex;"><span>                blk.append(d2l.Residual(in_channels, out_channels,
</span></span><span style="display:flex;"><span>                                        use_1x1conv=<span style="color:#fff;font-weight:bold">True</span>, strides=<span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>                blk.append(d2l.Residual(out_channels, out_channels))
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> nn.Sequential(*blk)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层</span>
</span></span><span style="display:flex;"><span>    net = nn.Sequential(
</span></span><span style="display:flex;"><span>        nn.Conv2d(in_channels, <span style="color:#ff0;font-weight:bold">64</span>, kernel_size=<span style="color:#ff0;font-weight:bold">3</span>, stride=<span style="color:#ff0;font-weight:bold">1</span>, padding=<span style="color:#ff0;font-weight:bold">1</span>),
</span></span><span style="display:flex;"><span>        nn.BatchNorm2d(<span style="color:#ff0;font-weight:bold">64</span>),
</span></span><span style="display:flex;"><span>        nn.ReLU())
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block1&#34;</span>, resnet_block(
</span></span><span style="display:flex;"><span>        <span style="color:#ff0;font-weight:bold">64</span>, <span style="color:#ff0;font-weight:bold">64</span>, <span style="color:#ff0;font-weight:bold">2</span>, first_block=<span style="color:#fff;font-weight:bold">True</span>))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block2&#34;</span>, resnet_block(<span style="color:#ff0;font-weight:bold">64</span>, <span style="color:#ff0;font-weight:bold">128</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block3&#34;</span>, resnet_block(<span style="color:#ff0;font-weight:bold">128</span>, <span style="color:#ff0;font-weight:bold">256</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block4&#34;</span>, resnet_block(<span style="color:#ff0;font-weight:bold">256</span>, <span style="color:#ff0;font-weight:bold">512</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block5&#34;</span>, resnet_block(<span style="color:#ff0;font-weight:bold">512</span>, <span style="color:#ff0;font-weight:bold">1024</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;resnet_block6&#34;</span>, resnet_block(<span style="color:#ff0;font-weight:bold">1024</span>, <span style="color:#ff0;font-weight:bold">1024</span>, <span style="color:#ff0;font-weight:bold">2</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># net.add_module(&#34;resnet_block7&#34;, resnet_block(1024, 1024, 2))</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># net.add_module(&#34;resnet_block8&#34;, resnet_block(1024, 1024, 2))</span>
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;global_avg_pool&#34;</span>, nn.AdaptiveAvgPool2d((<span style="color:#ff0;font-weight:bold">1</span>,<span style="color:#ff0;font-weight:bold">1</span>)))
</span></span><span style="display:flex;"><span>    net.add_module(<span style="color:#0ff;font-weight:bold">&#34;fc&#34;</span>, nn.Sequential(nn.Flatten(),
</span></span><span style="display:flex;"><span>                                       nn.Linear(<span style="color:#ff0;font-weight:bold">1024</span>, num_classes)))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> net
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 实例化模型</span>
</span></span><span style="display:flex;"><span>net = resnet18(<span style="color:#ff0;font-weight:bold">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 获取所有的GPU列表</span>
</span></span><span style="display:flex;"><span>devices = d2l.try_all_gpus()
</span></span><span style="display:flex;"><span>devices
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [device(type=&#39;cuda&#39;, index=0),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  device(type=&#39;cuda&#39;, index=1),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  device(type=&#39;cuda&#39;, index=2)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 我们将在训练代码实现中初始化网络</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（2）定义训练函数</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train(net, num_gpus, batch_size, lr):
</span></span><span style="display:flex;"><span>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 定义所使用的多个GPU</span>
</span></span><span style="display:flex;"><span>    devices = [d2l.try_gpu(i) <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(num_gpus)]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> init_weights(m):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) in [nn.Linear, nn.Conv2d]:
</span></span><span style="display:flex;"><span>            nn.init.normal_(m.weight, std=<span style="color:#ff0;font-weight:bold">0.01</span>)
</span></span><span style="display:flex;"><span>    net.apply(init_weights)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 在多个GPU上设置模型</span>
</span></span><span style="display:flex;"><span>    net = nn.DataParallel(net, device_ids=devices)
</span></span><span style="display:flex;"><span>    trainer = torch.optim.SGD(net.parameters(), lr) <span style="color:#007f7f">#优化器</span>
</span></span><span style="display:flex;"><span>    loss = nn.CrossEntropyLoss() <span style="color:#007f7f">#损失函数</span>
</span></span><span style="display:flex;"><span>    timer, num_epochs = d2l.Timer(), <span style="color:#ff0;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;test acc&#39;</span>, xlim=[<span style="color:#ff0;font-weight:bold">1</span>, num_epochs])
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        net.train()
</span></span><span style="display:flex;"><span>        timer.start()
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> X, y in train_iter:
</span></span><span style="display:flex;"><span>            trainer.zero_grad()
</span></span><span style="display:flex;"><span>            X, y = X.to(devices[<span style="color:#ff0;font-weight:bold">0</span>]), y.to(devices[<span style="color:#ff0;font-weight:bold">0</span>]) <span style="color:#007f7f"># 先把批量样本数据都暂时放到cuda:0中</span>
</span></span><span style="display:flex;"><span>            l = loss(net(X), y) <span style="color:#007f7f">#模型会自动将样本分发给多个GPU</span>
</span></span><span style="display:flex;"><span>            l.backward()
</span></span><span style="display:flex;"><span>            trainer.step()
</span></span><span style="display:flex;"><span>        timer.stop()
</span></span><span style="display:flex;"><span>        animator.add(epoch + <span style="color:#ff0;font-weight:bold">1</span>, (d2l.evaluate_accuracy_gpu(net, test_iter),))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;测试精度：</span><span style="color:#0ff;font-weight:bold">{</span>animator.Y[<span style="color:#ff0;font-weight:bold">0</span>][-<span style="color:#ff0;font-weight:bold">1</span>]<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.2f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">，</span><span style="color:#0ff;font-weight:bold">{</span>timer.avg()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">秒/轮，&#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;在</span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">str</span>(devices)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（3）比较</strong></p>
<ul>
<li>发现在批量数较大时，才能发挥并行计算的优势</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">## Batch size = 256</span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">1</span>,batch_size=<span style="color:#ff0;font-weight:bold">256</span>,lr=<span style="color:#ff0;font-weight:bold">0.1</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.90，7.9秒/轮，在[device(type=&#39;cuda&#39;, index=0)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">2</span>,batch_size=<span style="color:#ff0;font-weight:bold">512</span>,lr=<span style="color:#ff0;font-weight:bold">0.2</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.75，13.8秒/轮，在[device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">## Batch size = 512</span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">1</span>,batch_size=<span style="color:#ff0;font-weight:bold">512</span>,lr=<span style="color:#ff0;font-weight:bold">0.1</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.87，7.6秒/轮，在[device(type=&#39;cuda&#39;, index=0)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">2</span>,batch_size=<span style="color:#ff0;font-weight:bold">1024</span>,lr=<span style="color:#ff0;font-weight:bold">0.2</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.90，8.6秒/轮，在[device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">## Batch size = 1024</span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">1</span>,batch_size=<span style="color:#ff0;font-weight:bold">1024</span>,lr=<span style="color:#ff0;font-weight:bold">0.1</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.69，7.7秒/轮，在[device(type=&#39;cuda&#39;, index=0)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">2</span>,batch_size=<span style="color:#ff0;font-weight:bold">1024</span>*<span style="color:#ff0;font-weight:bold">2</span>,lr=<span style="color:#ff0;font-weight:bold">0.1</span>*<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.79，6.4秒/轮，在[device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train(net, num_gpus=<span style="color:#ff0;font-weight:bold">3</span>,batch_size=<span style="color:#ff0;font-weight:bold">1024</span>*<span style="color:#ff0;font-weight:bold">3</span>,lr=<span style="color:#ff0;font-weight:bold">0.1</span>*<span style="color:#ff0;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 测试精度：0.79，5.4秒/轮，在[device(type=&#39;cuda&#39;, index=0), device(type=&#39;cuda&#39;, index=1), device(type=&#39;cuda&#39;, index=2)]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>TIP：当训练的批量大小增大时，学习率也要相应的增加。</p></blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lishensuo.github.io/en/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
      <li><a href="https://lishensuo.github.io/en/tags/d2l/">D2L</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lishensuo.github.io/en/posts/bioinfo/714d2l-%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%8F%8A%E5%8D%81%E4%BA%94%E7%AB%A0bert%E6%A8%A1%E5%9E%8B/">
    <span class="title">« Prev Page</span>
    <br>
    <span>D2L--第十四及十五章BERT模型</span>
  </a>
  <a class="next" href="https://lishensuo.github.io/en/posts/bioinfo/716%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0--gan%E5%9F%BA%E7%A1%80/">
    <span class="title">Next Page »</span>
    <br>
    <span>深度学习--GAN基础</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lishensuo.github.io/en/">Li&#39;s Bioinfo-Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
		<br/>您是本站第 <span id="busuanzi_value_site_uv"></span> 位访问者，总浏览量为 <span id="busuanzi_value_site_pv"></span> 次
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>

<script type="text/javascript"
async
src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
displayMath: [['$$','$$'], ['\[\[','\]\]']],
processEscapes: true,
processEnvironments: true,
skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
TeX: { equationNumbers: { autoNumber: "AMS" },
extensions: ["AMSmath.js", "AMSsymbols.js"] }
}
});

MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style></body>
</html>

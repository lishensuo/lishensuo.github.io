<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">

<link rel="icon" href="/favicon.ico" type="image/x-icon"> 
<title>D2L--第九章现代循环神经网络 | Li&#39;s Bioinfo-Blog</title>
<meta name="keywords" content="深度学习, D2L">
<meta name="description" content="1. 门控循环单元(GRU)

传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。">
<meta name="author" content="Lishensuo">
<link rel="canonical" href="https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.9e4de5e3ba61ea358168341aa7cdf70abfaafb7c697dfe8624af3ddff9a35c2f.css" integrity="sha256-nk3l47ph6jWBaDQap833Cr&#43;q&#43;3xpff6GJK893/mjXC8=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.555af97124d54bb1457985dd081b8f5616a48103aafeb30ac89fde835d65aa6c.js" integrity="sha256-VVr5cSTVS7FFeYXdCBuPVhakgQOq/rMKyJ/eg11lqmw="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://lishensuo.github.io/img/Q.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://lishensuo.github.io/img/Q.gif">
<link rel="apple-touch-icon" href="https://lishensuo.github.io/Q.gif">
<link rel="mask-icon" href="https://lishensuo.github.io/Q.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="D2L--第九章现代循环神经网络" />
<meta property="og:description" content="1. 门控循环单元(GRU)

传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-11T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2024-08-11T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="D2L--第九章现代循环神经网络"/>
<meta name="twitter:description" content="1. 门控循环单元(GRU)

传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "分类",
      "item": "https://lishensuo.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📖 生信数据分析--分析流程，工具包等",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "D2L--第九章现代循环神经网络",
      "item": "https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "D2L--第九章现代循环神经网络",
  "name": "D2L--第九章现代循环神经网络",
  "description": "1. 门控循环单元(GRU) 传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。\n",
  "keywords": [
    "深度学习", "D2L"
  ],
  "articleBody": "1. 门控循环单元(GRU) 传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。\n1.1 门控隐藏状态 （1）重置门与更新门\n通过支持对隐状态的门控，模型可以学习序列中相对重要的词元，跳过不太相关的词元。GRU包括了两个门控单元：\n重置门：决定上一时刻的隐藏状态(Ht−1)有多少信息需要被“重置”或忽略，计算候选隐状态; 更新门：决定多少旧状态(Ht-1)应该被保留，多少新状态(即上面的候选隐状态，包括新输入的Xt)应该被添加到当前状态中。 计算上述两个门控单元的方式与RNN中Ht的计算公式基本一致，只是激活函数选择不同。这里使用的Sigmoid，使得转换为0~1范围，方便后续的控制操作。 （2）候选隐状态\n可通过重置门，来控制生成候选隐状态。 Rt = 1时，就是基本的RNN层（包含Ht-1与Xt）； Rt = 0时，上一步的隐状态会被重置/忽略，仅考虑Xt输入。 （3）隐状态\n更新门可以控制最终隐状态的输出，用于预测Ot Zt = 0时，会全部使用上述的候选隐状态（包含Xt） Zt = 1时，会丢弃候选隐状态，直接继承前一隐藏状态的Ht-1 若整个子序列的所有时间步的更新门都接近1，则序列起始时间步的隐状态将很容易保留、并传递到序列结束。 综上，\n重置门可以控制多大程度获得上一步骤的隐状态，有助于捕获序列中的短期依赖关系。 更新门可以控制多大程度学习当前步骤(Xt)的观测，有助于捕获序列中的长期依赖关系。 1.2 从零开始实现 加载数据 1 2 3 4 5 6 import torch from torch import nn from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) （1）初始化模型参数\n与RNN相比，多了更新门与重置门的模型参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def get_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device)) W_xz, W_hz, b_z = three() # 更新门参数 W_xr, W_hr, b_r = three() # 重置门参数 W_xh, W_hh, b_h = three() # 候选隐状态参数 # 输出层参数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params （2）定义模型\n隐状态初始化函数，与之前RNN一样 1 2 def init_gru_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), ) 定义GRU模型的传播, @表示按元素相乘的矩阵乘法 1 2 3 4 5 6 7 8 9 10 11 12 def gru(inputs, state, params): W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params H, = state outputs = [] for X in inputs: Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z) #更新门 R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r) #重置门 H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h) #候选隐状态 H = Z * H + (1 - Z) * H_tilda Y = H @ W_hq + b_q outputs.append(Y) return torch.cat(outputs, dim=0), (H,) 训练预测，与RNN代码基本一致 1 2 3 4 5 6 7 8 9 10 vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu() num_epochs, lr = 500, 1 # 定义模型 model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params, init_gru_state, gru) # 训练 d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # perplexity 1.1, 23869.1 tokens/sec on cuda:0 # time traveller for so it will be convenient to speak of himwas e # traveller afweryhin ing sfor the three dimensions of space 1.3 简洁实现 直接通过torch的nn.GRU()定义门控神经单元 1 2 3 4 5 6 7 8 9 10 11 num_inputs = vocab_size gru_layer = nn.GRU(num_inputs, num_hiddens) model = d2l.RNNModel(gru_layer, len(vocab)) model = model.to(device) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # perplexity 1.0, 132652.9 tokens/sec on cuda:0 # time travelleryou can show black is white by argument said filby # travelleryou can show black is white by argument said filby 2. 长短期记忆网络(LSTM) LSTM与GRU较为类似，其被早提出20年，设计更加复杂一点\n2.1 门控记忆元 除了隐状态以外，LSTM又提出了记忆元的概念。它与隐状态的形状相同，设计目的是用于记录更多的信息。 （1）输入门、输出门和输出门\n共有三个门被提出用于控制记忆元： 输出门用来控制从记忆元输出到隐状态； 输入门用来控制如何从上一步的隐状态以及当前的观测中学习记忆元； 遗忘门用来控制多大程度继承上一步的记忆元。 这三个门的计算方式与之前都类似 （2）候选记忆元\n候选记忆元的计算方式与上述也类似，只是激活函数为tanh，因此变换后的范围是(-1, 1) （3）记忆元\n如下图，计算当前时间步的记忆元基于两个门的控制； 输入门It控制多大程度来自于上述计算的候选记忆元； 遗忘门Ft控制多大程度来自于上一时间步的记忆元； （4）隐状态\n基于上述的计算，最终通过输出门Ot决定多大程度将记忆元输出作为隐状态 2.2 从零开始实现 加载数据 1 2 3 4 5 6 import torch from torch import nn from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) （1）初始化模型参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def get_lstm_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device)) #与GRU相比，在数量上多了一组门参数 W_xi, W_hi, b_i = three() # 输入门参数 W_xf, W_hf, b_f = three() # 遗忘门参数 W_xo, W_ho, b_o = three() # 输出门参数 W_xc, W_hc, b_c = three() # 候选记忆元参数 # 输出层参数 W_hq = normal((num_hiddens, num_outputs)) b_q = torch.zeros(num_outputs, device=device) # 附加梯度 params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] for param in params: param.requires_grad_(True) return params （2）定义模型\n初始化隐状态以及记忆元，二者的形状相同 1 2 3 def init_lstm_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device=device), torch.zeros((batch_size, num_hiddens), device=device)) 参照上述思路，定义LSTM的前向传播方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def lstm(inputs, state, params): [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params (H, C) = state #隐状态+记忆元 outputs = [] for X in inputs: I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i) F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f) O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o) C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) #候选记忆元 C = F * C + I * C_tilda #记忆元 H = O * torch.tanh(C) #隐状态 Y = (H @ W_hq) + b_q #预测输出 outputs.append(Y) return torch.cat(outputs, dim=0), (H, C) （3）训练和预测\n1 2 3 4 5 6 7 8 9 10 vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu() num_epochs, lr = 500, 1 model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # perplexity 1.1, 20088.5 tokens/sec on cuda:0 # time traveller proceeded anyreal body must have extension in fou # traveller and whyon geantating simong and why can thive yor 2.3 简洁实现 基于torch的nn.LSTM()，快速实现 1 2 3 4 5 6 7 8 9 10 num_inputs = vocab_size lstm_layer = nn.LSTM(num_inputs, num_hiddens) model = d2l.RNNModel(lstm_layer, len(vocab)) model = model.to(device) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # perplexity 1.0, 130362.3 tokens/sec on cuda:0 # time traveller with a slight accession ofcheerfulness really thi # travelleryou can show black is white by argument said filby 3. 深度RNN 对于之前学习的RNN，以及更加复杂的GRU、LSTM，本质上都可以理解为单隐藏层(Ht)的MLP。 可以搭建具有L个隐藏层的深度循环神经网络， 每个隐状态都连续地传递到当前层的下一个时间步和下一层的当前时间步。 3.1 简洁实现 加载数据 1 2 3 4 5 6 import torch from torch import nn from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) 如下以LSTM模型为例，仅需要在nn.LSTM()模型中的第三个参数中设置层数即可 1 2 3 4 5 6 7 8 vocab_size, num_hiddens, num_layers = len(vocab), 256, 2 num_inputs = vocab_size device = d2l.try_gpu() # num_layers设置为两层 lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers) model = d2l.RNNModel(lstm_layer, len(vocab)) model = model.to(device) 3.2 训练与预测 1 2 3 4 5 num_epochs, lr = 500, 2 d2l.train_ch8(model, train_iter, vocab, lr*1.0, num_epochs, device) # perplexity 1.0, 98815.1 tokens/sec on cuda:0 # time travelleryou can show black is white by argument said filby # travelleryou can show black is white by argument said filby 4. 双向RNN 4.1 定义 有时，序列的下文也对当前步的预测有帮助，例如我__, 请给我点吃的。\n双向RNN可以理解为有两个隐藏层的RNN模型，使用序列两端的信息预测输出。\n其中两层遍历序列的方向相反，分别计算前向与反向隐状态 最后将两个隐状态结果合并起来，共同用于计算Ot 双向RNN模型的计算速度较慢，主要原因是网络的前向传播需要在双向层中进行前向和后向递归， 并且网络的反向传播还依赖于前向传播的结果。 因此，梯度求解将有一个非常长的链。 此外，双向RNN模型的应用场景有限，不适合用于下文预测；可以用于填充缺失的单词、词元注释，机器翻译等。 4.2 错误应用 如上，双向RNN在预测时需要用到过去和未来的数据，不适合用于预测未来词元，尽管有时模型训练性能较好。 在torch中实现也很简单，仅需要设置相应的参数即可。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import torch from torch import nn from d2l import torch as d2l # 加载数据 batch_size, num_steps, device = 32, 35, d2l.try_gpu() train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) # 通过设置“bidirective=True”来定义双向LSTM模型 vocab_size, num_hiddens, num_layers = len(vocab), 256, 2 num_inputs = vocab_size lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=True) model = d2l.RNNModel(lstm_layer, len(vocab)) model = model.to(device) # 训练模型 num_epochs, lr = 500, 1 d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # perplexity 1.1, 64036.4 tokens/sec on cuda:0 # time travellerererererererererererererererererererererererererer # travellerererererererererererererererererererererererererer 5. 机器翻译与数据集 机器翻译是将一种语言翻译为另一种语言； 可以理解为是将输入序列转换成输出序列的序列转换模型。 接下来的后面几节都将学习如何实现 1 2 3 import os import torch from d2l import torch as d2l 5.1 下载和预处理 示例数据是一个’英语—法语’文本数据集。 每一行都是由制表符分割的文本序列对。 文本序列可以是单词，句子，段落（包含标点） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@save d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip', '94646ad1522d915e7b0f9296181140edcf86a4f5') #@save def read_data_nmt(): \"\"\"载入“英语－法语”数据集\"\"\" data_dir = d2l.download_extract('fra-eng') with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f: return f.read() raw_text = read_data_nmt() print(raw_text[:20]) # Go.\tVa ! # Hi.\tSalut ! 文本预处理操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #@save def preprocess_nmt(text): \"\"\"预处理“英语－法语”数据集\"\"\" # 返回逻辑值：字符是否为标点符号，且该字符前是否没有空格 def no_space(char, prev_char): return char in set(',.!?') and prev_char != ' ' # 使用空格替换不间断空格 # 使用小写字母替换大写字母 text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower() # 在单词和标点符号之间插入空格 out = [' ' + char if i \u003e 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)] return ''.join(out) text = preprocess_nmt(raw_text) print(text[:25]) # go .\tva ! # hi .\tsalut ! # ru 5.2 词元化 将单词以及标点符号认为是词元 在每一行中，对制表符前后的文本分别进行词元化，作为source与target 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #@save def tokenize_nmt(text, num_examples=None): \"\"\"词元化“英语－法语”数据数据集\"\"\" source, target = [], [] for i, line in enumerate(text.split('\\n')): if num_examples and i \u003e num_examples: break parts = line.split('\\t') if len(parts) == 2: source.append(parts[0].split(' ')) target.append(parts[1].split(' ')) return source, target #list of list source, target = tokenize_nmt(text) source[:3], target[:3] # ([['go', '.'], ['hi', '.'], ['run', '!']], # [['va', '!'], ['salut', '!'], ['cours', '!']]) 5.3 词表 分别为源语言（英语）以及目标（法语）语言构建词表； 将词频低于2的词元设置为’' 此外，额外指定几个特殊词元 ‘’ 填充词元 ‘’ 开始词元 ‘’ 结束词元 1 2 3 4 5 # 如下以源语言为例 src_vocab = d2l.Vocab(source, min_freq=2, reserved_tokens=['', '', '']) len(src_vocab) #词元类别数 # 10012 5.4 加载数据集 为了便于训练，需要将输入序列为设置为固定长度。此时会有如下两种情况 截断：仅取前面预期序列长度的词元，丢弃后面的词元 填充：当不满足预期序列长度时，在后面填充补齐 1 2 3 4 5 6 7 8 9 10 #@save def truncate_pad(line, num_steps, padding_token): \"\"\"截断或填充文本序列\"\"\" if len(line) \u003e num_steps: return line[:num_steps] # 截断 return line + [padding_token] * (num_steps - len(line)) # 填充 # 如下示例，对source的第一个词元序列进行处理，使用填充字符将长度补到10 truncate_pad(src_vocab[source[0]], 10, src_vocab['']) # [47, 4, 1, 1, 1, 1, 1, 1, 1, 1] 定义一个函数，对source/target进行上述处理，并在序列结尾加上一个’‘词元 此外，会统计一下每个序列的有效长度（除去填充词元） 1 2 3 4 5 6 7 8 9 #@save def build_array_nmt(lines, vocab, num_steps): \"\"\"将机器翻译的文本序列转换成小批量\"\"\" lines = [vocab[l] for l in lines] lines = [l + [vocab['']] for l in lines] array = torch.tensor([truncate_pad( l, num_steps, vocab['']) for l in lines]) valid_len = (array != vocab['']).type(torch.int32).sum(1) return array, valid_len 5.5 最终形式 定义一个综合函数，返回数据迭代器，源语言词表，目标语言词表 数据迭代器每次返回一个批量的输入序列与输出序列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #@save def load_data_nmt(batch_size, num_steps, num_examples=600): \"\"\"返回翻译数据集的迭代器和词表\"\"\" text = preprocess_nmt(read_data_nmt()) source, target = tokenize_nmt(text, num_examples) src_vocab = d2l.Vocab(source, min_freq=2, reserved_tokens=['', '', '']) tgt_vocab = d2l.Vocab(target, min_freq=2, reserved_tokens=['', '', '']) src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps) tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps) data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len) data_iter = d2l.load_array(data_arrays, batch_size) return data_iter, src_vocab, tgt_vocab 示例 1 2 3 4 5 6 7 8 9 10 11 12 13 train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8) for X, X_valid_len, Y, Y_valid_len in train_iter: print('X:', X.type(torch.int32)) print('X的有效长度:', X_valid_len) print('Y:', Y.type(torch.int32)) print('Y的有效长度:', Y_valid_len) break # X: tensor([[ 58, 47, 4, 3, 1, 1, 1, 1], # [ 7, 102, 5, 3, 1, 1, 1, 1]], dtype=torch.int32) # X的有效长度: tensor([4, 4]) # Y: tensor([[ 18, 14, 34, 4, 3, 1, 1, 1], # [ 6, 7, 161, 5, 3, 1, 1, 1]], dtype=torch.int32) # Y的有效长度: tensor([5, 5]) 6. 编码器与解码器架构 对于之前学习的CNN以及现在学习的RNN，都可以理解为编码器与解码器架构； 编码器：将输入变换为中间表达形式（特征）； 对于RNN，可将长度可变的序列作为输入，转换为具有固定形状的编码状态 解码器：将提取的中间表示编码成输出。 对于RNN，将固定形状的编码状态映射到长度可变的序列 接下来定义一个抽象的编码器-解码器接口，以方便后续的实现\n6.1 编码器 在编码器接口中，指定长度可变的序列作为输入X 1 2 3 4 5 6 7 8 9 10 from torch import nn #@save class Encoder(nn.Module): \"\"\"编码器-解码器架构的基本编码器接口\"\"\" def __init__(self, **kwargs): super(Encoder, self).__init__(**kwargs) def forward(self, X, *args): raise NotImplementedError raise NotImplementedError 是一种编程模式，用于表明某个方法或功能还没有准备好或者需要被子类覆盖以提供实际的行为。\n6.2 解码器 init_state用于初始化解码器的状态。 主要是将编码器的输出转换为编码后的状态 根据RNN思路，解码器在每个时间步都会将输入X （例如：在前一时间步生成的词元）和编码后的状态 映射成当前时间步的输出词元。 1 2 3 4 5 6 7 8 9 10 11 #@save class Decoder(nn.Module): \"\"\"编码器-解码器架构的基本解码器接口\"\"\" def __init__(self, **kwargs): super(Decoder, self).__init__(**kwargs) def init_state(self, enc_outputs, *args): raise NotImplementedError def forward(self, X, state): raise NotImplementedError 6.3 合并编码器与解码器 在前向传播中，\n编码器的输出用于生成编码状态； 这个状态又被解码器作为其输入的一部分。 1 2 3 4 5 6 7 8 9 10 11 12 #@save class EncoderDecoder(nn.Module): \"\"\"编码器-解码器架构的基类\"\"\" def __init__(self, encoder, decoder, **kwargs): super(EncoderDecoder, self).__init__(**kwargs) self.encoder = encoder self.decoder = decoder def forward(self, enc_X, dec_X, *args): enc_outputs = self.encoder(enc_X, *args) dec_state = self.decoder.init_state(enc_outputs, *args) return self.decoder(dec_X, dec_state) 7. 序列到序列学习(seq2seq) 序列到序列学习模型由两个RNN的编码器与解码器组成 编码器RNN：将输入序列的信息编码为固定形状的隐状态。 解码器RNN：基于编码器输入序列的编码信息以及当前时间步的词元，来预测下一个词元。 1 2 3 4 5 import collections import math import torch from torch import nn from d2l import torch as d2l 7.1 编码器 在编码器RNN部分，主要目的是得到输入序列最后一个时间步的隐状态表示（可以有多层）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #@save class Seq2SeqEncoder(d2l.Encoder): \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\" def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs): super(Seq2SeqEncoder, self).__init__(**kwargs) # 嵌入层：提取每个词元的特征向量 self.embedding = nn.Embedding(vocab_size, embed_size) # 这里使用多层的GRU循环神经网络 self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout) def forward(self, X, *args): # 输入'X'的形状：(batch_size,num_steps) # 输出'X'的形状：(batch_size,num_steps,embed_size) X = self.embedding(X) # 在循环神经网络模型中，需要将第一个轴设置为时间步（批量内的子序列） X = X.permute(1, 0, 2) # 如果未提及状态，则默认为0 output, state = self.rnn(X) # output的形状:(num_steps,batch_size,num_hiddens) # state的形状:(num_layers,batch_size,num_hiddens) return output, state output是基于每个时间步最后一层的隐状态（一般情况下后面需要跟全连接层进行预测输出）；\nstate是最后一个时间步的多层的隐状态。\n示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2) encoder.eval() X = torch.zeros((4, 7), dtype=torch.long) output, state = encoder(X) output.shape # torch.Size([7, 4, 16]) #(时间步数，批量大小，隐藏单元数) state.shape # torch.Size([2, 4, 16]) #(隐藏层的数量，批量大小，隐藏单元的数量) # output 批量内第1个子序列的第7个时间步的前5个值 # state 批量内第1个子序列的最后一个时间步的第2层的前5个值 output[6, 0, :5], state[1, 0, :5] # (tensor([ 0.0533, -0.2092, 0.0406, -0.0956, -0.3704], grad_fn=), # tensor([ 0.0533, -0.2092, 0.0406, -0.0956, -0.3704], grad_fn=)) 7.2 解码器 在解码器RNN中，\n一方面，会继承编码器RNN的最后一个时间步的所有隐状态，作为解码器输入序列的初始化隐状态； 另一方面会将编码器RNN的最后一个时间步的最后一层隐状态，作为解码器输入序列中每个观测词元的一部分特征（参考上图）。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Seq2SeqDecoder(d2l.Decoder): \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\" def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs): super(Seq2SeqDecoder, self).__init__(**kwargs) self.embedding = nn.Embedding(vocab_size, embed_size) # 观测词元输入=词元本身特征+编码器的信息context self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout) self.dense = nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, *args): return enc_outputs[1] #取state，而非output def forward(self, X, state): # 输出'X'的形状：(batch_size,num_steps,embed_size) X = self.embedding(X).permute(1, 0, 2) # 广播context，使其具有与X相同的num_steps context = state[-1].repeat(X.shape[0], 1, 1) X_and_context = torch.cat((X, context), 2) output, state = self.rnn(X_and_context, state) output = self.dense(output).permute(1, 0, 2) # output的形状:(batch_size,num_steps,vocab_size)，预测结果 # state的形状:(num_layers,batch_size,num_hiddens)，解码器序列最后一个时间步的隐状态 return output, state 7.3 损失函数 对于解码器的预测输出，一般使用平均交叉熵损失(Softmax)评价与标签序列的差异损失； 在计算损失时，应不需要关注对于序列中的填充词元的预测正确与否 换句话说，仅关注序列中有效词元的预测结果 1 2 3 4 5 6 7 8 9 10 11 12 13 #@save def sequence_mask(X, valid_len, value=0): \"\"\"在序列中屏蔽不相关的项\"\"\" maxlen = X.size(1) mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] \u003c valid_len[:, None] X[~mask] = value return X X = torch.tensor([[1, 2, 3], [4, 5, 6]]) sequence_mask(X, torch.tensor([1, 2])) # tensor([[1, 0, 0], #第一个词元以外的部分被置换为0 # [4, 5, 0]]) #前两个词元以外的部分被置换为0 据此自定义一个损失函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #@save class MaskedSoftmaxCELoss(nn.CrossEntropyLoss): \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\" # pred的形状：(batch_size,num_steps,vocab_size) # label的形状：(batch_size,num_steps) # valid_len的形状：(batch_size,) def forward(self, pred, label, valid_len): weights = torch.ones_like(label) #无效词元的权重设置为0，即忽略 weights = sequence_mask(weights, valid_len) self.reduction='none' #不会自动对输出进行平均或求和 unweighted_loss = super(MaskedSoftmaxCELoss, self).forward( pred.permute(0, 2, 1), label) #(batch_size, vocab_size, num_steps) 将类别概率放在第二维 weighted_loss = (unweighted_loss * weights).mean(dim=1) return weighted_loss 7.4 训练 在解码器中，’‘与原始的输出序列（不包含’’）连接在一起共同作为输入。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #@save def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device): \"\"\"训练序列到序列模型\"\"\" def xavier_init_weights(m): if type(m) == nn.Linear: nn.init.xavier_uniform_(m.weight) if type(m) == nn.GRU: for param in m._flat_weights_names: if \"weight\" in param: nn.init.xavier_uniform_(m._parameters[param]) net.apply(xavier_init_weights) net.to(device) optimizer = torch.optim.Adam(net.parameters(), lr=lr) loss = MaskedSoftmaxCELoss() net.train() animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[10, num_epochs]) for epoch in range(num_epochs): timer = d2l.Timer() metric = d2l.Accumulator(2) # 训练损失总和，词元数量 for batch in data_iter: optimizer.zero_grad() X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch] #在之前序列预处理里load_data_nmt中，已将每个序列末尾添加了词元 #对于解码器的输入序列，在开头插入一个bos词元。为保证长度不变，需要截掉序列的最后一个词元() bos = torch.tensor([tgt_vocab['']] * Y.shape[0], device=device).reshape(-1, 1) dec_input = torch.cat([bos, Y[:, :-1]], 1) # 强制教学 # X_valid_len本章暂时用不到，Y_valid_len会用到 Y_hat, _ = net(X, dec_input, X_valid_len) l = loss(Y_hat, Y, Y_valid_len) l.sum().backward() # 损失函数的标量进行“反向传播” d2l.grad_clipping(net, 1) num_tokens = Y_valid_len.sum() optimizer.step() with torch.no_grad(): metric.add(l.sum(), num_tokens) if (epoch + 1) % 10 == 0: animator.add(epoch + 1, (metric[0] / metric[1],)) print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} ' f'tokens/sec on {str(device)}') 实例化模型，并训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1 batch_size, num_steps = 64, 10 lr, num_epochs, device = 0.005, 300, d2l.try_gpu() train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps) encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout) decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout) net = d2l.EncoderDecoder(encoder, decoder) train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) # loss 0.019, 10100.9 tokens/sec on cuda:0 7.5 预测 与训练部分不同之处在于， 每个解码器当前时间步的输入都将来自于前一时间步的预测词元。而在训练时的解码器输入都是来自真实的词元。 src_sentence 表示用户的输入英语句子 src_vocab表示英语的索引词表 tgt_vocab表示法语的索引词表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #@save def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False): \"\"\"序列到序列模型的预测\"\"\" # 在预测时将net设置为评估模式 net.eval() src_tokens = src_vocab[src_sentence.lower().split(' ')] + [ src_vocab['']] enc_valid_len = torch.tensor([len(src_tokens)], device=device) src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['']) #固定长度 # 添加批量轴（作为第一个维度） enc_X = torch.unsqueeze( torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0) enc_outputs = net.encoder(enc_X, enc_valid_len) dec_state = net.decoder.init_state(enc_outputs, enc_valid_len) # 添加批量轴 dec_X = torch.unsqueeze(torch.tensor( [tgt_vocab['']], dtype=torch.long, device=device), dim=0) output_seq, attention_weight_seq = [], [] for _ in range(num_steps): Y, dec_state = net.decoder(dec_X, dec_state) # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入 dec_X = Y.argmax(dim=2) pred = dec_X.squeeze(dim=0).type(torch.int32).item() # 保存注意力权重（稍后讨论） if save_attention_weights: attention_weight_seq.append(net.decoder.attention_weights) # 一旦序列结束词元被预测，输出序列的生成就提前完成了 if pred == tgt_vocab['']: break output_seq.append(pred) return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq 7.6 预测序列的评估 可使用Bleu值评估预测序列与真实序列的差异；值越大，且接近1表示效果越好 当预测的序列长度小于真实序列长度时，前面的exp系数运算就会小于1，即对Bleu值惩罚； 当n值较大时的n元预测准确率越高时，Pn项就越大。 具体地说，给定标签序列A、B、C、D、E、F 和预测序列A、B、B、C、D， 我们有p1=4/5、p2=3/4、p3=1/3和p4=0。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def bleu(pred_seq, label_seq, k): #@save \"\"\"计算BLEU\"\"\" pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ') len_pred, len_label = len(pred_tokens), len(label_tokens) score = math.exp(min(0, 1 - len_label / len_pred)) for n in range(1, k + 1): num_matches, label_subs = 0, collections.defaultdict(int) for i in range(len_label - n + 1): label_subs[' '.join(label_tokens[i: i + n])] += 1 for i in range(len_pred - n + 1): if label_subs[' '.join(pred_tokens[i: i + n])] \u003e 0: num_matches += 1 label_subs[' '.join(pred_tokens[i: i + n])] -= 1 score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n)) return score 示例 1 2 3 4 5 6 7 8 9 10 engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .'] fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .'] for eng, fra in zip(engs, fras): translation, attention_weight_seq = predict_seq2seq( net, eng, src_vocab, tgt_vocab, num_steps, device) print(f'{eng} =\u003e {translation}, bleu {bleu(translation, fra, k=2):.3f}') # go . =\u003e va ., bleu 0.000 # i lost . =\u003e j'ai perdu ., bleu 1.000 # he's calm . =\u003e il est bon de de essaye ., bleu 0.418 # i'm home . =\u003e je suis chez de moi emporté ., bleu 0.578 ",
  "wordCount" : "8150",
  "inLanguage": "en",
  "datePublished": "2024-08-11T00:00:00Z",
  "dateModified": "2024-08-11T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Lishensuo"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lishensuo.github.io/en/posts/bioinfo/712d2l-%E7%AC%AC%E4%B9%9D%E7%AB%A0%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Li's Bioinfo-Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lishensuo.github.io/img/Q.gif"
    }
  }
}
</script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lishensuo.github.io/en/" accesskey="h" title="Li&#39;s Bioinfo-Blog (Alt + H)">Li&#39;s Bioinfo-Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lishensuo.github.io/en/" title="主页">
                    <span>主页</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/posts" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/tags" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/about" title="关于">
                    <span>关于</span>
                </a>
            </li>
            <li>
                <a href="https://lishensuo.github.io/en/search" title="搜索 (Alt &#43; /)" accesskey=/>
                    <span>搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://lishensuo.github.io/en/">Home</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/">分类</a>&nbsp;»&nbsp;<a href="https://lishensuo.github.io/en/posts/bioinfo/">📖 生信数据分析--分析流程，工具包等</a></div>
    <h1 class="post-title">
      D2L--第九章现代循环神经网络
    </h1>
    <div class="post-meta">













Create:&amp;nbsp;&lt;span title=&#39;2024-08-11 00:00:00 &#43;0000 UTC&#39;&gt;2024-08-11&lt;/span&gt;&amp;nbsp;|&amp;nbsp;Update:&amp;nbsp;2024-08-11&amp;nbsp;|&amp;nbsp;Words:&amp;nbsp;8150&amp;nbsp;|&amp;nbsp;17 min&amp;nbsp;|&amp;nbsp;Lishensuo

|  Viewers: <span id="busuanzi_value_page_pv"></span> 
	  
    </div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#1-%e9%97%a8%e6%8e%a7%e5%be%aa%e7%8e%af%e5%8d%95%e5%85%83gru" aria-label="1. 门控循环单元(GRU)">1. 门控循环单元(GRU)</a><ul>
                            
                    <li>
                        <a href="#11-%e9%97%a8%e6%8e%a7%e9%9a%90%e8%97%8f%e7%8a%b6%e6%80%81" aria-label="1.1 门控隐藏状态">1.1 门控隐藏状态</a></li>
                    <li>
                        <a href="#12-%e4%bb%8e%e9%9b%b6%e5%bc%80%e5%a7%8b%e5%ae%9e%e7%8e%b0" aria-label="1.2 从零开始实现">1.2 从零开始实现</a></li>
                    <li>
                        <a href="#13-%e7%ae%80%e6%b4%81%e5%ae%9e%e7%8e%b0" aria-label="1.3 简洁实现">1.3 简洁实现</a></li></ul>
                    </li>
                    <li>
                        <a href="#2-%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9clstm" aria-label="2. 长短期记忆网络(LSTM)">2. 长短期记忆网络(LSTM)</a><ul>
                            
                    <li>
                        <a href="#21-%e9%97%a8%e6%8e%a7%e8%ae%b0%e5%bf%86%e5%85%83" aria-label="2.1 门控记忆元">2.1 门控记忆元</a></li>
                    <li>
                        <a href="#22-%e4%bb%8e%e9%9b%b6%e5%bc%80%e5%a7%8b%e5%ae%9e%e7%8e%b0" aria-label="2.2 从零开始实现">2.2 从零开始实现</a></li>
                    <li>
                        <a href="#23-%e7%ae%80%e6%b4%81%e5%ae%9e%e7%8e%b0" aria-label="2.3 简洁实现">2.3 简洁实现</a></li></ul>
                    </li>
                    <li>
                        <a href="#3-%e6%b7%b1%e5%ba%a6rnn" aria-label="3. 深度RNN">3. 深度RNN</a><ul>
                            
                    <li>
                        <a href="#31-%e7%ae%80%e6%b4%81%e5%ae%9e%e7%8e%b0" aria-label="3.1 简洁实现">3.1 简洁实现</a></li>
                    <li>
                        <a href="#32-%e8%ae%ad%e7%bb%83%e4%b8%8e%e9%a2%84%e6%b5%8b" aria-label="3.2 训练与预测">3.2 训练与预测</a></li></ul>
                    </li>
                    <li>
                        <a href="#4-%e5%8f%8c%e5%90%91rnn" aria-label="4. 双向RNN">4. 双向RNN</a><ul>
                            
                    <li>
                        <a href="#41-%e5%ae%9a%e4%b9%89" aria-label="4.1 定义">4.1 定义</a></li>
                    <li>
                        <a href="#42-%e9%94%99%e8%af%af%e5%ba%94%e7%94%a8" aria-label="4.2 错误应用">4.2 错误应用</a></li></ul>
                    </li>
                    <li>
                        <a href="#5-%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="5. 机器翻译与数据集">5. 机器翻译与数据集</a><ul>
                            
                    <li>
                        <a href="#51-%e4%b8%8b%e8%bd%bd%e5%92%8c%e9%a2%84%e5%a4%84%e7%90%86" aria-label="5.1 下载和预处理">5.1 下载和预处理</a></li>
                    <li>
                        <a href="#52-%e8%af%8d%e5%85%83%e5%8c%96" aria-label="5.2 词元化">5.2 词元化</a></li>
                    <li>
                        <a href="#53-%e8%af%8d%e8%a1%a8" aria-label="5.3 词表">5.3 词表</a></li>
                    <li>
                        <a href="#54-%e5%8a%a0%e8%bd%bd%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="5.4 加载数据集">5.4 加载数据集</a></li>
                    <li>
                        <a href="#55-%e6%9c%80%e7%bb%88%e5%bd%a2%e5%bc%8f" aria-label="5.5 最终形式">5.5 最终形式</a></li></ul>
                    </li>
                    <li>
                        <a href="#6-%e7%bc%96%e7%a0%81%e5%99%a8%e4%b8%8e%e8%a7%a3%e7%a0%81%e5%99%a8%e6%9e%b6%e6%9e%84" aria-label="6. 编码器与解码器架构">6. 编码器与解码器架构</a><ul>
                            
                    <li>
                        <a href="#61-%e7%bc%96%e7%a0%81%e5%99%a8" aria-label="6.1 编码器">6.1 编码器</a></li>
                    <li>
                        <a href="#62-%e8%a7%a3%e7%a0%81%e5%99%a8" aria-label="6.2 解码器">6.2 解码器</a></li>
                    <li>
                        <a href="#63-%e5%90%88%e5%b9%b6%e7%bc%96%e7%a0%81%e5%99%a8%e4%b8%8e%e8%a7%a3%e7%a0%81%e5%99%a8" aria-label="6.3 合并编码器与解码器">6.3 合并编码器与解码器</a></li></ul>
                    </li>
                    <li>
                        <a href="#7-%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97%e5%ad%a6%e4%b9%a0seq2seq" aria-label="7. 序列到序列学习(seq2seq)">7. 序列到序列学习(seq2seq)</a><ul>
                            
                    <li>
                        <a href="#71-%e7%bc%96%e7%a0%81%e5%99%a8" aria-label="7.1 编码器">7.1 编码器</a></li>
                    <li>
                        <a href="#72-%e8%a7%a3%e7%a0%81%e5%99%a8" aria-label="7.2 解码器">7.2 解码器</a></li>
                    <li>
                        <a href="#73-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0" aria-label="7.3 损失函数">7.3 损失函数</a></li>
                    <li>
                        <a href="#74-%e8%ae%ad%e7%bb%83" aria-label="7.4 训练">7.4 训练</a></li>
                    <li>
                        <a href="#75-%e9%a2%84%e6%b5%8b" aria-label="7.5 预测">7.5 预测</a></li>
                    <li>
                        <a href="#76-%e9%a2%84%e6%b5%8b%e5%ba%8f%e5%88%97%e7%9a%84%e8%af%84%e4%bc%b0" aria-label="7.6 预测序列的评估">7.6 预测序列的评估</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>


  <div class="post-content"><h1 id="1-门控循环单元gru">1. 门控循环单元(GRU)<a hidden class="anchor" aria-hidden="true" href="#1-门控循环单元gru">#</a></h1>
<blockquote>
<p>传统的RNN在处理长序列时会遇到梯度消失或梯度爆炸的问题。为了解决这些问题，引入了门控机制的变种，如长短时记忆网络（LSTM, long short-term memory）和门控循环单元（GRU, gated recurrent unit）。GRU是LSTM的一个简化版本，它通过合并某些门并减少参数数量来提高效率。</p></blockquote>
<h2 id="11-门控隐藏状态">1.1 门控隐藏状态<a hidden class="anchor" aria-hidden="true" href="#11-门控隐藏状态">#</a></h2>
<p><strong>（1）重置门与更新门</strong></p>
<p>通过支持对隐状态的门控，模型可以学习序列中相对重要的词元，跳过不太相关的词元。GRU包括了两个门控单元：</p>
<ul>
<li><strong>重置门</strong>：决定上一时刻的隐藏状态(<strong>H</strong>t−1)有多少信息需要被“重置”或忽略，计算候选隐状态;</li>
<li><strong>更新门</strong>：决定多少旧状态(<strong>H</strong>t-1)应该被保留，多少新状态(即上面的候选隐状态，包括新输入的<strong>X</strong>t)应该被添加到当前状态中。</li>
<li>计算上述两个门控单元的方式与RNN中Ht的计算公式基本一致，只是激活函数选择不同。这里使用的Sigmoid，使得转换为0~1范围，方便后续的控制操作。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808102630079.png" alt="image-20240808102630079"  />
</p>
<p><strong>（2）候选隐状态</strong></p>
<ul>
<li>可通过重置门，来控制生成候选隐状态。</li>
<li>Rt = 1时，就是基本的RNN层（包含<strong>H</strong>t-1与<strong>X</strong>t）；</li>
<li>Rt = 0时，上一步的隐状态会被重置/忽略，仅考虑<strong>X</strong>t输入。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808103029769.png" alt="image-20240808103029769"  />
</p>
<p><strong>（3）隐状态</strong></p>
<ul>
<li>更新门可以控制最终隐状态的输出，用于预测<strong>O</strong>t</li>
<li>Zt = 0时，会全部使用上述的候选隐状态（包含<strong>X</strong>t）</li>
<li>Zt = 1时，会丢弃候选隐状态，直接继承前一隐藏状态的<strong>H</strong>t-1
<ul>
<li>若整个子序列的所有时间步的更新门都接近1，则序列起始时间步的隐状态将很容易保留、并传递到序列结束。</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808104015096.png" alt="image-20240808104015096"  />
</p>
<blockquote>
<p>综上，</p>
<ul>
<li>重置门可以控制<u>多大程度获得上一步骤的隐状态</u>，有助于捕获序列中的短期依赖关系。</li>
<li>更新门可以控制<u>多大程度学习当前步骤(Xt)的观测</u>，有助于捕获序列中的长期依赖关系。</li>
</ul></blockquote>
<h2 id="12-从零开始实现">1.2 从零开始实现<a hidden class="anchor" aria-hidden="true" href="#12-从零开始实现">#</a></h2>
<ul>
<li>加载数据</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（1）初始化模型参数</strong></p>
<ul>
<li>与RNN相比，多了更新门与重置门的模型参数</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_params(vocab_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    num_inputs = num_outputs = vocab_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> normal(shape):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> torch.randn(size=shape, device=device)*<span style="color:#ff0;font-weight:bold">0.01</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> three():
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> (normal((num_inputs, num_hiddens)),
</span></span><span style="display:flex;"><span>                normal((num_hiddens, num_hiddens)),
</span></span><span style="display:flex;"><span>                torch.zeros(num_hiddens, device=device))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    W_xz, W_hz, b_z = three()  <span style="color:#007f7f"># 更新门参数</span>
</span></span><span style="display:flex;"><span>    W_xr, W_hr, b_r = three()  <span style="color:#007f7f"># 重置门参数</span>
</span></span><span style="display:flex;"><span>    W_xh, W_hh, b_h = three()  <span style="color:#007f7f"># 候选隐状态参数</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 输出层参数</span>
</span></span><span style="display:flex;"><span>    W_hq = normal((num_hiddens, num_outputs))
</span></span><span style="display:flex;"><span>    b_q = torch.zeros(num_outputs, device=device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 附加梯度</span>
</span></span><span style="display:flex;"><span>    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> param in params:
</span></span><span style="display:flex;"><span>        param.requires_grad_(<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> params
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（2）定义模型</strong></p>
<ul>
<li>隐状态初始化函数，与之前RNN一样</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> init_gru_state(batch_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> (torch.zeros((batch_size, num_hiddens), device=device), )
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义GRU模型的传播, <code>@</code>表示按元素相乘的矩阵乘法</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> gru(inputs, state, params):
</span></span><span style="display:flex;"><span>    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params
</span></span><span style="display:flex;"><span>    H, = state
</span></span><span style="display:flex;"><span>    outputs = []
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> X in inputs:
</span></span><span style="display:flex;"><span>        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z) <span style="color:#007f7f">#更新门</span>
</span></span><span style="display:flex;"><span>        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r) <span style="color:#007f7f">#重置门</span>
</span></span><span style="display:flex;"><span>        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h) <span style="color:#007f7f">#候选隐状态</span>
</span></span><span style="display:flex;"><span>        H = Z * H + (<span style="color:#ff0;font-weight:bold">1</span> - Z) * H_tilda
</span></span><span style="display:flex;"><span>        Y = H @ W_hq + b_q
</span></span><span style="display:flex;"><span>        outputs.append(Y)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> torch.cat(outputs, dim=<span style="color:#ff0;font-weight:bold">0</span>), (H,)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>训练预测，与RNN代码基本一致</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vocab_size, num_hiddens, device = <span style="color:#fff;font-weight:bold">len</span>(vocab), <span style="color:#ff0;font-weight:bold">256</span>, d2l.try_gpu()
</span></span><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 定义模型</span>
</span></span><span style="display:flex;"><span>model = d2l.RNNModelScratch(<span style="color:#fff;font-weight:bold">len</span>(vocab), num_hiddens, device, get_params,
</span></span><span style="display:flex;"><span>                            init_gru_state, gru)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练</span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.1, 23869.1 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time traveller for so it will be convenient to speak of himwas e</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># traveller afweryhin ing sfor the three dimensions of space</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="13-简洁实现">1.3 简洁实现<a hidden class="anchor" aria-hidden="true" href="#13-简洁实现">#</a></h2>
<ul>
<li>直接通过torch的<code>nn.GRU()</code>定义门控神经单元</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_inputs = vocab_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gru_layer = nn.GRU(num_inputs, num_hiddens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model = d2l.RNNModel(gru_layer, <span style="color:#fff;font-weight:bold">len</span>(vocab))
</span></span><span style="display:flex;"><span>model = model.to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.0, 132652.9 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time travelleryou can show black is white by argument said filby</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travelleryou can show black is white by argument said filby</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="2-长短期记忆网络lstm">2. 长短期记忆网络(LSTM)<a hidden class="anchor" aria-hidden="true" href="#2-长短期记忆网络lstm">#</a></h1>
<p>LSTM与GRU较为类似，其被早提出20年，设计更加复杂一点</p>
<h2 id="21-门控记忆元">2.1 门控记忆元<a hidden class="anchor" aria-hidden="true" href="#21-门控记忆元">#</a></h2>
<ul>
<li>除了隐状态以外，LSTM又提出了记忆元的概念。它与隐状态的形状相同，设计目的是用于记录更多的信息。</li>
</ul>
<p><strong>（1）输入门、输出门和输出门</strong></p>
<ul>
<li>共有三个门被提出用于控制记忆元：
<ul>
<li>输出门用来控制从记忆元输出到隐状态；</li>
<li>输入门用来控制如何从上一步的隐状态以及当前的观测中学习记忆元；</li>
<li>遗忘门用来控制多大程度继承上一步的记忆元。</li>
</ul>
</li>
<li>这三个门的计算方式与之前都类似</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808162220950.png" alt="image-20240808162220950"  />
</p>
<p><strong>（2）候选记忆元</strong></p>
<ul>
<li>候选记忆元的计算方式与上述也类似，只是激活函数为tanh，因此变换后的范围是(-1, 1)</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808162522852.png" alt="image-20240808162522852"  />
</p>
<p><strong>（3）记忆元</strong></p>
<ul>
<li>如下图，计算当前时间步的记忆元基于两个门的控制；</li>
<li>输入门<strong>I</strong>t控制多大程度来自于上述计算的候选记忆元；</li>
<li>遗忘门<strong>F</strong>t控制多大程度来自于上一时间步的记忆元；</li>
</ul>
<p><img loading="lazy" src="C:%5cUsers%5cxiaoxin%5cAppData%5cRoaming%5cTypora%5ctypora-user-images%5cimage-20240808163653615.png" alt="image-20240808163653615"  />
</p>
<p><strong>（4）隐状态</strong></p>
<ul>
<li>基于上述的计算，最终通过输出门<strong>O</strong>t决定多大程度将记忆元输出作为隐状态</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808164312153.png" alt="image-20240808164312153"  />
</p>
<h2 id="22-从零开始实现">2.2 从零开始实现<a hidden class="anchor" aria-hidden="true" href="#22-从零开始实现">#</a></h2>
<ul>
<li>加载数据</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（1）初始化模型参数</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_lstm_params(vocab_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    num_inputs = num_outputs = vocab_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> normal(shape):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> torch.randn(size=shape, device=device)*<span style="color:#ff0;font-weight:bold">0.01</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> three():
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> (normal((num_inputs, num_hiddens)),
</span></span><span style="display:flex;"><span>                normal((num_hiddens, num_hiddens)),
</span></span><span style="display:flex;"><span>                torch.zeros(num_hiddens, device=device))
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f">#与GRU相比，在数量上多了一组门参数</span>
</span></span><span style="display:flex;"><span>    W_xi, W_hi, b_i = three()  <span style="color:#007f7f"># 输入门参数</span>
</span></span><span style="display:flex;"><span>    W_xf, W_hf, b_f = three()  <span style="color:#007f7f"># 遗忘门参数</span>
</span></span><span style="display:flex;"><span>    W_xo, W_ho, b_o = three()  <span style="color:#007f7f"># 输出门参数</span>
</span></span><span style="display:flex;"><span>    W_xc, W_hc, b_c = three()  <span style="color:#007f7f"># 候选记忆元参数</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 输出层参数</span>
</span></span><span style="display:flex;"><span>    W_hq = normal((num_hiddens, num_outputs))
</span></span><span style="display:flex;"><span>    b_q = torch.zeros(num_outputs, device=device)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 附加梯度</span>
</span></span><span style="display:flex;"><span>    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
</span></span><span style="display:flex;"><span>              b_c, W_hq, b_q]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> param in params:
</span></span><span style="display:flex;"><span>        param.requires_grad_(<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> params
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（2）定义模型</strong></p>
<ul>
<li>初始化隐状态以及记忆元，二者的形状相同</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> init_lstm_state(batch_size, num_hiddens, device):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> (torch.zeros((batch_size, num_hiddens), device=device),
</span></span><span style="display:flex;"><span>            torch.zeros((batch_size, num_hiddens), device=device))
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>参照上述思路，定义LSTM的前向传播方式</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> lstm(inputs, state, params):
</span></span><span style="display:flex;"><span>    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
</span></span><span style="display:flex;"><span>     W_hq, b_q] = params
</span></span><span style="display:flex;"><span>    (H, C) = state <span style="color:#007f7f">#隐状态+记忆元</span>
</span></span><span style="display:flex;"><span>    outputs = []
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> X in inputs:
</span></span><span style="display:flex;"><span>        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
</span></span><span style="display:flex;"><span>        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
</span></span><span style="display:flex;"><span>        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
</span></span><span style="display:flex;"><span>        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) <span style="color:#007f7f">#候选记忆元</span>
</span></span><span style="display:flex;"><span>        C = F * C + I * C_tilda <span style="color:#007f7f">#记忆元</span>
</span></span><span style="display:flex;"><span>        H = O * torch.tanh(C) <span style="color:#007f7f">#隐状态</span>
</span></span><span style="display:flex;"><span>        Y = (H @ W_hq) + b_q <span style="color:#007f7f">#预测输出</span>
</span></span><span style="display:flex;"><span>        outputs.append(Y)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> torch.cat(outputs, dim=<span style="color:#ff0;font-weight:bold">0</span>), (H, C)
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>（3）训练和预测</strong></p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vocab_size, num_hiddens, device = <span style="color:#fff;font-weight:bold">len</span>(vocab), <span style="color:#ff0;font-weight:bold">256</span>, d2l.try_gpu()
</span></span><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model = d2l.RNNModelScratch(<span style="color:#fff;font-weight:bold">len</span>(vocab), num_hiddens, device, get_lstm_params,
</span></span><span style="display:flex;"><span>                            init_lstm_state, lstm)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.1, 20088.5 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time traveller proceeded anyreal body must have extension in fou</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># traveller and whyon geantating simong and why can thive yor</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="23-简洁实现">2.3 简洁实现<a hidden class="anchor" aria-hidden="true" href="#23-简洁实现">#</a></h2>
<ul>
<li>基于torch的<code>nn.LSTM()</code>，快速实现</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_inputs = vocab_size
</span></span><span style="display:flex;"><span>lstm_layer = nn.LSTM(num_inputs, num_hiddens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model = d2l.RNNModel(lstm_layer, <span style="color:#fff;font-weight:bold">len</span>(vocab))
</span></span><span style="display:flex;"><span>model = model.to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.0, 130362.3 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time traveller with a slight accession ofcheerfulness really thi</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travelleryou can show black is white by argument said filby</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="3-深度rnn">3. 深度RNN<a hidden class="anchor" aria-hidden="true" href="#3-深度rnn">#</a></h1>
<ul>
<li>对于之前学习的RNN，以及更加复杂的GRU、LSTM，本质上都可以理解为单隐藏层(<strong>H</strong>t)的MLP。</li>
<li>可以搭建具有L个隐藏层的深度循环神经网络， 每个隐状态都连续地传递到当前层的下一个时间步和下一层的当前时间步。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808194229417.png" alt="image-20240808194229417"  />
</p>
<h2 id="31-简洁实现">3.1 简洁实现<a hidden class="anchor" aria-hidden="true" href="#31-简洁实现">#</a></h2>
<ul>
<li>加载数据</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>如下以LSTM模型为例，仅需要在<code>nn.LSTM()</code>模型中的第三个参数中设置层数即可</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vocab_size, num_hiddens, num_layers = <span style="color:#fff;font-weight:bold">len</span>(vocab), <span style="color:#ff0;font-weight:bold">256</span>, <span style="color:#ff0;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span>num_inputs = vocab_size
</span></span><span style="display:flex;"><span>device = d2l.try_gpu()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># num_layers设置为两层</span>
</span></span><span style="display:flex;"><span>lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)
</span></span><span style="display:flex;"><span>model = d2l.RNNModel(lstm_layer, <span style="color:#fff;font-weight:bold">len</span>(vocab))
</span></span><span style="display:flex;"><span>model = model.to(device)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="32-训练与预测">3.2 训练与预测<a hidden class="anchor" aria-hidden="true" href="#32-训练与预测">#</a></h2>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr*<span style="color:#ff0;font-weight:bold">1.0</span>, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.0, 98815.1 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time travelleryou can show black is white by argument said filby</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travelleryou can show black is white by argument said filby</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="4-双向rnn">4. 双向RNN<a hidden class="anchor" aria-hidden="true" href="#4-双向rnn">#</a></h1>
<h2 id="41-定义">4.1 定义<a hidden class="anchor" aria-hidden="true" href="#41-定义">#</a></h2>
<ul>
<li>
<p>有时，序列的下文也对当前步的预测有帮助，例如<code>我__, 请给我点吃的。</code></p>
</li>
<li>
<p>双向RNN可以理解为有两个隐藏层的RNN模型，使用序列两端的信息预测输出。</p>
<ul>
<li>其中两层遍历序列的方向相反，分别计算前向与反向隐状态</li>
<li>最后将两个隐状态结果合并起来，共同用于计算<strong>O</strong>t</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240808203233504.png" alt="image-20240808203233504"  />
</p>
<ul>
<li>双向RNN模型的计算速度较慢，主要原因是网络的前向传播需要在双向层中进行前向和后向递归， 并且网络的反向传播还依赖于前向传播的结果。 因此，梯度求解将有一个非常长的链。</li>
<li>此外，双向RNN模型的应用场景有限，不适合用于下文预测；可以用于填充缺失的单词、词元注释，机器翻译等。</li>
</ul>
<h2 id="42-错误应用">4.2 错误应用<a hidden class="anchor" aria-hidden="true" href="#42-错误应用">#</a></h2>
<ul>
<li>如上，双向RNN在预测时需要用到过去和未来的数据，不适合用于预测未来词元，尽管有时模型训练性能较好。</li>
<li>在torch中实现也很简单，仅需要设置相应的参数即可。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 加载数据</span>
</span></span><span style="display:flex;"><span>batch_size, num_steps, device = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">35</span>, d2l.try_gpu()
</span></span><span style="display:flex;"><span>train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 通过设置“bidirective=True”来定义双向LSTM模型</span>
</span></span><span style="display:flex;"><span>vocab_size, num_hiddens, num_layers = <span style="color:#fff;font-weight:bold">len</span>(vocab), <span style="color:#ff0;font-weight:bold">256</span>, <span style="color:#ff0;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span>num_inputs = vocab_size
</span></span><span style="display:flex;"><span>lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=<span style="color:#fff;font-weight:bold">True</span>) 
</span></span><span style="display:flex;"><span>model = d2l.RNNModel(lstm_layer, <span style="color:#fff;font-weight:bold">len</span>(vocab))
</span></span><span style="display:flex;"><span>model = model.to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 训练模型</span>
</span></span><span style="display:flex;"><span>num_epochs, lr = <span style="color:#ff0;font-weight:bold">500</span>, <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># perplexity 1.1, 64036.4 tokens/sec on cuda:0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># time travellerererererererererererererererererererererererererer</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># travellerererererererererererererererererererererererererer</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="5-机器翻译与数据集">5. 机器翻译与数据集<a hidden class="anchor" aria-hidden="true" href="#5-机器翻译与数据集">#</a></h1>
<ul>
<li>机器翻译是将一种语言翻译为另一种语言；</li>
<li>可以理解为是将输入序列转换成输出序列的序列转换模型。</li>
<li>接下来的后面几节都将学习如何实现</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="51-下载和预处理">5.1 下载和预处理<a hidden class="anchor" aria-hidden="true" href="#51-下载和预处理">#</a></h2>
<ul>
<li>示例数据是一个&rsquo;英语—法语&rsquo;文本数据集。</li>
<li>每一行都是由制表符分割的文本序列对。</li>
<li>文本序列可以是单词，句子，段落（包含标点）</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>d2l.DATA_HUB[<span style="color:#0ff;font-weight:bold">&#39;fra-eng&#39;</span>] = (d2l.DATA_URL + <span style="color:#0ff;font-weight:bold">&#39;fra-eng.zip&#39;</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#0ff;font-weight:bold">&#39;94646ad1522d915e7b0f9296181140edcf86a4f5&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> read_data_nmt():
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;载入“英语－法语”数据集&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    data_dir = d2l.download_extract(<span style="color:#0ff;font-weight:bold">&#39;fra-eng&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(os.path.join(data_dir, <span style="color:#0ff;font-weight:bold">&#39;fra.txt&#39;</span>), <span style="color:#0ff;font-weight:bold">&#39;r&#39;</span>,
</span></span><span style="display:flex;"><span>             encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> f:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> f.read()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>raw_text = read_data_nmt()
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(raw_text[:<span style="color:#ff0;font-weight:bold">20</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Go.	Va !</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Hi.	Salut !</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>文本预处理操作</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> preprocess_nmt(text):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;预处理“英语－法语”数据集&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 返回逻辑值：字符是否为标点符号，且该字符前是否没有空格</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> no_space(char, prev_char):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> char in <span style="color:#fff;font-weight:bold">set</span>(<span style="color:#0ff;font-weight:bold">&#39;,.!?&#39;</span>) and prev_char != <span style="color:#0ff;font-weight:bold">&#39; &#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 使用空格替换不间断空格</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 使用小写字母替换大写字母</span>
</span></span><span style="display:flex;"><span>    text = text.replace(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\u202f</span><span style="color:#0ff;font-weight:bold">&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39; &#39;</span>).replace(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\xa0</span><span style="color:#0ff;font-weight:bold">&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39; &#39;</span>).lower()
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 在单词和标点符号之间插入空格</span>
</span></span><span style="display:flex;"><span>    out = [<span style="color:#0ff;font-weight:bold">&#39; &#39;</span> + char <span style="color:#fff;font-weight:bold">if</span> i &gt; <span style="color:#ff0;font-weight:bold">0</span> and no_space(char, text[i - <span style="color:#ff0;font-weight:bold">1</span>]) <span style="color:#fff;font-weight:bold">else</span> char
</span></span><span style="display:flex;"><span>           <span style="color:#fff;font-weight:bold">for</span> i, char in <span style="color:#fff;font-weight:bold">enumerate</span>(text)]
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> <span style="color:#0ff;font-weight:bold">&#39;&#39;</span>.join(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text = preprocess_nmt(raw_text)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(text[:<span style="color:#ff0;font-weight:bold">25</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># go .	va !</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># hi .	salut !</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># ru</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="52-词元化">5.2 词元化<a hidden class="anchor" aria-hidden="true" href="#52-词元化">#</a></h2>
<ul>
<li>将单词以及标点符号认为是词元</li>
<li>在每一行中，对制表符前后的文本分别进行词元化，作为source与target</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> tokenize_nmt(text, num_examples=<span style="color:#fff;font-weight:bold">None</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;词元化“英语－法语”数据数据集&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    source, target = [], []
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> i, line in <span style="color:#fff;font-weight:bold">enumerate</span>(text.split(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>)):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> num_examples and i &gt; num_examples:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">break</span>
</span></span><span style="display:flex;"><span>        parts = line.split(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\t</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">len</span>(parts) == <span style="color:#ff0;font-weight:bold">2</span>:
</span></span><span style="display:flex;"><span>            source.append(parts[<span style="color:#ff0;font-weight:bold">0</span>].split(<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>))
</span></span><span style="display:flex;"><span>            target.append(parts[<span style="color:#ff0;font-weight:bold">1</span>].split(<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> source, target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#list of list</span>
</span></span><span style="display:flex;"><span>source, target = tokenize_nmt(text)
</span></span><span style="display:flex;"><span>source[:<span style="color:#ff0;font-weight:bold">3</span>], target[:<span style="color:#ff0;font-weight:bold">3</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># ([[&#39;go&#39;, &#39;.&#39;], [&#39;hi&#39;, &#39;.&#39;], [&#39;run&#39;, &#39;!&#39;]],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  [[&#39;va&#39;, &#39;!&#39;], [&#39;salut&#39;, &#39;!&#39;], [&#39;cours&#39;, &#39;!&#39;]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="53-词表">5.3 词表<a hidden class="anchor" aria-hidden="true" href="#53-词表">#</a></h2>
<ul>
<li>分别为源语言（英语）以及目标（法语）语言构建词表；</li>
<li>将词频低于2的词元设置为&rsquo;&lt;unk&gt;'</li>
<li>此外，额外指定几个特殊词元
<ul>
<li>&lsquo;&lt;pad&gt;&rsquo; 填充词元</li>
<li>&lsquo;&lt;bos&gt;&rsquo; 开始词元</li>
<li>&lsquo;&lt;eos&gt;&rsquo; 结束词元</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 如下以源语言为例</span>
</span></span><span style="display:flex;"><span>src_vocab = d2l.Vocab(source, min_freq=<span style="color:#ff0;font-weight:bold">2</span>,
</span></span><span style="display:flex;"><span>                      reserved_tokens=[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;bos&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">len</span>(src_vocab) <span style="color:#007f7f">#词元类别数</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 10012</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="54-加载数据集">5.4 加载数据集<a hidden class="anchor" aria-hidden="true" href="#54-加载数据集">#</a></h2>
<ul>
<li>为了便于训练，需要将输入序列为设置为固定长度。此时会有如下两种情况
<ul>
<li><strong>截断</strong>：仅取前面预期序列长度的词元，丢弃后面的词元</li>
<li><strong>填充</strong>：当不满足预期序列长度时，在后面填充补齐</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> truncate_pad(line, num_steps, padding_token):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;截断或填充文本序列&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">len</span>(line) &gt; num_steps:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> line[:num_steps]  <span style="color:#007f7f"># 截断</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> line + [padding_token] * (num_steps - <span style="color:#fff;font-weight:bold">len</span>(line))  <span style="color:#007f7f"># 填充</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 如下示例，对source的第一个词元序列进行处理，使用填充字符将长度补到10</span>
</span></span><span style="display:flex;"><span>truncate_pad(src_vocab[source[<span style="color:#ff0;font-weight:bold">0</span>]], <span style="color:#ff0;font-weight:bold">10</span>, src_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>])
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># [47, 4, 1, 1, 1, 1, 1, 1, 1, 1]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>定义一个函数，对source/target进行上述处理，并在序列结尾加上一个&rsquo;&lt;eos&gt;&lsquo;词元
<ul>
<li>此外，会统计一下每个序列的有效长度（除去填充词元）</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">9
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> build_array_nmt(lines, vocab, num_steps):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;将机器翻译的文本序列转换成小批量&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    lines = [vocab[l] <span style="color:#fff;font-weight:bold">for</span> l in lines]
</span></span><span style="display:flex;"><span>    lines = [l + [vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>]] <span style="color:#fff;font-weight:bold">for</span> l in lines]
</span></span><span style="display:flex;"><span>    array = torch.tensor([truncate_pad(
</span></span><span style="display:flex;"><span>        l, num_steps, vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>]) <span style="color:#fff;font-weight:bold">for</span> l in lines])
</span></span><span style="display:flex;"><span>    valid_len = (array != vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>]).type(torch.int32).sum(<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> array, valid_len
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="55-最终形式">5.5 最终形式<a hidden class="anchor" aria-hidden="true" href="#55-最终形式">#</a></h2>
<ul>
<li>定义一个综合函数，返回数据迭代器，源语言词表，目标语言词表
<ul>
<li>数据迭代器每次返回一个批量的输入序列与输出序列</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> load_data_nmt(batch_size, num_steps, num_examples=<span style="color:#ff0;font-weight:bold">600</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;返回翻译数据集的迭代器和词表&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    text = preprocess_nmt(read_data_nmt())
</span></span><span style="display:flex;"><span>    source, target = tokenize_nmt(text, num_examples)
</span></span><span style="display:flex;"><span>    src_vocab = d2l.Vocab(source, min_freq=<span style="color:#ff0;font-weight:bold">2</span>,
</span></span><span style="display:flex;"><span>                          reserved_tokens=[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;bos&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>])
</span></span><span style="display:flex;"><span>    tgt_vocab = d2l.Vocab(target, min_freq=<span style="color:#ff0;font-weight:bold">2</span>,
</span></span><span style="display:flex;"><span>                          reserved_tokens=[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;bos&gt;&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>])
</span></span><span style="display:flex;"><span>    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)
</span></span><span style="display:flex;"><span>    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)
</span></span><span style="display:flex;"><span>    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)
</span></span><span style="display:flex;"><span>    data_iter = d2l.load_array(data_arrays, batch_size)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> data_iter, src_vocab, tgt_vocab
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=<span style="color:#ff0;font-weight:bold">2</span>, num_steps=<span style="color:#ff0;font-weight:bold">8</span>)
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> X, X_valid_len, Y, Y_valid_len in train_iter:
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;X:&#39;</span>, X.type(torch.int32))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;X的有效长度:&#39;</span>, X_valid_len)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;Y:&#39;</span>, Y.type(torch.int32))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">&#39;Y的有效长度:&#39;</span>, Y_valid_len)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">break</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># X: tensor([[ 58,  47,   4,   3,   1,   1,   1,   1],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#         [  7, 102,   5,   3,   1,   1,   1,   1]], dtype=torch.int32)</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># X的有效长度: tensor([4, 4])</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Y: tensor([[ 18,  14,  34,   4,   3,   1,   1,   1],</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#         [  6,   7, 161,   5,   3,   1,   1,   1]], dtype=torch.int32)</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Y的有效长度: tensor([5, 5])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="6-编码器与解码器架构">6. 编码器与解码器架构<a hidden class="anchor" aria-hidden="true" href="#6-编码器与解码器架构">#</a></h1>
<ul>
<li>对于之前学习的CNN以及现在学习的RNN，都可以理解为编码器与解码器架构；</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809072826713.png" alt="image-20240809072826713" style="zoom:50%;" />
<ul>
<li><strong>编码器</strong>：将输入变换为中间表达形式（特征）；
<ul>
<li>对于RNN，可将长度可变的序列作为输入，转换为具有固定形状的编码状态</li>
</ul>
</li>
<li><strong>解码器</strong>：将提取的中间表示编码成输出。
<ul>
<li>对于RNN，将固定形状的编码状态映射到长度可变的序列</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809073527675.png" alt="image-20240809073527675"  />
</p>
<p>接下来定义一个抽象的编码器-解码器接口，以方便后续的实现</p>
<h2 id="61-编码器">6.1 编码器<a hidden class="anchor" aria-hidden="true" href="#61-编码器">#</a></h2>
<ul>
<li>在编码器接口中，指定长度可变的序列作为输入X</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Encoder(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;编码器-解码器架构的基本编码器接口&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(Encoder, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, X, *args):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">raise</span> NotImplementedError
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p><code>raise NotImplementedError</code> 是一种编程模式，用于表明某个方法或功能还没有准备好或者需要被子类覆盖以提供实际的行为。</p></blockquote>
<h2 id="62-解码器">6.2 解码器<a hidden class="anchor" aria-hidden="true" href="#62-解码器">#</a></h2>
<ul>
<li><code>init_state</code>用于初始化解码器的状态。
<ul>
<li>主要是将编码器的输出转换为编码后的状态</li>
</ul>
</li>
<li>根据RNN思路，解码器在每个时间步都会将输入<strong>X</strong> （例如：在前一时间步生成的词元）和编码后的状态 映射成当前时间步的输出词元。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Decoder(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;编码器-解码器架构的基本解码器接口&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(Decoder, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> init_state(<span style="color:#fff;font-weight:bold">self</span>, enc_outputs, *args):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">raise</span> NotImplementedError
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, X, state):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">raise</span> NotImplementedError
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="63-合并编码器与解码器">6.3 合并编码器与解码器<a hidden class="anchor" aria-hidden="true" href="#63-合并编码器与解码器">#</a></h2>
<p>在前向传播中，</p>
<ul>
<li>编码器的输出用于生成编码状态；</li>
<li>这个状态又被解码器作为其输入的一部分。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> EncoderDecoder(nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;编码器-解码器架构的基类&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, encoder, decoder, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(EncoderDecoder, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.encoder = encoder
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.decoder = decoder
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, enc_X, dec_X, *args):
</span></span><span style="display:flex;"><span>        enc_outputs = <span style="color:#fff;font-weight:bold">self</span>.encoder(enc_X, *args)
</span></span><span style="display:flex;"><span>        dec_state = <span style="color:#fff;font-weight:bold">self</span>.decoder.init_state(enc_outputs, *args)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">self</span>.decoder(dec_X, dec_state)
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="7-序列到序列学习seq2seq">7. 序列到序列学习(seq2seq)<a hidden class="anchor" aria-hidden="true" href="#7-序列到序列学习seq2seq">#</a></h1>
<ul>
<li>序列到序列学习模型由两个RNN的编码器与解码器组成
<ul>
<li><strong>编码器RNN</strong>：将输入序列的信息编码为固定形状的隐状态。</li>
<li><strong>解码器RNN</strong>：基于编码器输入序列的编码信息以及当前时间步的词元，来预测下一个词元。</li>
</ul>
</li>
</ul>
<img src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809142553682.png" alt="image-20240809142553682" style="zoom: 67%;" />
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> collections
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch <span style="color:#fff;font-weight:bold">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> d2l <span style="color:#fff;font-weight:bold">import</span> torch <span style="color:#fff;font-weight:bold">as</span> d2l
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="71-编码器">7.1 编码器<a hidden class="anchor" aria-hidden="true" href="#71-编码器">#</a></h2>
<ul>
<li>在编码器RNN部分，主要目的是得到输入序列最后一个时间步的隐状态表示（可以有多层）。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Seq2SeqEncoder(d2l.Encoder):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;用于序列到序列学习的循环神经网络编码器&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, vocab_size, embed_size, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                 dropout=<span style="color:#ff0;font-weight:bold">0</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(Seq2SeqEncoder, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 嵌入层：提取每个词元的特征向量</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.embedding = nn.Embedding(vocab_size, embed_size)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 这里使用多层的GRU循环神经网络</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.rnn = nn.GRU(embed_size, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                          dropout=dropout)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, X, *args):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 输入&#39;X&#39;的形状：(batch_size,num_steps)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
</span></span><span style="display:flex;"><span>        X = <span style="color:#fff;font-weight:bold">self</span>.embedding(X)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 在循环神经网络模型中，需要将第一个轴设置为时间步（批量内的子序列）</span>
</span></span><span style="display:flex;"><span>        X = X.permute(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 如果未提及状态，则默认为0</span>
</span></span><span style="display:flex;"><span>        output, state = <span style="color:#fff;font-weight:bold">self</span>.rnn(X)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># output的形状:(num_steps,batch_size,num_hiddens)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># state的形状:(num_layers,batch_size,num_hiddens)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> output, state
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>output是基于每个时间步最后一层的隐状态（一般情况下后面需要跟全连接层进行预测输出）；</p>
<p>state是最后一个时间步的多层的隐状态。</p></blockquote>
<ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>encoder = Seq2SeqEncoder(vocab_size=<span style="color:#ff0;font-weight:bold">10</span>, embed_size=<span style="color:#ff0;font-weight:bold">8</span>, num_hiddens=<span style="color:#ff0;font-weight:bold">16</span>,
</span></span><span style="display:flex;"><span>                         num_layers=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>encoder.eval()
</span></span><span style="display:flex;"><span>X = torch.zeros((<span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">7</span>), dtype=torch.long)
</span></span><span style="display:flex;"><span>output, state = encoder(X)
</span></span><span style="display:flex;"><span>output.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([7, 4, 16])  #(时间步数，批量大小，隐藏单元数)</span>
</span></span><span style="display:flex;"><span>state.shape
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># torch.Size([2, 4, 16])  #(隐藏层的数量，批量大小，隐藏单元的数量)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># output 批量内第1个子序列的第7个时间步的前5个值</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># state 批量内第1个子序列的最后一个时间步的第2层的前5个值</span>
</span></span><span style="display:flex;"><span>output[<span style="color:#ff0;font-weight:bold">6</span>, <span style="color:#ff0;font-weight:bold">0</span>, :<span style="color:#ff0;font-weight:bold">5</span>], state[<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">0</span>, :<span style="color:#ff0;font-weight:bold">5</span>]
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># (tensor([ 0.0533, -0.2092,  0.0406, -0.0956, -0.3704], grad_fn=&lt;SliceBackward0&gt;),</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  tensor([ 0.0533, -0.2092,  0.0406, -0.0956, -0.3704], grad_fn=&lt;SliceBackward0&gt;))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="72-解码器">7.2 解码器<a hidden class="anchor" aria-hidden="true" href="#72-解码器">#</a></h2>
<p>在解码器RNN中，</p>
<ul>
<li>一方面，会继承编码器RNN的最后一个时间步的所有隐状态，作为解码器输入序列的初始化隐状态；</li>
<li>另一方面会将编码器RNN的最后一个时间步的最后一层隐状态，作为解码器输入序列中每个观测词元的一部分特征（参考上图）。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> Seq2SeqDecoder(d2l.Decoder):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;用于序列到序列学习的循环神经网络解码器&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(<span style="color:#fff;font-weight:bold">self</span>, vocab_size, embed_size, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                 dropout=<span style="color:#ff0;font-weight:bold">0</span>, **kwargs):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(Seq2SeqDecoder, <span style="color:#fff;font-weight:bold">self</span>).__init__(**kwargs)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.embedding = nn.Embedding(vocab_size, embed_size)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 观测词元输入=词元本身特征+编码器的信息context</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                          dropout=dropout)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.dense = nn.Linear(num_hiddens, vocab_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> init_state(<span style="color:#fff;font-weight:bold">self</span>, enc_outputs, *args):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> enc_outputs[<span style="color:#ff0;font-weight:bold">1</span>] <span style="color:#007f7f">#取state，而非output</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, X, state):
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
</span></span><span style="display:flex;"><span>        X = <span style="color:#fff;font-weight:bold">self</span>.embedding(X).permute(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 广播context，使其具有与X相同的num_steps</span>
</span></span><span style="display:flex;"><span>        context = state[-<span style="color:#ff0;font-weight:bold">1</span>].repeat(X.shape[<span style="color:#ff0;font-weight:bold">0</span>], <span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>        X_and_context = torch.cat((X, context), <span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        output, state = <span style="color:#fff;font-weight:bold">self</span>.rnn(X_and_context, state)
</span></span><span style="display:flex;"><span>        output = <span style="color:#fff;font-weight:bold">self</span>.dense(output).permute(<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># output的形状:(batch_size,num_steps,vocab_size)，预测结果</span>
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># state的形状:(num_layers,batch_size,num_hiddens)，解码器序列最后一个时间步的隐状态</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> output, state
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809160845276.png" alt="image-20240809160845276"  />
</p>
<h2 id="73-损失函数">7.3 损失函数<a hidden class="anchor" aria-hidden="true" href="#73-损失函数">#</a></h2>
<ul>
<li>对于解码器的预测输出，一般使用平均交叉熵损失(Softmax)评价与标签序列的差异损失；</li>
<li>在计算损失时，应不需要关注对于序列中的填充词元的预测正确与否
<ul>
<li>换句话说，仅关注序列中有效词元的预测结果</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> sequence_mask(X, valid_len, value=<span style="color:#ff0;font-weight:bold">0</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;在序列中屏蔽不相关的项&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    maxlen = X.size(<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>    mask = torch.arange((maxlen), dtype=torch.float32,
</span></span><span style="display:flex;"><span>                        device=X.device)[<span style="color:#fff;font-weight:bold">None</span>, :] &lt; valid_len[:, <span style="color:#fff;font-weight:bold">None</span>]
</span></span><span style="display:flex;"><span>    X[~mask] = value
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> X
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X = torch.tensor([[<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">3</span>], [<span style="color:#ff0;font-weight:bold">4</span>, <span style="color:#ff0;font-weight:bold">5</span>, <span style="color:#ff0;font-weight:bold">6</span>]])
</span></span><span style="display:flex;"><span>sequence_mask(X, torch.tensor([<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">2</span>]))
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># tensor([[1, 0, 0],   #第一个词元以外的部分被置换为0</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#         [4, 5, 0]])  #前两个词元以外的部分被置换为0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>据此自定义一个损失函数</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;带遮蔽的softmax交叉熵损失函数&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># pred的形状：(batch_size,num_steps,vocab_size)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># label的形状：(batch_size,num_steps)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># valid_len的形状：(batch_size,)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(<span style="color:#fff;font-weight:bold">self</span>, pred, label, valid_len):
</span></span><span style="display:flex;"><span>        weights = torch.ones_like(label)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f">#无效词元的权重设置为0，即忽略</span>
</span></span><span style="display:flex;"><span>        weights = sequence_mask(weights, valid_len)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">self</span>.reduction=<span style="color:#0ff;font-weight:bold">&#39;none&#39;</span> <span style="color:#007f7f">#不会自动对输出进行平均或求和</span>
</span></span><span style="display:flex;"><span>        unweighted_loss = <span style="color:#fff;font-weight:bold">super</span>(MaskedSoftmaxCELoss, <span style="color:#fff;font-weight:bold">self</span>).forward(
</span></span><span style="display:flex;"><span>            pred.permute(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">1</span>), label) 
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f">#(batch_size, vocab_size, num_steps) 将类别概率放在第二维</span>
</span></span><span style="display:flex;"><span>        weighted_loss = (unweighted_loss * weights).mean(dim=<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> weighted_loss
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="74-训练">7.4 训练<a hidden class="anchor" aria-hidden="true" href="#74-训练">#</a></h2>
<ul>
<li>在解码器中，&rsquo;&lt;bos&gt;&lsquo;与原始的输出序列（不包含&rsquo;&lt;eos&gt;&rsquo;）连接在一起共同作为输入。</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">42
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;训练序列到序列模型&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> xavier_init_weights(m):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) == nn.Linear:
</span></span><span style="display:flex;"><span>            nn.init.xavier_uniform_(m.weight)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">type</span>(m) == nn.GRU:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">for</span> param in m._flat_weights_names:
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">if</span> <span style="color:#0ff;font-weight:bold">&#34;weight&#34;</span> in param:
</span></span><span style="display:flex;"><span>                    nn.init.xavier_uniform_(m._parameters[param])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    net.apply(xavier_init_weights)
</span></span><span style="display:flex;"><span>    net.to(device)
</span></span><span style="display:flex;"><span>    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
</span></span><span style="display:flex;"><span>    loss = MaskedSoftmaxCELoss()
</span></span><span style="display:flex;"><span>    net.train()
</span></span><span style="display:flex;"><span>    animator = d2l.Animator(xlabel=<span style="color:#0ff;font-weight:bold">&#39;epoch&#39;</span>, ylabel=<span style="color:#0ff;font-weight:bold">&#39;loss&#39;</span>,
</span></span><span style="display:flex;"><span>                     xlim=[<span style="color:#ff0;font-weight:bold">10</span>, num_epochs])
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> epoch in <span style="color:#fff;font-weight:bold">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        timer = d2l.Timer()
</span></span><span style="display:flex;"><span>        metric = d2l.Accumulator(<span style="color:#ff0;font-weight:bold">2</span>)  <span style="color:#007f7f"># 训练损失总和，词元数量</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> batch in data_iter:
</span></span><span style="display:flex;"><span>            optimizer.zero_grad()
</span></span><span style="display:flex;"><span>            X, X_valid_len, Y, Y_valid_len = [x.to(device) <span style="color:#fff;font-weight:bold">for</span> x in batch]
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f">#在之前序列预处理里load_data_nmt中，已将每个序列末尾添加了&lt;eos&gt;词元</span>
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f">#对于解码器的输入序列，在开头插入一个bos词元。为保证长度不变，需要截掉序列的最后一个词元(&lt;eos&gt;)</span>
</span></span><span style="display:flex;"><span>            bos = torch.tensor([tgt_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;bos&gt;&#39;</span>]] * Y.shape[<span style="color:#ff0;font-weight:bold">0</span>],
</span></span><span style="display:flex;"><span>                          device=device).reshape(-<span style="color:#ff0;font-weight:bold">1</span>, <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>            dec_input = torch.cat([bos, Y[:, :-<span style="color:#ff0;font-weight:bold">1</span>]], <span style="color:#ff0;font-weight:bold">1</span>)  <span style="color:#007f7f"># 强制教学</span>
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># X_valid_len本章暂时用不到，Y_valid_len会用到</span>
</span></span><span style="display:flex;"><span>            Y_hat, _ = net(X, dec_input, X_valid_len) 
</span></span><span style="display:flex;"><span>            l = loss(Y_hat, Y, Y_valid_len)
</span></span><span style="display:flex;"><span>            l.sum().backward()      <span style="color:#007f7f"># 损失函数的标量进行“反向传播”</span>
</span></span><span style="display:flex;"><span>            d2l.grad_clipping(net, <span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>            num_tokens = Y_valid_len.sum()
</span></span><span style="display:flex;"><span>            optimizer.step()
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">with</span> torch.no_grad():
</span></span><span style="display:flex;"><span>                metric.add(l.sum(), num_tokens)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> (epoch + <span style="color:#ff0;font-weight:bold">1</span>) % <span style="color:#ff0;font-weight:bold">10</span> == <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>            animator.add(epoch + <span style="color:#ff0;font-weight:bold">1</span>, (metric[<span style="color:#ff0;font-weight:bold">0</span>] / metric[<span style="color:#ff0;font-weight:bold">1</span>],))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;loss </span><span style="color:#0ff;font-weight:bold">{</span>metric[<span style="color:#ff0;font-weight:bold">0</span>] / metric[<span style="color:#ff0;font-weight:bold">1</span>]<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, </span><span style="color:#0ff;font-weight:bold">{</span>metric[<span style="color:#ff0;font-weight:bold">1</span>] / timer.stop()<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.1f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold"> &#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;tokens/sec on </span><span style="color:#0ff;font-weight:bold">{</span><span style="color:#fff;font-weight:bold">str</span>(device)<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>实例化模型，并训练</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>embed_size, num_hiddens, num_layers, dropout = <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">32</span>, <span style="color:#ff0;font-weight:bold">2</span>, <span style="color:#ff0;font-weight:bold">0.1</span>
</span></span><span style="display:flex;"><span>batch_size, num_steps = <span style="color:#ff0;font-weight:bold">64</span>, <span style="color:#ff0;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>lr, num_epochs, device = <span style="color:#ff0;font-weight:bold">0.005</span>, <span style="color:#ff0;font-weight:bold">300</span>, d2l.try_gpu()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>encoder = Seq2SeqEncoder(<span style="color:#fff;font-weight:bold">len</span>(src_vocab), embed_size, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                        dropout)
</span></span><span style="display:flex;"><span>decoder = Seq2SeqDecoder(<span style="color:#fff;font-weight:bold">len</span>(tgt_vocab), embed_size, num_hiddens, num_layers,
</span></span><span style="display:flex;"><span>                        dropout)
</span></span><span style="display:flex;"><span>net = d2l.EncoderDecoder(encoder, decoder)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># loss 0.019, 10100.9 tokens/sec on cuda:0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="75-预测">7.5 预测<a hidden class="anchor" aria-hidden="true" href="#75-预测">#</a></h2>
<ul>
<li>与训练部分不同之处在于， 每个解码器当前时间步的输入都将来自于前一时间步的预测词元。而在训练时的解码器输入都是来自真实的词元。
<ul>
<li>src_sentence 表示用户的输入英语句子</li>
<li>src_vocab表示英语的索引词表</li>
<li>tgt_vocab表示法语的索引词表</li>
</ul>
</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">32
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,
</span></span><span style="display:flex;"><span>                    device, save_attention_weights=<span style="color:#fff;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;序列到序列模型的预测&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 在预测时将net设置为评估模式</span>
</span></span><span style="display:flex;"><span>    net.eval()
</span></span><span style="display:flex;"><span>    src_tokens = src_vocab[src_sentence.lower().split(<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>)] + [
</span></span><span style="display:flex;"><span>        src_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>]]
</span></span><span style="display:flex;"><span>    enc_valid_len = torch.tensor([<span style="color:#fff;font-weight:bold">len</span>(src_tokens)], device=device)
</span></span><span style="display:flex;"><span>    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;pad&gt;&#39;</span>]) <span style="color:#007f7f">#固定长度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 添加批量轴（作为第一个维度）</span>
</span></span><span style="display:flex;"><span>    enc_X = torch.unsqueeze(
</span></span><span style="display:flex;"><span>        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=<span style="color:#ff0;font-weight:bold">0</span>)
</span></span><span style="display:flex;"><span>    enc_outputs = net.encoder(enc_X, enc_valid_len)
</span></span><span style="display:flex;"><span>    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 添加批量轴</span>
</span></span><span style="display:flex;"><span>    dec_X = torch.unsqueeze(torch.tensor(
</span></span><span style="display:flex;"><span>        [tgt_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;bos&gt;&#39;</span>]], dtype=torch.long, device=device), dim=<span style="color:#ff0;font-weight:bold">0</span>)
</span></span><span style="display:flex;"><span>    output_seq, attention_weight_seq = [], []
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> _ in <span style="color:#fff;font-weight:bold">range</span>(num_steps):
</span></span><span style="display:flex;"><span>        Y, dec_state = net.decoder(dec_X, dec_state)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入</span>
</span></span><span style="display:flex;"><span>        dec_X = Y.argmax(dim=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        pred = dec_X.squeeze(dim=<span style="color:#ff0;font-weight:bold">0</span>).type(torch.int32).item()
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 保存注意力权重（稍后讨论）</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> save_attention_weights:
</span></span><span style="display:flex;"><span>            attention_weight_seq.append(net.decoder.attention_weights)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 一旦序列结束词元被预测，输出序列的生成就提前完成了</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> pred == tgt_vocab[<span style="color:#0ff;font-weight:bold">&#39;&lt;eos&gt;&#39;</span>]:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">break</span>
</span></span><span style="display:flex;"><span>        output_seq.append(pred)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> <span style="color:#0ff;font-weight:bold">&#39; &#39;</span>.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809171239840.png" alt="image-20240809171239840"  />
</p>
<h2 id="76-预测序列的评估">7.6 预测序列的评估<a hidden class="anchor" aria-hidden="true" href="#76-预测序列的评估">#</a></h2>
<ul>
<li>可使用Bleu值评估预测序列与真实序列的差异；值越大，且接近1表示效果越好
<ul>
<li>当预测的序列长度小于真实序列长度时，前面的exp系数运算就会小于1，即对Bleu值惩罚；</li>
<li>当n值较大时的n元预测准确率越高时，Pn项就越大。</li>
</ul>
</li>
</ul>
<blockquote>
<p>具体地说，给定标签序列A、B、C、D、E、F 和预测序列A、B、B、C、D， 我们有p1=4/5、p2=3/4、p3=1/3和p4=0。</p></blockquote>
<p><img loading="lazy" src="https://raw.githubusercontent.com/lishensuo/images2/main/img01/image-20240809172146342.png" alt="image-20240809172146342"  />
</p>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> bleu(pred_seq, label_seq, k):  <span style="color:#007f7f">#@save</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0ff;font-weight:bold">&#34;&#34;&#34;计算BLEU&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    pred_tokens, label_tokens = pred_seq.split(<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>), label_seq.split(<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>)
</span></span><span style="display:flex;"><span>    len_pred, len_label = <span style="color:#fff;font-weight:bold">len</span>(pred_tokens), <span style="color:#fff;font-weight:bold">len</span>(label_tokens)
</span></span><span style="display:flex;"><span>    score = math.exp(<span style="color:#fff;font-weight:bold">min</span>(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">1</span> - len_label / len_pred))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> n in <span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">1</span>, k + <span style="color:#ff0;font-weight:bold">1</span>):
</span></span><span style="display:flex;"><span>        num_matches, label_subs = <span style="color:#ff0;font-weight:bold">0</span>, collections.defaultdict(<span style="color:#fff;font-weight:bold">int</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(len_label - n + <span style="color:#ff0;font-weight:bold">1</span>):
</span></span><span style="display:flex;"><span>            label_subs[<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>.join(label_tokens[i: i + n])] += <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> i in <span style="color:#fff;font-weight:bold">range</span>(len_pred - n + <span style="color:#ff0;font-weight:bold">1</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> label_subs[<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>.join(pred_tokens[i: i + n])] &gt; <span style="color:#ff0;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>                num_matches += <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>                label_subs[<span style="color:#0ff;font-weight:bold">&#39; &#39;</span>.join(pred_tokens[i: i + n])] -= <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>        score *= math.pow(num_matches / (len_pred - n + <span style="color:#ff0;font-weight:bold">1</span>), math.pow(<span style="color:#ff0;font-weight:bold">0.5</span>, n))
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">return</span> score
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>示例</li>
</ul>
<div class="highlight"><div style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#727272">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>engs = [<span style="color:#0ff;font-weight:bold">&#39;go .&#39;</span>, <span style="color:#0ff;font-weight:bold">&#34;i lost .&#34;</span>, <span style="color:#0ff;font-weight:bold">&#39;he</span><span style="color:#0ff;font-weight:bold">\&#39;</span><span style="color:#0ff;font-weight:bold">s calm .&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;i</span><span style="color:#0ff;font-weight:bold">\&#39;</span><span style="color:#0ff;font-weight:bold">m home .&#39;</span>]
</span></span><span style="display:flex;"><span>fras = [<span style="color:#0ff;font-weight:bold">&#39;va !&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;j</span><span style="color:#0ff;font-weight:bold">\&#39;</span><span style="color:#0ff;font-weight:bold">ai perdu .&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;il est calme .&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;je suis chez moi .&#39;</span>]
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> eng, fra in <span style="color:#fff;font-weight:bold">zip</span>(engs, fras):
</span></span><span style="display:flex;"><span>    translation, attention_weight_seq = predict_seq2seq(
</span></span><span style="display:flex;"><span>        net, eng, src_vocab, tgt_vocab, num_steps, device)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">{</span>eng<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold"> =&gt; </span><span style="color:#0ff;font-weight:bold">{</span>translation<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">, bleu </span><span style="color:#0ff;font-weight:bold">{</span>bleu(translation, fra, k=<span style="color:#ff0;font-weight:bold">2</span>)<span style="color:#0ff;font-weight:bold">:</span><span style="color:#0ff;font-weight:bold">.3f</span><span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># go . =&gt; va &lt;unk&gt; &lt;unk&gt; ., bleu 0.000</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># i lost . =&gt; j&#39;ai perdu ., bleu 1.000</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># he&#39;s calm . =&gt; il est bon de de essaye ., bleu 0.418</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># i&#39;m home . =&gt; je suis chez de moi &lt;unk&gt; emporté ., bleu 0.578</span>
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lishensuo.github.io/en/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li>
      <li><a href="https://lishensuo.github.io/en/tags/d2l/">D2L</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://lishensuo.github.io/en/posts/bioinfo/711d2l-%E7%AC%AC%E5%85%AB%E7%AB%A0%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
    <span class="title">« Prev Page</span>
    <br>
    <span>D2L--第八章循环神经网络</span>
  </a>
  <a class="next" href="https://lishensuo.github.io/en/posts/bioinfo/713d2l-%E7%AC%AC%E5%8D%81%E7%AB%A0%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">
    <span class="title">Next Page »</span>
    <br>
    <span>D2L--第十章注意力机制与Transformer</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://lishensuo.github.io/en/">Li&#39;s Bioinfo-Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
		<br/>您是本站第 <span id="busuanzi_value_site_uv"></span> 位访问者，总浏览量为 <span id="busuanzi_value_site_pv"></span> 次
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>

<script type="text/javascript"
async
src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
displayMath: [['$$','$$'], ['\[\[','\]\]']],
processEscapes: true,
processEnvironments: true,
skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
TeX: { equationNumbers: { autoNumber: "AMS" },
extensions: ["AMSmath.js", "AMSsymbols.js"] }
}
});

MathJax.Hub.Queue(function() {



var all = MathJax.Hub.getAllJax(), i;
for(i = 0; i < all.length; i += 1) {
all[i].SourceElement().parentNode.className += ' has-jax';
}
});
</script>

<style>
code.has-jax {
font: inherit;
font-size: 100%;
background: inherit;
border: inherit;
color: #515151;
}
</style></body>
</html>
